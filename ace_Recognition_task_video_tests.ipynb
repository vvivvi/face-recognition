{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znzWDP4N8cRn"
   },
   "source": [
    "# Face recognition using neural network features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUey7NiG8cRq"
   },
   "source": [
    "In this task, you have to construct face recognizer based on features extracted from the neural network. The task consists of two parts: image classification and video classification. In the first one you should classify distinct images and in the second one you will deal with short video sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "q-DupBs-wz6F",
    "outputId": "87169e0c-17ad-4e4e-a1b8-3dad6d5926fd"
   },
   "outputs": [],
   "source": [
    "# !pip install mtcnn\n",
    "# !conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJgKREpP8cRs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lZrAaqQw8cRx",
    "outputId": "21fdcebd-26cb-4a79-dcb7-2c589a4aeda2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['imread']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from copy import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SZ19PNFAaI_"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unpack(filename):\n",
    "    with zipfile.ZipFile(filename) as zf:\n",
    "        zf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "F_C8UHF2Am2Z",
    "outputId": "2521d485-c62c-43ae-85c8-b531103deeb9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "assignment_dir = 'face-recognition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njBxmkGt8cR0"
   },
   "source": [
    "First of all, you have you have to read the data. Run the cell below to unpack data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVu-Hvau8cR1"
   },
   "outputs": [],
   "source": [
    "# from get_data import unpack\n",
    "#unpack(assignment_dir + '/Face_Recognition_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BUXXCYBKlwy"
   },
   "outputs": [],
   "source": [
    "images_processed=True\n",
    "videos_processed=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRnR7EDWvO3Y"
   },
   "outputs": [],
   "source": [
    "# !unzip '/content/drive/My Drive/face-recognition/Face_Recognition_data.zip' -d '/content/drive/My Drive/face-recognition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q400JXHp8cR4"
   },
   "source": [
    "### Reading data for image and video classification (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kVl390l8cR5"
   },
   "source": [
    "Implement function $\\tt{load}$\\_$\\tt{image}$\\_$\\tt{data}$. It should return a tuple of 4 dictionaries: the first two are training images and labels, the second two are testing ones. The keys of the dictionaries are the names of the image files and the values are 3-dimensional numpy arrays (for images) or strings with the names (for labels).\n",
    "\n",
    "$\\tt{dir}$\\_$\\tt{name}$ is the name of directory with data for image classification. If 'Face_Recofnition_data' directory is located in the same directory as this notebook, then the default value can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_C6qbsj8cR6"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_image_data(dir_name):\n",
    "    \"\"\"Your implementation\"\"\"\n",
    "    images_train={}\n",
    "    images_test={}\n",
    "    labels_train={}\n",
    "    labels_test={}\n",
    "\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/train/images/*.jpg\")):\n",
    "      images_train[im_path.split('/')[-1]] = io.imread(im_path)\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/test/images/*.jpg\")):\n",
    "      images_test[im_path.split('/')[-1]] = io.imread(im_path)  \n",
    "\n",
    "    labels=pd.read_csv(dir_name+'/train/y_train.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_train[labels.iloc[rowidx,0]] = labels.iloc[rowidx,1]\n",
    "\n",
    "\n",
    "    labels=pd.read_csv(dir_name+'/test/y_test.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_test[labels.iloc[rowidx,0]] = labels.iloc[rowidx,1]\n",
    "    \n",
    "    \n",
    " \n",
    "    return images_train, labels_train, images_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TloxdDpK8cR9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661 \ttraining images\n",
      "808 \ttesting images\n"
     ]
    }
   ],
   "source": [
    "if not images_processed:\n",
    "  x_train, y_train, x_test, y_test = load_image_data(assignment_dir + \"/Face_Recognition_data/image_classification\")\n",
    "  np.savez_compressed(assignment_dir+'/loaded_images.npz',x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test)\n",
    "else:\n",
    "  with np.load(assignment_dir + \"/loaded_images.npz\", allow_pickle=True) as data:\n",
    "    x_train = data['x_train'].item()\n",
    "    y_train = data['y_train'].item()\n",
    "    x_test = data['x_test'].item()\n",
    "    y_test = data['y_test'].item()\n",
    "    \n",
    "print(len(x_train), '\\ttraining images')\n",
    "print(len(x_test), '\\ttesting images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSFbVqqq8cSB"
   },
   "outputs": [],
   "source": [
    "def visualize(data, labels, function = lambda x:x[0], n_cols = 5, n_rows=1):\n",
    "    figure(figsize = (3*n_cols,3*n_rows))\n",
    "    for n,i in enumerate(np.random.choice(list(data.keys()), size = n_cols*n_rows)):\n",
    "        plt.subplot(n_rows,n_cols,n+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(function([data[i]]))\n",
    "        plt.title(labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKL8sKaV8cSE"
   },
   "source": [
    "That is how the data looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJJFsX1x8cSI"
   },
   "source": [
    "Let us now read the video classification data, as well. You have to implement function to load video data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fTf4Edj8cSJ"
   },
   "source": [
    "Function $\\tt{load}$\\_$\\tt{video}$\\_$\\tt{data}$ should also return a tuple of 4 dictionaries: the first two are training images and labels, the second two are testing videos and labels. The training data is in the same format as in image classification task. The keys of testing data and labels are video ids and the values are the lists of frames and the strings with names, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpxUKpip8cSK"
   },
   "outputs": [],
   "source": [
    "def load_video_data(dir_name = 'Face_Recognition_data/video_classification'):\n",
    "    images_train={}\n",
    "    videos_test={}\n",
    "    labels_train={}\n",
    "    labels_test={}\n",
    "\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/train/images/*.jpg\")):\n",
    "      images_train[im_path.split('/')[-1]] = io.imread(im_path)\n",
    "    \n",
    "    labels=pd.read_csv(dir_name+'/train/y_train.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_train[str(labels.iloc[rowidx,0])] = labels.iloc[rowidx,1]\n",
    "\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/test/videos/*/\")):\n",
    "      video_id=im_path.split('/')[-2]\n",
    "      print(video_id)\n",
    "      filenames = glob.glob(dir_name + \"/test/videos/\"+video_id+\"/*.jpg\")\n",
    "      sorted_filenames = sorted(filenames, key=lambda x:int(x.split('/')[-1][:-4]))\n",
    "      videos_test[video_id] = []\n",
    "      for fn in sorted_filenames:\n",
    "        videos_test[video_id].append(io.imread(fn))\n",
    "      \n",
    "\n",
    "    labels=pd.read_csv(dir_name+'/test/y_test.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_test[str(labels.iloc[rowidx,0])] = labels.iloc[rowidx,1]\n",
    "\n",
    "      # images_test[im_path.split('/')[-1]] = io.imread(im_path)  \n",
    "  \n",
    "\n",
    "    return images_train, labels_train, videos_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVGLJte58cSN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729 \ttraining images\n",
      "70 \ttesting videos\n"
     ]
    }
   ],
   "source": [
    "if not videos_processed:\n",
    "  video_train, train_labels, video_test, test_labels = load_video_data(assignment_dir + \"/Face_Recognition_data/video_classification\")\n",
    "  np.savez_compressed(assignment_dir+'/loaded_videos.npz',video_train=video_train, train_labels=train_labels, \n",
    "                    video_test=video_test, test_labels=test_labels)\n",
    "else:\n",
    "  with np.load(assignment_dir + \"/loaded_videos.npz\", allow_pickle=True) as data:\n",
    "    video_train = data['video_train'].item()\n",
    "    train_labels = data['train_labels'].item()\n",
    "    video_test = data['video_test'].item()\n",
    "    test_labels = data['test_labels'].item()  \n",
    "\n",
    "\n",
    "print(len(video_train), '\\ttraining images')\n",
    "print(len(video_test), '\\ttesting videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xy3POFf8cSW"
   },
   "source": [
    "### Preprocessing (3 points)\n",
    "You have to implement preprocessing function in the cell below.\n",
    "Getting a list of images as an input the this function should detect the face on each image, find the facial keypoints () and then crop and normalize the image according to these keypoints. The output of this function is the list of images which contain only the aligned face and should be converted to the tensor of the shape $(N, 224, 224, 3)\\ $ where $N$ is the length of the initial list. You can add extra arguments to the preprocess function if necessary (i.e. flag $\\tt{is}$\\_$\\tt{video}$ to determine if the list of images is video sequence or not).\n",
    "\n",
    "For face detection and facial keypoint regression you can use your models from the previous tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxnViArxRpNB"
   },
   "source": [
    "\n",
    "---\n",
    "From the above wording of the instructions, we conclude that we are not forced to use the models from previous tasks but can use also other models of our choosing for the pre-processing task.\n",
    "\n",
    "Exactly this we will do as we anticipate a heap of problems with the previous models, as those models have been trained for fixed resolution and with just small datasets. Instead, we base the pre-processing on face and facial landmark detections of the MTCNN model of the ipazc/MTCNN project (http://github.com/ipazc/mtcnn).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6DKcVXPfQai"
   },
   "outputs": [],
   "source": [
    "# from week 1 assignment\n",
    "from skimage import transform\n",
    "\n",
    "def transform_face(image, eyes, size_multiplier = 2.15):\n",
    "    e=np.array(eyes)\n",
    "    center = np.mean(e,axis=0, keepdims=True)\n",
    "    diff = e[1]-e[0]\n",
    "    dist=np.sqrt(np.sum(diff*diff))\n",
    "    angle = np.arctan2(diff[1],diff[0])\n",
    "    \n",
    "    img_rotated = transform.rotate(image,np.degrees(angle), center=center)\n",
    "\n",
    "    #plt.imshow(img_rotated)\n",
    "    #print('Rotated image')\n",
    "    #plt.show()\n",
    "\n",
    "    face_extent = int(size_multiplier*dist) \n",
    "\n",
    "    # print('Face extent: ', face_extent)\n",
    "\n",
    "    box_left = int(center[0,0]-face_extent) \n",
    "    box_right = int(box_left + 2* face_extent)\n",
    "\n",
    "    box_top = int(center[0,1]-face_extent) \n",
    "    box_bottom = int(box_top + 2* face_extent)\n",
    "\n",
    "    pad=max(0,-box_left,-box_top,box_bottom-image.shape[0]-1, box_right-image.shape[1]-1)\n",
    "    img_crop = np.pad(img_rotated, ((pad,pad),(pad,pad),(0,0)))[box_top+pad:box_bottom+1+pad, box_left+pad:box_right+1+pad]\n",
    "\n",
    "    BOTTLENECK_SIZE = 90\n",
    "    img_crop = transform.resize(img_crop, (BOTTLENECK_SIZE, BOTTLENECK_SIZE))\n",
    "    \n",
    "    return transform.resize(img_crop, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gcqFMJK8cSX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "\n",
    "import copy\n",
    "\n",
    "def equalize_color_img(img):\n",
    "  img_eq = np.zeros_like(img)\n",
    "  img_eq[:,:,0] = exposure.equalize_hist(img[:,:,0])\n",
    "  img_eq[:,:,1] = exposure.equalize_hist(img[:,:,1])\n",
    "  img_eq[:,:,2] = exposure.equalize_hist(img[:,:,2])\n",
    "  return img_eq\n",
    "\n",
    "def distance_from_center(img, detection):\n",
    "    # img is numpay array\n",
    "    # detection is the face detection object from MTCNN detector\n",
    "\n",
    "    x, y, width, height = detection['box']\n",
    "    center_x = (img.shape[1]-1)/2.0\n",
    "    center_y = (img.shape[0]-1)/2.0\n",
    "    face_x = x + width/2.0\n",
    "    face_y = y + height/2.0\n",
    "    dx = center_x - face_x\n",
    "    dy = center_y - face_y\n",
    "    return np.sqrt(dx*dx+dy*dy)\n",
    "\n",
    "def measure_blur(img):\n",
    "  return np.var(filters.laplace(img[:,:,0])) + np.var(filters.laplace(img[:,:,1])) + np.var(filters.laplace(img[:,:,2]))\n",
    "\n",
    "def preprocess_imgs(imgs, size_multiplier=2.15):\n",
    "    ret_imgs=[]\n",
    "    detector = MTCNN()\n",
    "    n_images = len(imgs)\n",
    "    processed_img = 0\n",
    "\n",
    "    for img in imgs:\n",
    "      processed_img += 1\n",
    "      if processed_img%10 == 1: \n",
    "          print ('Preprocessing image {}/{}'.format(processed_img,n_images))\n",
    "      #plt.imshow(img)\n",
    "      #plt.title('Source image')\n",
    "      #plt.show()\n",
    "\n",
    "      faces = detector.detect_faces(img)\n",
    "      #for face in faces:\n",
    "\t    #  print(face)\n",
    "       \n",
    "      #choose the face that is closest to the image center\n",
    "      if len(faces) < 1:\n",
    "        ret_imgs.append(np.zeros((224,224,3)))\n",
    "        continue\n",
    "\n",
    "      min_ind=0\n",
    "      min_dist = distance_from_center(img, faces[0])\n",
    "      for i in range(1,len(faces)):\n",
    "        dist = distance_from_center(img, faces[i])\n",
    "        if dist < min_dist:\n",
    "          min_ind = i\n",
    "          min_dist = dist     \n",
    "       \n",
    "      #plt.imshow(img)\n",
    "      #ax = plt.gca()\n",
    "      face=faces[min_ind]\n",
    "\n",
    "      #x, y, width, height = face['box']\n",
    "      #rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "      #ax.add_patch(rect)\n",
    "      #dot = Circle(face['keypoints']['left_eye'], radius=2, color='green')\n",
    "      #ax.add_patch(dot)\n",
    "      #dot = Circle(face['keypoints']['right_eye'], radius=2, color='blue')\n",
    "      #ax.add_patch(dot)\n",
    "      #plt.show() \n",
    "\n",
    "      if face['confidence']< 0.9:\n",
    "        ret_imgs.append(np.zeros((224,224,3)))\n",
    "        continue\n",
    "\n",
    "      eyes=[face['keypoints']['left_eye'], face['keypoints']['right_eye']]  \n",
    "      #print(eyes)\n",
    "      img_transformed = equalize_color_img(transform_face(img, eyes, \n",
    "                                                          size_multiplier=size_multiplier))\n",
    "      \n",
    "      #blur = np.var(filters.laplace(img_transformed[:,:,0])) + np.var(filters.laplace(img_transformed[:,:,1])) + np.var(filters.laplace(img_transformed[:,:,2]))\n",
    "      #print('Blur: ',blur)\n",
    "\n",
    "      img_blurred=copy.deepcopy(img_transformed) \n",
    "\n",
    "      #sigma=1\n",
    "      #for i in range(5):\n",
    "      #  img_blurred=filters.gaussian(img_blurred)\n",
    "      #sharpness = measure_blur(img_blurred)\n",
    "      #MAX_SHARPNESS = 0.0005\n",
    "      #while sharpness > MAX_SHARPNESS:\n",
    "      #  img_blurred=filters.gaussian(img_blurred)\n",
    "      #  sharpness = measure_blur(img_blurred)\n",
    "        #print('Blur after {} iterations of Gaussian blurring: {}'.format(i+1,blur))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "      #plt.imshow(img_transformed)\n",
    "      #plt.show()\n",
    "\n",
    "      ret_imgs.append(img_blurred)\n",
    "    return ret_imgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLIbD5We8cSb"
   },
   "source": [
    "#### Visualization of preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bG1EI8788cSh"
   },
   "source": [
    "The neural network is already trained on the other face dataset. You should use this network as feature extractor to get descriptors of the faces. You can choose any hidden layer you need (or several layers) to extract features and any classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrvXOnn-8cSi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc6/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc7/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 500)               2048500   \n",
      "_________________________________________________________________\n",
      "prob (Activation)            (None, 500)               0         \n",
      "=================================================================\n",
      "Total params: 136,309,044\n",
      "Trainable params: 136,309,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(assignment_dir + '/face_recognition_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9CBRzUJ8cSl"
   },
   "source": [
    "Here is an example of using the network as feature extractor. The shape of input tensor has to be (n_images, 224, 224, 3), so you can input several images simultaneously and get their face descriptors of shape (n_images, n_components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-ApWK778cSl"
   },
   "outputs": [],
   "source": [
    "def get_layer_output(images, layer = 'fc7'):\n",
    "    assert len(images.shape)==4, 'Wrong input dimentionality!'\n",
    "    assert images.shape[1:]==(224,224,3), 'Wrong input shape!'\n",
    "    \n",
    "    layers=layer.split('+')\n",
    "    n_img = images.shape[0]\n",
    "\n",
    "    output=np.zeros((images.shape[0],0))\n",
    "\n",
    "    batch_size = 2\n",
    "    \n",
    "    for l in layers: \n",
    "      network_output = model.get_layer(l).output\n",
    "      feature_extraction_model = Model(model.input, network_output)\n",
    "         \n",
    "      layer_output=zeros((n_img,feature_extraction_model.predict(images[0,:,:,:].reshape(1,224,224,3)).shape[1]))\n",
    "    \n",
    "      \n",
    "    \n",
    "      for i in range(int(n_img/batch_size)):\n",
    "        layer_output[i*batch_size:min(n_img,(i+1)*batch_size),:]=feature_extraction_model.predict(\n",
    "            images[i*batch_size:min(n_img,(i+1)*batch_size),:,:,:])    \n",
    "    \n",
    "      output=np.hstack((output,layer_output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOaAKwX18cSo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.resize(x_train['0.jpg'], (224,224)).reshape(1,224,224,3)\n",
    "out = get_layer_output(img)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJLDs5QP8cSr"
   },
   "source": [
    "### Training classifier (2 points)\n",
    "\n",
    "\n",
    "You have to implement class $\\tt{Classifier}$ with methods $\\tt{fit}$, $\\tt{classify}$\\_$\\tt{images}$ and $\\tt{classify}$\\_$\\tt{videos}$ in the cell below. \n",
    "The method $\\tt{Classifier.fit}$ gets two dictionaries as input: train images and labels, and trains the classifier to predict the person shown on the image.\n",
    "$\\tt{Classifier.classify}$\\_$\\tt{images}$ gets the dictionary of test images (with filenames as keys) as input and should return the dictionary of the predicted labels.\n",
    "$\\tt{Classifier.classify}$\\_$\\tt{videos}$ is similar to the previous one, but gets the dictionary of test videos (with video as keys) as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4-aKpmg8cSt"
   },
   "source": [
    "To classify video you can combine the predictions for its frames any way you want (averaging, voting, etc.).\n",
    "If video classification takes too long you can use face detector not in all the frames but every few frames while preprocessing video frames. \n",
    "Besides, sometimes the face is hardly detected on the image and the frame in which the detector works wrong can add noise to the prediction. Hence, the result of the prediction without using such frames may be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "taBviW0o8cSx"
   },
   "source": [
    "Now we can build the classifier, fit it and use to predict the labels of testing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4U2NkS8cS0"
   },
   "source": [
    "### Image classification quality (2 points)\n",
    "\n",
    "Let us check the accuracy of your classification. To obtain 1 point for that rubric your implementation must have accuracy at least 0.90, to obtain 2 points — at least 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geFa3GNe8cS1"
   },
   "outputs": [],
   "source": [
    "def check_test(output, gt):\n",
    "    correct = 0.\n",
    "    total = len(gt)\n",
    "    for k, v in gt.items():\n",
    "        if output[k] == v:\n",
    "            correct += 1\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return 'Classification accuracy is %.4f' % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MY1WMDVP8cS6"
   },
   "source": [
    "### Video classification quality (2 points)\n",
    "\n",
    "Let us check the quality of video classification. To obtain 1 point for that rubric your implementation must have accuracy at least 0.80, to obtain 2 points — at least 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from os.path import join\n",
    "class ClassifierVideoCatboost():\n",
    "    def __init__(self, nn_model):\n",
    "        self.label_encoder = preprocessing.LabelEncoder()\n",
    "        self.catboost_model = CatBoostClassifier(verbose=True, iterations=3000)\n",
    "        self.pca1 = decomposition.PCA(0.9)\n",
    "        self.pca2 = decomposition.PCA(0.9)\n",
    "        self.pca3 = decomposition.PCA(0.9)\n",
    "        \n",
    "        self.layer = 'fc6+fc7+fc8'\n",
    "        self.size_multiplier=2.15\n",
    "        self.video_step = 1\n",
    "\n",
    "    def fit(self, train_imgs, train_labels):\n",
    "        n_images=len(train_imgs)\n",
    "        image_counter=0\n",
    "        \n",
    "        labels_orig = []\n",
    "        for id in train_imgs:\n",
    "          labels_orig.append(train_labels[id])\n",
    "        \n",
    "        labels_orig.extend(labels_orig)\n",
    "\n",
    "        preprocessed_images = np.array(preprocess_imgs(train_imgs.values(), size_multiplier=self.size_multiplier))\n",
    "        flipped_images=np.flip(preprocessed_images, -2)\n",
    "        augmented_images = np.vstack((preprocessed_images, flipped_images))\n",
    "\n",
    "        # augment images with two different scaling bottlenecks\n",
    "\n",
    "#        bottleneck_70 = np.zeros_like(augmented_images)\n",
    "#        bottleneck_110 = np.zeros_like(augmented_images)\n",
    "##\n",
    "#        n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#        bottleneck_70[i,:,:] = transform.resize(transform.resize(augmented_images[i], (70, 70)), (224, 224))\n",
    "#        bottleneck_110[i,:,:] = transform.resize(transform.resize(augmented_images[i], (110, 110)), (224, 224))\n",
    "\n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, bottleneck_70, bottleneck_110))\n",
    "        \n",
    "#        blur1 = np.zeros_like(augmented_images)\n",
    "#        blur2 = np.zeros_like(augmented_images)\n",
    "\n",
    "#        n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#         blur1[i,:,:] = filters.gaussian(augmented_images[i])\n",
    "#         blur2[i,:,:] = filters.gaussian(blur1[i])\n",
    "         \n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, blur1, blur2))\n",
    "\n",
    "#        print('augmented image set shape {}'.format(augmented_images.shape))\n",
    "\n",
    "#        #flip the images of the second half horizontally\n",
    "\n",
    "        pca1 = self.pca1.fit_transform(get_layer_output(augmented_images, layer='fc6'))\n",
    "        pca2 = self.pca2.fit_transform(get_layer_output(augmented_images, layer='fc7'))\n",
    "        pca3 = self.pca3.fit_transform(get_layer_output(augmented_images, layer='fc8'))\n",
    "        # pca2 = self.pca2.fit_transform(get_layer_output(augmented_images,layer='fc7'))\n",
    "        \n",
    "        self.x_train_internal= np.hstack((pca1,pca2,pca3))\n",
    "        self.y_train_internal = self.label_encoder.fit_transform(labels_orig)\n",
    "        \n",
    "        self.catboost_model.fit(self.x_train_internal, self.y_train_internal)\n",
    "        self.fitted=True\n",
    "\n",
    "    def classify_images(self, test_imgs):\n",
    "      assert self.fitted\n",
    "\n",
    "      n_images=len(test_imgs)\n",
    "      image_counter=0\n",
    "              \n",
    "      # x_test= get_layer_output(np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier)), layer=self.layer)\n",
    "      preprocess_result = np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier))   \n",
    "      pca1 =  self.pca1.transform(get_layer_output(preprocess_result, layer='fc7'))\n",
    "      pca2 =  self.pca2.transform(get_layer_output(preprocess_result, layer='fc7'))\n",
    "      pca3 =  self.pca3.transform(get_layer_output(preprocess_result, layer='fc8'))\n",
    "      x_test = np.hstack((pca1, pca2, pca3))  \n",
    "      ids=[] \n",
    "      for id in test_imgs:\n",
    "        ids.append(id)\n",
    "        \n",
    "      y_test=self.label_encoder.inverse_transform(self.catboost_model.predict(x_test))\n",
    "      print('mapping predictions back')\n",
    "      print(y_test.shape)\n",
    "      for i in range(n_images):\n",
    "        predictions[ids[i]] = str(y_test[i])\n",
    "      return predictions\n",
    "        \n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "        \n",
    "    def classify_videos(self, test_video):\n",
    "        assert self.fitted\n",
    "        predictions={}\n",
    "\n",
    "        video_step = 6\n",
    "\n",
    "        preprocess_pool=[]\n",
    "        pool_start={}\n",
    "        pool_end={}\n",
    "\n",
    "        # populate pool and preprocess all images in one lump\n",
    "        for id in test_video:\n",
    "          pool_start[id] = len(preprocess_pool) \n",
    "          preprocess_pool.extend(test_video[id][::video_step])\n",
    "          pool_end[id] = len(preprocess_pool) \n",
    "\n",
    "        preprocess_result = np.array(preprocess_imgs(preprocess_pool, size_multiplier=self.size_multiplier))\n",
    "        \n",
    "         \n",
    "        for id in test_video:\n",
    "          print('classifying video id ',id )\n",
    "          pca1 = self.pca1.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc7'))\n",
    "          pca2 = self.pca2.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc7'))\n",
    "          pca3 = self.pca3.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc8'))\n",
    "                                    \n",
    "          x_pred=  np.hstack((pca1, pca2, pca3))\n",
    "          probs = self.catboost_model.predict_proba(x_pred)\n",
    "          y_pred= self.label_encoder.inverse_transform(self.catboost_model.predict(x_pred))\n",
    "          for row in range(probs.shape[0]):\n",
    "         #   print('Frame ',row)\n",
    "             best_indices = probs[row,:].argsort()[-5:][::-1]\n",
    "         #   #print(neigh_dist.shape, neigh_ind.shape)\n",
    "         #   #print('best indices:', best_indices)\n",
    "             for i in range(5):\n",
    "              print('{} (p={})'.format(self.label_encoder.inverse_transform(best_indices)[i],\n",
    "                                       probs[row,best_indices[i]]))\n",
    "\n",
    "#            # collect sliding window of past nearest neighbours\n",
    "#\n",
    "#            windowstart=max(0,row-10)\n",
    "#            ind_window=np.array(neigh_ind[windowstart:row+1]).flatten() \n",
    "#            dist_window=np.array(neigh_dist[windowstart:row+1]).flatten() \n",
    "#\n",
    "#            ind_window_sorted = ind_window[np.argsort(dist_window)]\n",
    "#            dist_window_sorted = np.sort(dist_window)\n",
    "#\n",
    "#            \n",
    "#            print(neigh_dist[row])\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[neigh_ind[row]]))\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[ind_window_sorted]))\n",
    "#            print(dist_window_sorted)\n",
    "\n",
    "             print('Frame prediction: ',y_pred[row])\n",
    "\n",
    "          lst=list(y_pred)\n",
    "          predictions[id]=max(set(lst), key=lst.count) # mode of y_pred\n",
    "          print('prediction for video {}: {}'.format(id,predictions[id]))\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSLiFmtWLgan"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from statistics import mode\n",
    "\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from os.path import join\n",
    "class ClassifierVideo():\n",
    "    def __init__(self, nn_model):\n",
    "        self.label_encoder = preprocessing.LabelEncoder()\n",
    "        self.standard_scaler = preprocessing.StandardScaler()\n",
    "        self.fitted = False\n",
    "        self.feature_dim = 4096\n",
    "        self.knn_model = kNN(n_neighbors=5)\n",
    "        self.pca = decomposition.PCA(0.9, whiten=True)\n",
    "        self.pca2 = decomposition.PCA(0.9, whiten=True)\n",
    "        self.layer = 'fc7'\n",
    "        self.size_multiplier=2.15\n",
    "        self.video_step = 1\n",
    "\n",
    "    def fit(self, train_imgs, train_labels):\n",
    "        n_images=len(train_imgs)\n",
    "        image_counter=0\n",
    "        \n",
    "        labels_orig = []\n",
    "        for id in train_imgs:\n",
    "          labels_orig.append(train_labels[id])\n",
    "        \n",
    "        labels_orig.extend(labels_orig)\n",
    "\n",
    "        preprocessed_images = np.array(preprocess_imgs(train_imgs.values(), size_multiplier=self.size_multiplier))\n",
    "        flipped_images=np.flip(preprocessed_images, -2)\n",
    "        augmented_images = np.vstack((preprocessed_images, flipped_images))\n",
    "\n",
    "        # augment images with two different scaling bottlenecks\n",
    "\n",
    "        #bottleneck_70 = np.zeros_like(augmented_images)\n",
    "        #bottleneck_110 = np.zeros_like(augmented_images)\n",
    "#\n",
    "#       n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#         bottleneck_70[i,:,:] = transform.resize(transform.resize(augmented_images[i], (70, 70)), (224, 224))\n",
    "#         bottleneck_110[i,:,:] = transform.resize(transform.resize(augmented_images[i], (110, 110)), (224, 224))\n",
    "#\n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, bottleneck_70, bottleneck_110))\n",
    "        \n",
    " #       blur1 = np.zeros_like(augmented_images)\n",
    " #       blur2 = np.zeros_like(augmented_images)\n",
    "\n",
    " #       n_augm = augmented_images.shape[0]\n",
    " #       for i in range(n_augm):\n",
    " #        blur1[i,:,:] = filters.gaussian(augmented_images[i])\n",
    " #        blur2[i,:,:] = filters.gaussian(blur1[i])\n",
    "         \n",
    " #       labels_orig = labels_orig * 3\n",
    " #       augmented_images = np.vstack((augmented_images, blur1, blur2))\n",
    "\n",
    "        print('augmented image set shape {}'.format(augmented_images.shape))\n",
    "\n",
    "        #flip the images of the second half horizontally\n",
    "\n",
    "        pca1 = self.pca.fit_transform(get_layer_output(augmented_images,layer=self.layer))\n",
    "        # pca2 = self.pca2.fit_transform(get_layer_output(augmented_images,layer='fc7'))\n",
    "        \n",
    "        self.x_train_internal= pca1\n",
    "        self.y_train_internal = self.label_encoder.fit_transform(labels_orig)\n",
    "        \n",
    "        self.knn_model.fit(self.x_train_internal, self.y_train_internal)\n",
    "        self.fitted=True\n",
    "\n",
    "    def classify_images(self, test_imgs):\n",
    "      assert self.fitted\n",
    "      predictions={}\n",
    "\n",
    "      n_images=len(test_imgs)\n",
    "      image_counter=0\n",
    "              \n",
    "      x_test= self.pca.transform(get_layer_output(np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier)), layer=self.layer))\n",
    "      ids=[] \n",
    "      for id in test_imgs:\n",
    "        ids.append(id)\n",
    "\n",
    "      y_test=self.label_encoder.inverse_transform(self.knn_model.predict(x_test))\n",
    "      print('mapping predictions back')\n",
    "      print(y_test.shape)\n",
    "      for i in range(n_images):\n",
    "        predictions[ids[i]] = str(y_test[i])\n",
    "      return predictions\n",
    "        \n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "        \n",
    "    def classify_videos(self, test_video):\n",
    "        assert self.fitted\n",
    "        predictions={}\n",
    "\n",
    "        video_step = 6\n",
    "\n",
    "        preprocess_pool=[]\n",
    "        pool_start={}\n",
    "        pool_end={}\n",
    "\n",
    "        # populate pool and preprocess all images in one lump\n",
    "        for id in test_video:\n",
    "          pool_start[id] = len(preprocess_pool) \n",
    "          preprocess_pool.extend(test_video[id][::video_step])\n",
    "          pool_end[id] = len(preprocess_pool) \n",
    "\n",
    "        preprocess_result = np.array(preprocess_imgs(preprocess_pool, size_multiplier=self.size_multiplier))\n",
    "        \n",
    "         \n",
    "        for id in test_video:\n",
    "          print('classifying video id ',id )\n",
    "          pca1 = self.pca.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer=self.layer))\n",
    "          # pca2 = self.pca2.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc7'))\n",
    "                                    \n",
    "          x_pred= pca1 # np.hstack((pca1, pca2))\n",
    "          probs = self.knn_model.predict_proba(x_pred)\n",
    "          y_pred= self.label_encoder.inverse_transform(self.knn_model.predict(x_pred))\n",
    " #         neigh_dist, neigh_ind = self.knn_model.kneighbors(x_pred, return_distance=True)\n",
    "          for row in range(probs.shape[0]):\n",
    "         #   print('Frame ',row)\n",
    "            best_indices = probs[row,:].argsort()[-5:][::-1]\n",
    "         #   #print(neigh_dist.shape, neigh_ind.shape)\n",
    "             # print('best indices:', best_indices)\n",
    "            for i in range(5):\n",
    "             print('{} (p={})'.format(self.label_encoder.inverse_transform(best_indices)[i],\n",
    "                                      probs[row,best_indices[i]]))\n",
    "\n",
    "#            # collect sliding window of past nearest neighbours\n",
    "#\n",
    "#            windowstart=max(0,row-10)\n",
    "#            ind_window=np.array(neigh_ind[windowstart:row+1]).flatten() \n",
    "#            dist_window=np.array(neigh_dist[windowstart:row+1]).flatten() \n",
    "#\n",
    "#            ind_window_sorted = ind_window[np.argsort(dist_window)]\n",
    "#            dist_window_sorted = np.sort(dist_window)\n",
    "#\n",
    "#            \n",
    "#            print(neigh_dist[row])\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[neigh_ind[row]]))\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[ind_window_sorted]))\n",
    "#            print(dist_window_sorted)\n",
    "\n",
    "            print('Frame prediction: ',y_pred[row])\n",
    "\n",
    "          lst=list(y_pred)\n",
    "          predictions[id]=max(set(lst), key=lst.count) # mode of y_pred\n",
    "          print('prediction for video {}: {}'.format(id,predictions[id]))\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from os.path import join\n",
    "class ClassifierRandomForest():\n",
    "    def __init__(self, nn_model):\n",
    "        self.label_encoder = preprocessing.LabelEncoder()\n",
    "        self.rf_model = ensemble.RandomForestClassifier(n_estimators=750,verbose=1)\n",
    "        self.pca1 = decomposition.PCA(0.9)\n",
    "        self.pca2 = decomposition.PCA(0.9)\n",
    "        self.pca3 = decomposition.PCA(0.9)\n",
    "        \n",
    "        self.layer = 'fc6+fc7+fc8'\n",
    "        self.size_multiplier=2.15\n",
    "        self.video_step = 1\n",
    "\n",
    "    def fit(self, train_imgs, train_labels):\n",
    "        n_images=len(train_imgs)\n",
    "        image_counter=0\n",
    "        \n",
    "        labels_orig = []\n",
    "        for id in train_imgs:\n",
    "          labels_orig.append(train_labels[id])\n",
    "        \n",
    "        labels_orig.extend(labels_orig)\n",
    "\n",
    "        preprocessed_images = np.array(preprocess_imgs(train_imgs.values(), size_multiplier=self.size_multiplier))\n",
    "        flipped_images=np.flip(preprocessed_images, -2)\n",
    "        augmented_images = np.vstack((preprocessed_images, flipped_images))\n",
    "\n",
    "        # augment images with two different scaling bottlenecks\n",
    "\n",
    "#        bottleneck_70 = np.zeros_like(augmented_images)\n",
    "#        bottleneck_110 = np.zeros_like(augmented_images)\n",
    "##\n",
    "#        n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#        bottleneck_70[i,:,:] = transform.resize(transform.resize(augmented_images[i], (70, 70)), (224, 224))\n",
    "#        bottleneck_110[i,:,:] = transform.resize(transform.resize(augmented_images[i], (110, 110)), (224, 224))\n",
    "\n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, bottleneck_70, bottleneck_110))\n",
    "        \n",
    "#        blur1 = np.zeros_like(augmented_images)\n",
    "#        blur2 = np.zeros_like(augmented_images)\n",
    "\n",
    "#        n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#         blur1[i,:,:] = filters.gaussian(augmented_images[i])\n",
    "#         blur2[i,:,:] = filters.gaussian(blur1[i])\n",
    "         \n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, blur1, blur2))\n",
    "\n",
    "#        print('augmented image set shape {}'.format(augmented_images.shape))\n",
    "\n",
    "#        #flip the images of the second half horizontally\n",
    "\n",
    "        pca1 = self.pca1.fit_transform(get_layer_output(augmented_images, layer='fc6'))\n",
    "        pca2 = self.pca2.fit_transform(get_layer_output(augmented_images, layer='fc7'))\n",
    "        pca3 = self.pca3.fit_transform(get_layer_output(augmented_images, layer='fc8'))\n",
    "        # pca2 = self.pca2.fit_transform(get_layer_output(augmented_images,layer='fc7'))\n",
    "        \n",
    "        self.x_train_internal= np.hstack((pca1,pca2,pca3))\n",
    "        self.y_train_internal = self.label_encoder.fit_transform(labels_orig)\n",
    "        \n",
    "        self.rf_model.fit(self.x_train_internal, self.y_train_internal)\n",
    "        self.fitted=True\n",
    "\n",
    "    def classify_images(self, test_imgs):\n",
    "      assert self.fitted\n",
    "\n",
    "      n_images=len(test_imgs)\n",
    "      image_counter=0\n",
    "              \n",
    "      # x_test= get_layer_output(np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier)), layer=self.layer)\n",
    "      preprocess_result = np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier))   \n",
    "      pca1 =  self.pca1.transform(get_layer_output(preprocess_result, layer='fc6'))\n",
    "      pca2 =  self.pca2.transform(get_layer_output(preprocess_result, layer='fc7'))\n",
    "      pca3 =  self.pca3.transform(get_layer_output(preprocess_result, layer='fc8'))\n",
    "      x_test = np.hstack((pca1, pca2, pca3))  \n",
    "      ids=[] \n",
    "      for id in test_imgs:\n",
    "        ids.append(id)\n",
    "        \n",
    "      y_test=self.label_encoder.inverse_transform(self.rf_model.predict(x_test))\n",
    "      print('mapping predictions back')\n",
    "      print(y_test.shape)\n",
    "      for i in range(n_images):\n",
    "        predictions[ids[i]] = str(y_test[i])\n",
    "      return predictions\n",
    "        \n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "        \n",
    "    def classify_videos(self, test_video):\n",
    "        assert self.fitted\n",
    "        predictions={}\n",
    "\n",
    "        video_step = 6\n",
    "\n",
    "        preprocess_pool=[]\n",
    "        pool_start={}\n",
    "        pool_end={}\n",
    "\n",
    "        # populate pool and preprocess all images in one lump\n",
    "        for id in test_video:\n",
    "          pool_start[id] = len(preprocess_pool) \n",
    "          preprocess_pool.extend(test_video[id][::video_step])\n",
    "          pool_end[id] = len(preprocess_pool) \n",
    "\n",
    "        preprocess_result = np.array(preprocess_imgs(preprocess_pool, size_multiplier=self.size_multiplier))\n",
    "        \n",
    "         \n",
    "        for id in test_video:\n",
    "          print('classifying video id ',id )\n",
    "          pca1 = self.pca1.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc6'))\n",
    "          pca2 = self.pca2.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc7'))\n",
    "          pca3 = self.pca3.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc8'))\n",
    "                                    \n",
    "          x_pred= np.hstack((pca1, pca2, pca3))\n",
    "          probs = self.rf_model.predict_proba(x_pred)\n",
    "          y_pred= self.label_encoder.inverse_transform(self.rf_model.predict(x_pred))\n",
    "          for row in range(probs.shape[0]):\n",
    "         #   print('Frame ',row)\n",
    "         #   #best_indices = probs[row,:].argsort()[-5:][::-1]\n",
    "         #   #print(neigh_dist.shape, neigh_ind.shape)\n",
    "         #   #print('best indices:', best_indices)\n",
    "         #   #for i in range(5):\n",
    "         #   #  print('{} (p={})'.format(self.label_encoder.inverse_transform(best_indices)[i],\n",
    "         #   #                           probs[row,best_indices[i]]))\n",
    "\n",
    "#            # collect sliding window of past nearest neighbours\n",
    "#\n",
    "#            windowstart=max(0,row-10)\n",
    "#            ind_window=np.array(neigh_ind[windowstart:row+1]).flatten() \n",
    "#            dist_window=np.array(neigh_dist[windowstart:row+1]).flatten() \n",
    "#\n",
    "#            ind_window_sorted = ind_window[np.argsort(dist_window)]\n",
    "#            dist_window_sorted = np.sort(dist_window)\n",
    "#\n",
    "#            \n",
    "#            print(neigh_dist[row])\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[neigh_ind[row]]))\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[ind_window_sorted]))\n",
    "#            print(dist_window_sorted)\n",
    "\n",
    "            print('Frame prediction: ',y_pred[row])\n",
    "\n",
    "          lst=list(y_pred)\n",
    "          predictions[id]=max(set(lst), key=lst.count) # mode of y_pred\n",
    "          print('prediction for video {}: {}'.format(id,predictions[id]))\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdT5_xfVsqSu"
   },
   "outputs": [],
   "source": [
    "len(video_test['0'][::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAgG4UyJoL6Q"
   },
   "outputs": [],
   "source": [
    "# %%capture cap_out --no-stderr\n",
    "\n",
    "def extract_subdict(d, keys):\n",
    "    return dict((k, d[k]) for k in keys if k in d)\n",
    "\n",
    "difficult_labels=['10','14','16','29','35','40','43','49','5','50','53','54','57','59','63']\n",
    "testing_labels = ['0','1','11']+difficult_labels\n",
    "video_classifier = ClassifierVideo(model)\n",
    "video_classifier.fit(video_train, train_labels)\n",
    "y_video_difficult_out = video_classifier.classify_videos(extract_subdict(video_test, testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsTLjxSpthaS"
   },
   "outputs": [],
   "source": [
    "with open('fc7-heq-2.15.txt', 'w') as f:\n",
    "    f.write(cap_out.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing image 1/729\n",
      "Preprocessing image 11/729\n",
      "Preprocessing image 21/729\n",
      "Preprocessing image 31/729\n",
      "Preprocessing image 41/729\n",
      "Preprocessing image 51/729\n",
      "Preprocessing image 61/729\n",
      "Preprocessing image 71/729\n",
      "Preprocessing image 81/729\n",
      "Preprocessing image 91/729\n",
      "Preprocessing image 101/729\n",
      "Preprocessing image 111/729\n",
      "Preprocessing image 121/729\n",
      "Preprocessing image 131/729\n",
      "Preprocessing image 141/729\n",
      "Preprocessing image 151/729\n",
      "Preprocessing image 161/729\n",
      "Preprocessing image 171/729\n",
      "Preprocessing image 181/729\n",
      "Preprocessing image 191/729\n",
      "Preprocessing image 201/729\n",
      "Preprocessing image 211/729\n",
      "Preprocessing image 221/729\n",
      "Preprocessing image 231/729\n",
      "Preprocessing image 241/729\n",
      "Preprocessing image 251/729\n",
      "Preprocessing image 261/729\n",
      "Preprocessing image 271/729\n",
      "Preprocessing image 281/729\n",
      "Preprocessing image 291/729\n",
      "Preprocessing image 301/729\n",
      "Preprocessing image 311/729\n",
      "Preprocessing image 321/729\n",
      "Preprocessing image 331/729\n",
      "Preprocessing image 341/729\n",
      "Preprocessing image 351/729\n",
      "Preprocessing image 361/729\n",
      "Preprocessing image 371/729\n",
      "Preprocessing image 381/729\n",
      "Preprocessing image 391/729\n",
      "Preprocessing image 401/729\n",
      "Preprocessing image 411/729\n",
      "Preprocessing image 421/729\n",
      "Preprocessing image 431/729\n",
      "Preprocessing image 441/729\n",
      "Preprocessing image 451/729\n",
      "Preprocessing image 461/729\n",
      "Preprocessing image 471/729\n",
      "Preprocessing image 481/729\n",
      "Preprocessing image 491/729\n",
      "Preprocessing image 501/729\n",
      "Preprocessing image 511/729\n",
      "Preprocessing image 521/729\n",
      "Preprocessing image 531/729\n",
      "Preprocessing image 541/729\n",
      "Preprocessing image 551/729\n",
      "Preprocessing image 561/729\n",
      "Preprocessing image 571/729\n",
      "Preprocessing image 581/729\n",
      "Preprocessing image 591/729\n",
      "Preprocessing image 601/729\n",
      "Preprocessing image 611/729\n",
      "Preprocessing image 621/729\n",
      "Preprocessing image 631/729\n",
      "Preprocessing image 641/729\n",
      "Preprocessing image 651/729\n",
      "Preprocessing image 661/729\n",
      "Preprocessing image 671/729\n",
      "Preprocessing image 681/729\n",
      "Preprocessing image 691/729\n",
      "Preprocessing image 701/729\n",
      "Preprocessing image 711/729\n",
      "Preprocessing image 721/729\n",
      "0:\tlearn: 4.5371521\ttotal: 6.86s\tremaining: 4h 16m 59s\n",
      "1:\tlearn: 4.5084245\ttotal: 13.5s\tremaining: 4h 13m 36s\n",
      "2:\tlearn: 4.4762142\ttotal: 20.4s\tremaining: 4h 14m 39s\n",
      "3:\tlearn: 4.4459361\ttotal: 27.3s\tremaining: 4h 15m 6s\n",
      "4:\tlearn: 4.4164921\ttotal: 34.2s\tremaining: 4h 15m 38s\n",
      "5:\tlearn: 4.3846365\ttotal: 41s\tremaining: 4h 15m 30s\n",
      "6:\tlearn: 4.3531024\ttotal: 47.6s\tremaining: 4h 14m 19s\n",
      "7:\tlearn: 4.3164537\ttotal: 54.5s\tremaining: 4h 14m 29s\n",
      "8:\tlearn: 4.2863429\ttotal: 1m 1s\tremaining: 4h 14m 5s\n",
      "9:\tlearn: 4.2598365\ttotal: 1m 8s\tremaining: 4h 13m 59s\n",
      "10:\tlearn: 4.2242074\ttotal: 1m 14s\tremaining: 4h 13m 16s\n",
      "11:\tlearn: 4.1952547\ttotal: 1m 21s\tremaining: 4h 13m 6s\n",
      "12:\tlearn: 4.1736072\ttotal: 1m 28s\tremaining: 4h 13m 13s\n",
      "13:\tlearn: 4.1459201\ttotal: 1m 35s\tremaining: 4h 13m 6s\n",
      "14:\tlearn: 4.1132068\ttotal: 1m 41s\tremaining: 4h 13m 8s\n",
      "15:\tlearn: 4.0791308\ttotal: 1m 48s\tremaining: 4h 13m 1s\n",
      "16:\tlearn: 4.0515423\ttotal: 1m 55s\tremaining: 4h 12m 55s\n",
      "17:\tlearn: 4.0314786\ttotal: 2m 2s\tremaining: 4h 12m 39s\n",
      "18:\tlearn: 4.0076826\ttotal: 2m 8s\tremaining: 4h 12m 21s\n",
      "19:\tlearn: 3.9793491\ttotal: 2m 15s\tremaining: 4h 12m 29s\n",
      "20:\tlearn: 3.9510989\ttotal: 2m 22s\tremaining: 4h 12m 1s\n",
      "21:\tlearn: 3.9224761\ttotal: 2m 29s\tremaining: 4h 12m 38s\n",
      "22:\tlearn: 3.8979110\ttotal: 2m 36s\tremaining: 4h 12m 45s\n",
      "23:\tlearn: 3.8617024\ttotal: 2m 43s\tremaining: 4h 13m 3s\n",
      "24:\tlearn: 3.8240022\ttotal: 2m 50s\tremaining: 4h 12m 46s\n",
      "25:\tlearn: 3.7998598\ttotal: 2m 58s\tremaining: 4h 13m 48s\n",
      "26:\tlearn: 3.7577564\ttotal: 3m 5s\tremaining: 4h 14m 4s\n",
      "27:\tlearn: 3.7259214\ttotal: 3m 12s\tremaining: 4h 14m 15s\n",
      "28:\tlearn: 3.7048868\ttotal: 3m 19s\tremaining: 4h 14m 37s\n",
      "29:\tlearn: 3.6746979\ttotal: 3m 26s\tremaining: 4h 14m 11s\n",
      "30:\tlearn: 3.6441158\ttotal: 3m 33s\tremaining: 4h 14m 9s\n",
      "31:\tlearn: 3.6153118\ttotal: 3m 39s\tremaining: 4h 13m 47s\n",
      "32:\tlearn: 3.5900591\ttotal: 3m 46s\tremaining: 4h 13m 32s\n",
      "33:\tlearn: 3.5619322\ttotal: 3m 53s\tremaining: 4h 14m 5s\n",
      "34:\tlearn: 3.5341915\ttotal: 4m 3s\tremaining: 4h 17m 7s\n",
      "35:\tlearn: 3.5032035\ttotal: 4m 16s\tremaining: 4h 22m 59s\n",
      "36:\tlearn: 3.4742465\ttotal: 4m 28s\tremaining: 4h 27m 32s\n",
      "37:\tlearn: 3.4437472\ttotal: 4m 40s\tremaining: 4h 31m 42s\n",
      "38:\tlearn: 3.4216263\ttotal: 4m 50s\tremaining: 4h 34m 51s\n",
      "39:\tlearn: 3.4011244\ttotal: 5m 3s\tremaining: 4h 39m 51s\n",
      "40:\tlearn: 3.3648133\ttotal: 5m 15s\tremaining: 4h 43m 2s\n",
      "41:\tlearn: 3.3423688\ttotal: 5m 26s\tremaining: 4h 46m 5s\n",
      "42:\tlearn: 3.3126975\ttotal: 5m 37s\tremaining: 4h 49m 2s\n",
      "43:\tlearn: 3.2862495\ttotal: 5m 48s\tremaining: 4h 51m 19s\n",
      "44:\tlearn: 3.2605511\ttotal: 6m\tremaining: 4h 54m 37s\n",
      "45:\tlearn: 3.2280128\ttotal: 6m 11s\tremaining: 4h 56m 35s\n",
      "46:\tlearn: 3.1972205\ttotal: 6m 22s\tremaining: 4h 59m 10s\n",
      "47:\tlearn: 3.1747618\ttotal: 6m 34s\tremaining: 5h 1m 33s\n",
      "48:\tlearn: 3.1530986\ttotal: 6m 45s\tremaining: 5h 3m 32s\n",
      "49:\tlearn: 3.1346377\ttotal: 6m 55s\tremaining: 5h 4m 53s\n",
      "50:\tlearn: 3.1110951\ttotal: 7m 7s\tremaining: 5h 7m 19s\n",
      "51:\tlearn: 3.0843120\ttotal: 7m 19s\tremaining: 5h 9m 35s\n",
      "52:\tlearn: 3.0643388\ttotal: 7m 30s\tremaining: 5h 11m 32s\n",
      "53:\tlearn: 3.0442061\ttotal: 7m 42s\tremaining: 5h 13m 42s\n",
      "54:\tlearn: 3.0240897\ttotal: 7m 54s\tremaining: 5h 15m 53s\n",
      "55:\tlearn: 2.9997563\ttotal: 8m 7s\tremaining: 5h 18m\n",
      "56:\tlearn: 2.9783750\ttotal: 8m 18s\tremaining: 5h 19m 50s\n",
      "57:\tlearn: 2.9562678\ttotal: 8m 30s\tremaining: 5h 21m 20s\n",
      "58:\tlearn: 2.9267072\ttotal: 8m 41s\tremaining: 5h 22m 45s\n",
      "59:\tlearn: 2.8982060\ttotal: 8m 53s\tremaining: 5h 24m 23s\n",
      "60:\tlearn: 2.8768990\ttotal: 9m 4s\tremaining: 5h 25m 57s\n",
      "61:\tlearn: 2.8545127\ttotal: 9m 15s\tremaining: 5h 26m 58s\n",
      "62:\tlearn: 2.8380986\ttotal: 9m 22s\tremaining: 5h 25m 17s\n",
      "63:\tlearn: 2.8212664\ttotal: 9m 28s\tremaining: 5h 23m 47s\n",
      "64:\tlearn: 2.7886019\ttotal: 9m 36s\tremaining: 5h 22m 43s\n",
      "65:\tlearn: 2.7672005\ttotal: 9m 42s\tremaining: 5h 21m 21s\n",
      "66:\tlearn: 2.7434948\ttotal: 9m 49s\tremaining: 5h 19m 52s\n",
      "67:\tlearn: 2.7244814\ttotal: 9m 55s\tremaining: 5h 18m 34s\n",
      "68:\tlearn: 2.6932179\ttotal: 10m 1s\tremaining: 5h 17m 8s\n",
      "69:\tlearn: 2.6679693\ttotal: 10m 8s\tremaining: 5h 15m 45s\n",
      "70:\tlearn: 2.6465510\ttotal: 10m 14s\tremaining: 5h 14m 30s\n",
      "71:\tlearn: 2.6269378\ttotal: 10m 21s\tremaining: 5h 13m 12s\n",
      "72:\tlearn: 2.6052265\ttotal: 10m 27s\tremaining: 5h 12m 2s\n",
      "73:\tlearn: 2.5830982\ttotal: 10m 34s\tremaining: 5h 10m 47s\n",
      "74:\tlearn: 2.5631598\ttotal: 10m 40s\tremaining: 5h 9m 33s\n",
      "75:\tlearn: 2.5403351\ttotal: 10m 46s\tremaining: 5h 8m 27s\n",
      "76:\tlearn: 2.5181831\ttotal: 10m 53s\tremaining: 5h 7m 16s\n",
      "77:\tlearn: 2.5030009\ttotal: 10m 59s\tremaining: 5h 6m 14s\n",
      "78:\tlearn: 2.4871332\ttotal: 11m 6s\tremaining: 5h 5m 7s\n",
      "79:\tlearn: 2.4621142\ttotal: 11m 12s\tremaining: 5h 4m 1s\n",
      "80:\tlearn: 2.4366829\ttotal: 11m 19s\tremaining: 5h 3m 3s\n",
      "81:\tlearn: 2.4155940\ttotal: 11m 25s\tremaining: 5h 2m 1s\n",
      "82:\tlearn: 2.3967190\ttotal: 11m 31s\tremaining: 5h 1m 5s\n",
      "83:\tlearn: 2.3767530\ttotal: 11m 38s\tremaining: 5h 4s\n",
      "84:\tlearn: 2.3636488\ttotal: 11m 44s\tremaining: 4h 59m 5s\n",
      "85:\tlearn: 2.3407976\ttotal: 11m 51s\tremaining: 4h 58m 12s\n",
      "86:\tlearn: 2.3220614\ttotal: 11m 57s\tremaining: 4h 57m 16s\n",
      "87:\tlearn: 2.3033572\ttotal: 12m 3s\tremaining: 4h 56m 26s\n",
      "88:\tlearn: 2.2802695\ttotal: 12m 10s\tremaining: 4h 55m 32s\n",
      "89:\tlearn: 2.2586862\ttotal: 12m 16s\tremaining: 4h 54m 38s\n",
      "90:\tlearn: 2.2387584\ttotal: 12m 23s\tremaining: 4h 53m 50s\n",
      "91:\tlearn: 2.2154802\ttotal: 12m 29s\tremaining: 4h 52m 58s\n",
      "92:\tlearn: 2.1967285\ttotal: 12m 35s\tremaining: 4h 52m 12s\n",
      "93:\tlearn: 2.1783595\ttotal: 12m 42s\tremaining: 4h 51m 23s\n",
      "94:\tlearn: 2.1578504\ttotal: 12m 48s\tremaining: 4h 50m 35s\n",
      "95:\tlearn: 2.1430056\ttotal: 12m 55s\tremaining: 4h 49m 51s\n",
      "96:\tlearn: 2.1264222\ttotal: 13m 1s\tremaining: 4h 49m 4s\n",
      "97:\tlearn: 2.1064908\ttotal: 13m 7s\tremaining: 4h 48m 23s\n",
      "98:\tlearn: 2.0853081\ttotal: 13m 14s\tremaining: 4h 47m 38s\n",
      "99:\tlearn: 2.0675491\ttotal: 13m 20s\tremaining: 4h 46m 54s\n",
      "100:\tlearn: 2.0489284\ttotal: 13m 27s\tremaining: 4h 46m 15s\n",
      "101:\tlearn: 2.0341804\ttotal: 13m 33s\tremaining: 4h 45m 32s\n",
      "102:\tlearn: 2.0184805\ttotal: 13m 39s\tremaining: 4h 44m 50s\n",
      "103:\tlearn: 1.9981028\ttotal: 13m 46s\tremaining: 4h 44m 13s\n",
      "104:\tlearn: 1.9810092\ttotal: 13m 52s\tremaining: 4h 43m 32s\n",
      "105:\tlearn: 1.9669701\ttotal: 13m 59s\tremaining: 4h 42m 56s\n",
      "106:\tlearn: 1.9487349\ttotal: 14m 5s\tremaining: 4h 42m 16s\n",
      "107:\tlearn: 1.9295981\ttotal: 14m 12s\tremaining: 4h 41m 41s\n",
      "108:\tlearn: 1.9127655\ttotal: 14m 18s\tremaining: 4h 41m 3s\n",
      "109:\tlearn: 1.8946532\ttotal: 14m 24s\tremaining: 4h 40m 26s\n",
      "110:\tlearn: 1.8799479\ttotal: 14m 31s\tremaining: 4h 39m 53s\n",
      "111:\tlearn: 1.8683797\ttotal: 14m 37s\tremaining: 4h 39m 17s\n",
      "112:\tlearn: 1.8513019\ttotal: 14m 44s\tremaining: 4h 38m 41s\n",
      "113:\tlearn: 1.8334593\ttotal: 14m 50s\tremaining: 4h 38m 8s\n",
      "114:\tlearn: 1.8185347\ttotal: 14m 57s\tremaining: 4h 37m 33s\n",
      "115:\tlearn: 1.7993713\ttotal: 15m 3s\tremaining: 4h 37m\n",
      "116:\tlearn: 1.7849269\ttotal: 15m 9s\tremaining: 4h 36m 26s\n",
      "117:\tlearn: 1.7708262\ttotal: 15m 16s\tremaining: 4h 35m 56s\n",
      "118:\tlearn: 1.7535618\ttotal: 15m 22s\tremaining: 4h 35m 23s\n",
      "119:\tlearn: 1.7342503\ttotal: 15m 29s\tremaining: 4h 34m 50s\n",
      "120:\tlearn: 1.7244953\ttotal: 15m 35s\tremaining: 4h 34m 20s\n",
      "121:\tlearn: 1.7123599\ttotal: 15m 41s\tremaining: 4h 33m 48s\n",
      "122:\tlearn: 1.6955835\ttotal: 15m 48s\tremaining: 4h 33m 20s\n",
      "123:\tlearn: 1.6791355\ttotal: 15m 54s\tremaining: 4h 32m 49s\n",
      "124:\tlearn: 1.6683754\ttotal: 16m 1s\tremaining: 4h 32m 17s\n",
      "125:\tlearn: 1.6548289\ttotal: 16m 7s\tremaining: 4h 31m 50s\n",
      "126:\tlearn: 1.6416286\ttotal: 16m 13s\tremaining: 4h 31m 19s\n",
      "127:\tlearn: 1.6280443\ttotal: 16m 20s\tremaining: 4h 30m 53s\n",
      "128:\tlearn: 1.6150995\ttotal: 16m 26s\tremaining: 4h 30m 23s\n",
      "129:\tlearn: 1.6022729\ttotal: 16m 33s\tremaining: 4h 29m 55s\n",
      "130:\tlearn: 1.5890145\ttotal: 16m 39s\tremaining: 4h 29m 30s\n",
      "131:\tlearn: 1.5776378\ttotal: 16m 45s\tremaining: 4h 29m 1s\n",
      "132:\tlearn: 1.5645584\ttotal: 16m 52s\tremaining: 4h 28m 37s\n",
      "133:\tlearn: 1.5506613\ttotal: 16m 58s\tremaining: 4h 28m 9s\n",
      "134:\tlearn: 1.5386059\ttotal: 17m 5s\tremaining: 4h 27m 42s\n",
      "135:\tlearn: 1.5267722\ttotal: 17m 11s\tremaining: 4h 27m 18s\n",
      "136:\tlearn: 1.5141950\ttotal: 17m 18s\tremaining: 4h 26m 51s\n",
      "137:\tlearn: 1.5023709\ttotal: 17m 24s\tremaining: 4h 26m 28s\n",
      "138:\tlearn: 1.4892060\ttotal: 17m 30s\tremaining: 4h 26m 1s\n",
      "139:\tlearn: 1.4772721\ttotal: 17m 37s\tremaining: 4h 25m 34s\n",
      "140:\tlearn: 1.4663072\ttotal: 17m 43s\tremaining: 4h 25m 11s\n",
      "141:\tlearn: 1.4548446\ttotal: 17m 50s\tremaining: 4h 24m 45s\n",
      "142:\tlearn: 1.4437817\ttotal: 17m 56s\tremaining: 4h 24m 23s\n",
      "143:\tlearn: 1.4342090\ttotal: 18m 2s\tremaining: 4h 23m 57s\n",
      "144:\tlearn: 1.4196828\ttotal: 18m 9s\tremaining: 4h 23m 32s\n",
      "145:\tlearn: 1.4074544\ttotal: 18m 15s\tremaining: 4h 23m 10s\n",
      "146:\tlearn: 1.3943170\ttotal: 18m 22s\tremaining: 4h 22m 45s\n",
      "147:\tlearn: 1.3824395\ttotal: 18m 28s\tremaining: 4h 22m 23s\n",
      "148:\tlearn: 1.3694637\ttotal: 18m 34s\tremaining: 4h 21m 59s\n",
      "149:\tlearn: 1.3588571\ttotal: 18m 41s\tremaining: 4h 21m 35s\n",
      "150:\tlearn: 1.3485685\ttotal: 18m 47s\tremaining: 4h 21m 14s\n",
      "151:\tlearn: 1.3393524\ttotal: 18m 53s\tremaining: 4h 20m 51s\n",
      "152:\tlearn: 1.3292349\ttotal: 19m\tremaining: 4h 20m 31s\n",
      "153:\tlearn: 1.3197526\ttotal: 19m 6s\tremaining: 4h 20m 9s\n",
      "154:\tlearn: 1.3081385\ttotal: 19m 13s\tremaining: 4h 19m 46s\n",
      "155:\tlearn: 1.2940498\ttotal: 19m 20s\tremaining: 4h 19m 40s\n",
      "156:\tlearn: 1.2835858\ttotal: 19m 28s\tremaining: 4h 19m 33s\n",
      "157:\tlearn: 1.2713202\ttotal: 19m 35s\tremaining: 4h 19m 18s\n",
      "158:\tlearn: 1.2628634\ttotal: 19m 41s\tremaining: 4h 18m 56s\n",
      "159:\tlearn: 1.2506510\ttotal: 19m 47s\tremaining: 4h 18m 36s\n",
      "160:\tlearn: 1.2411589\ttotal: 19m 54s\tremaining: 4h 18m 15s\n",
      "161:\tlearn: 1.2328507\ttotal: 20m\tremaining: 4h 17m 53s\n",
      "162:\tlearn: 1.2244539\ttotal: 20m 7s\tremaining: 4h 17m 34s\n",
      "163:\tlearn: 1.2136821\ttotal: 20m 13s\tremaining: 4h 17m 13s\n",
      "164:\tlearn: 1.2035276\ttotal: 20m 19s\tremaining: 4h 16m 54s\n",
      "165:\tlearn: 1.1935205\ttotal: 20m 26s\tremaining: 4h 16m 34s\n",
      "166:\tlearn: 1.1832239\ttotal: 20m 32s\tremaining: 4h 16m 16s\n",
      "167:\tlearn: 1.1766124\ttotal: 20m 39s\tremaining: 4h 15m 57s\n",
      "168:\tlearn: 1.1688725\ttotal: 20m 45s\tremaining: 4h 15m 37s\n",
      "169:\tlearn: 1.1607091\ttotal: 20m 52s\tremaining: 4h 15m 19s\n",
      "170:\tlearn: 1.1527698\ttotal: 20m 58s\tremaining: 4h 14m 59s\n",
      "171:\tlearn: 1.1410061\ttotal: 21m 4s\tremaining: 4h 14m 39s\n",
      "172:\tlearn: 1.1312306\ttotal: 21m 11s\tremaining: 4h 14m 22s\n",
      "173:\tlearn: 1.1211757\ttotal: 21m 17s\tremaining: 4h 14m 2s\n",
      "174:\tlearn: 1.1117571\ttotal: 21m 23s\tremaining: 4h 13m 44s\n",
      "175:\tlearn: 1.1023817\ttotal: 21m 30s\tremaining: 4h 13m 26s\n",
      "176:\tlearn: 1.0938454\ttotal: 21m 36s\tremaining: 4h 13m 7s\n",
      "177:\tlearn: 1.0857488\ttotal: 21m 43s\tremaining: 4h 12m 50s\n",
      "178:\tlearn: 1.0784375\ttotal: 21m 49s\tremaining: 4h 12m 31s\n",
      "179:\tlearn: 1.0710541\ttotal: 21m 56s\tremaining: 4h 12m 15s\n",
      "180:\tlearn: 1.0615678\ttotal: 22m 2s\tremaining: 4h 11m 57s\n",
      "181:\tlearn: 1.0536278\ttotal: 22m 8s\tremaining: 4h 11m 38s\n",
      "182:\tlearn: 1.0475906\ttotal: 22m 15s\tremaining: 4h 11m 21s\n",
      "183:\tlearn: 1.0379063\ttotal: 22m 21s\tremaining: 4h 11m 3s\n",
      "184:\tlearn: 1.0295228\ttotal: 22m 28s\tremaining: 4h 10m 47s\n",
      "185:\tlearn: 1.0230601\ttotal: 22m 34s\tremaining: 4h 10m 29s\n",
      "186:\tlearn: 1.0129939\ttotal: 22m 40s\tremaining: 4h 10m 12s\n",
      "187:\tlearn: 1.0045713\ttotal: 22m 47s\tremaining: 4h 9m 56s\n",
      "188:\tlearn: 0.9965311\ttotal: 22m 53s\tremaining: 4h 9m 39s\n",
      "189:\tlearn: 0.9872280\ttotal: 23m\tremaining: 4h 9m 23s\n",
      "190:\tlearn: 0.9814076\ttotal: 23m 6s\tremaining: 4h 9m 6s\n",
      "191:\tlearn: 0.9736004\ttotal: 23m 12s\tremaining: 4h 8m 49s\n",
      "192:\tlearn: 0.9666945\ttotal: 23m 19s\tremaining: 4h 8m 33s\n",
      "193:\tlearn: 0.9592794\ttotal: 23m 25s\tremaining: 4h 8m 16s\n",
      "194:\tlearn: 0.9526775\ttotal: 23m 32s\tremaining: 4h 8m\n",
      "195:\tlearn: 0.9448009\ttotal: 23m 38s\tremaining: 4h 7m 44s\n",
      "196:\tlearn: 0.9383152\ttotal: 23m 44s\tremaining: 4h 7m 26s\n",
      "197:\tlearn: 0.9300443\ttotal: 23m 51s\tremaining: 4h 7m 11s\n",
      "198:\tlearn: 0.9226533\ttotal: 23m 57s\tremaining: 4h 6m 55s\n",
      "199:\tlearn: 0.9151048\ttotal: 24m 3s\tremaining: 4h 6m 40s\n",
      "200:\tlearn: 0.9086107\ttotal: 24m 10s\tremaining: 4h 6m 24s\n",
      "201:\tlearn: 0.9013963\ttotal: 24m 16s\tremaining: 4h 6m 9s\n",
      "202:\tlearn: 0.8943806\ttotal: 24m 23s\tremaining: 4h 5m 54s\n",
      "203:\tlearn: 0.8871529\ttotal: 24m 29s\tremaining: 4h 5m 38s\n",
      "204:\tlearn: 0.8799211\ttotal: 24m 36s\tremaining: 4h 5m 24s\n",
      "205:\tlearn: 0.8716624\ttotal: 24m 42s\tremaining: 4h 5m 9s\n",
      "206:\tlearn: 0.8639135\ttotal: 24m 48s\tremaining: 4h 4m 53s\n",
      "207:\tlearn: 0.8564965\ttotal: 24m 55s\tremaining: 4h 4m 39s\n",
      "208:\tlearn: 0.8503069\ttotal: 25m 1s\tremaining: 4h 4m 23s\n",
      "209:\tlearn: 0.8443019\ttotal: 25m 8s\tremaining: 4h 4m 10s\n",
      "210:\tlearn: 0.8376010\ttotal: 25m 14s\tremaining: 4h 3m 54s\n",
      "211:\tlearn: 0.8318027\ttotal: 25m 20s\tremaining: 4h 3m 38s\n",
      "212:\tlearn: 0.8248519\ttotal: 25m 27s\tremaining: 4h 3m 24s\n",
      "213:\tlearn: 0.8179376\ttotal: 25m 33s\tremaining: 4h 3m 9s\n",
      "214:\tlearn: 0.8117997\ttotal: 25m 39s\tremaining: 4h 2m 55s\n",
      "215:\tlearn: 0.8052673\ttotal: 25m 46s\tremaining: 4h 2m 41s\n",
      "216:\tlearn: 0.7990688\ttotal: 25m 52s\tremaining: 4h 2m 26s\n",
      "217:\tlearn: 0.7930062\ttotal: 25m 59s\tremaining: 4h 2m 13s\n",
      "218:\tlearn: 0.7874064\ttotal: 26m 5s\tremaining: 4h 1m 59s\n",
      "219:\tlearn: 0.7803287\ttotal: 26m 12s\tremaining: 4h 1m 45s\n",
      "220:\tlearn: 0.7749549\ttotal: 26m 18s\tremaining: 4h 1m 30s\n",
      "221:\tlearn: 0.7692611\ttotal: 26m 24s\tremaining: 4h 1m 16s\n",
      "222:\tlearn: 0.7635096\ttotal: 26m 31s\tremaining: 4h 1m 3s\n",
      "223:\tlearn: 0.7579039\ttotal: 26m 37s\tremaining: 4h 48s\n",
      "224:\tlearn: 0.7526478\ttotal: 26m 43s\tremaining: 4h 35s\n",
      "225:\tlearn: 0.7480595\ttotal: 26m 50s\tremaining: 4h 21s\n",
      "226:\tlearn: 0.7447565\ttotal: 26m 56s\tremaining: 4h 6s\n",
      "227:\tlearn: 0.7387254\ttotal: 27m 3s\tremaining: 3h 59m 54s\n",
      "228:\tlearn: 0.7323540\ttotal: 27m 9s\tremaining: 3h 59m 39s\n",
      "229:\tlearn: 0.7268882\ttotal: 27m 15s\tremaining: 3h 59m 27s\n",
      "230:\tlearn: 0.7212493\ttotal: 27m 22s\tremaining: 3h 59m 14s\n",
      "231:\tlearn: 0.7172000\ttotal: 27m 28s\tremaining: 3h 58m 59s\n",
      "232:\tlearn: 0.7112665\ttotal: 27m 35s\tremaining: 3h 58m 46s\n",
      "233:\tlearn: 0.7053807\ttotal: 27m 41s\tremaining: 3h 58m 33s\n",
      "234:\tlearn: 0.6999251\ttotal: 27m 47s\tremaining: 3h 58m 20s\n",
      "235:\tlearn: 0.6944051\ttotal: 27m 54s\tremaining: 3h 58m 6s\n",
      "236:\tlearn: 0.6881502\ttotal: 28m\tremaining: 3h 57m 52s\n",
      "237:\tlearn: 0.6833632\ttotal: 28m 6s\tremaining: 3h 57m 40s\n",
      "238:\tlearn: 0.6780693\ttotal: 28m 13s\tremaining: 3h 57m 26s\n",
      "239:\tlearn: 0.6731048\ttotal: 28m 19s\tremaining: 3h 57m 14s\n",
      "240:\tlearn: 0.6692131\ttotal: 28m 25s\tremaining: 3h 57m\n",
      "241:\tlearn: 0.6641265\ttotal: 28m 32s\tremaining: 3h 56m 49s\n",
      "242:\tlearn: 0.6584893\ttotal: 28m 39s\tremaining: 3h 56m 38s\n",
      "243:\tlearn: 0.6541266\ttotal: 28m 45s\tremaining: 3h 56m 24s\n",
      "244:\tlearn: 0.6477532\ttotal: 28m 51s\tremaining: 3h 56m 12s\n",
      "245:\tlearn: 0.6428018\ttotal: 28m 58s\tremaining: 3h 56m\n",
      "246:\tlearn: 0.6379615\ttotal: 29m 4s\tremaining: 3h 55m 46s\n",
      "247:\tlearn: 0.6324905\ttotal: 29m 10s\tremaining: 3h 55m 34s\n",
      "248:\tlearn: 0.6289055\ttotal: 29m 17s\tremaining: 3h 55m 21s\n",
      "249:\tlearn: 0.6245916\ttotal: 29m 23s\tremaining: 3h 55m 9s\n",
      "250:\tlearn: 0.6191606\ttotal: 29m 30s\tremaining: 3h 54m 56s\n",
      "251:\tlearn: 0.6144371\ttotal: 29m 36s\tremaining: 3h 54m 43s\n",
      "252:\tlearn: 0.6109821\ttotal: 29m 42s\tremaining: 3h 54m 32s\n",
      "253:\tlearn: 0.6063433\ttotal: 29m 49s\tremaining: 3h 54m 19s\n",
      "254:\tlearn: 0.6016606\ttotal: 29m 55s\tremaining: 3h 54m 7s\n",
      "255:\tlearn: 0.5964324\ttotal: 30m 1s\tremaining: 3h 53m 54s\n",
      "256:\tlearn: 0.5915013\ttotal: 30m 8s\tremaining: 3h 53m 42s\n",
      "257:\tlearn: 0.5880349\ttotal: 30m 14s\tremaining: 3h 53m 30s\n",
      "258:\tlearn: 0.5834242\ttotal: 30m 20s\tremaining: 3h 53m 17s\n",
      "259:\tlearn: 0.5784775\ttotal: 30m 27s\tremaining: 3h 53m 5s\n",
      "260:\tlearn: 0.5738700\ttotal: 30m 33s\tremaining: 3h 52m 53s\n",
      "261:\tlearn: 0.5701997\ttotal: 30m 39s\tremaining: 3h 52m 41s\n",
      "262:\tlearn: 0.5657357\ttotal: 30m 46s\tremaining: 3h 52m 30s\n",
      "263:\tlearn: 0.5611312\ttotal: 30m 52s\tremaining: 3h 52m 17s\n",
      "264:\tlearn: 0.5577003\ttotal: 30m 59s\tremaining: 3h 52m 6s\n",
      "265:\tlearn: 0.5534854\ttotal: 31m 5s\tremaining: 3h 51m 54s\n",
      "266:\tlearn: 0.5510138\ttotal: 31m 11s\tremaining: 3h 51m 42s\n",
      "267:\tlearn: 0.5459884\ttotal: 31m 18s\tremaining: 3h 51m 31s\n",
      "268:\tlearn: 0.5424630\ttotal: 31m 24s\tremaining: 3h 51m 19s\n",
      "269:\tlearn: 0.5381933\ttotal: 31m 30s\tremaining: 3h 51m 7s\n",
      "270:\tlearn: 0.5334749\ttotal: 31m 37s\tremaining: 3h 50m 55s\n",
      "271:\tlearn: 0.5306151\ttotal: 31m 43s\tremaining: 3h 50m 43s\n",
      "272:\tlearn: 0.5269348\ttotal: 31m 50s\tremaining: 3h 50m 33s\n",
      "273:\tlearn: 0.5226034\ttotal: 31m 56s\tremaining: 3h 50m 21s\n",
      "274:\tlearn: 0.5185575\ttotal: 32m 2s\tremaining: 3h 50m 9s\n",
      "275:\tlearn: 0.5144969\ttotal: 32m 9s\tremaining: 3h 49m 58s\n",
      "276:\tlearn: 0.5123347\ttotal: 32m 15s\tremaining: 3h 49m 46s\n",
      "277:\tlearn: 0.5081324\ttotal: 32m 22s\tremaining: 3h 49m 35s\n",
      "278:\tlearn: 0.5053722\ttotal: 32m 28s\tremaining: 3h 49m 24s\n",
      "279:\tlearn: 0.5010264\ttotal: 32m 34s\tremaining: 3h 49m 13s\n",
      "280:\tlearn: 0.4978441\ttotal: 32m 41s\tremaining: 3h 49m 2s\n",
      "281:\tlearn: 0.4939871\ttotal: 32m 47s\tremaining: 3h 48m 50s\n",
      "282:\tlearn: 0.4917316\ttotal: 32m 53s\tremaining: 3h 48m 40s\n",
      "283:\tlearn: 0.4878847\ttotal: 33m\tremaining: 3h 48m 28s\n",
      "284:\tlearn: 0.4844660\ttotal: 33m 6s\tremaining: 3h 48m 17s\n",
      "285:\tlearn: 0.4807007\ttotal: 33m 12s\tremaining: 3h 48m 6s\n",
      "286:\tlearn: 0.4763305\ttotal: 33m 19s\tremaining: 3h 47m 54s\n",
      "287:\tlearn: 0.4725527\ttotal: 33m 25s\tremaining: 3h 47m 44s\n",
      "288:\tlearn: 0.4690617\ttotal: 33m 32s\tremaining: 3h 47m 32s\n",
      "289:\tlearn: 0.4654976\ttotal: 33m 38s\tremaining: 3h 47m 21s\n",
      "290:\tlearn: 0.4627091\ttotal: 33m 44s\tremaining: 3h 47m 10s\n",
      "291:\tlearn: 0.4596970\ttotal: 33m 51s\tremaining: 3h 46m 59s\n",
      "292:\tlearn: 0.4560212\ttotal: 33m 57s\tremaining: 3h 46m 49s\n",
      "293:\tlearn: 0.4525751\ttotal: 34m 3s\tremaining: 3h 46m 38s\n",
      "294:\tlearn: 0.4490254\ttotal: 34m 10s\tremaining: 3h 46m 27s\n",
      "295:\tlearn: 0.4462012\ttotal: 34m 16s\tremaining: 3h 46m 17s\n",
      "296:\tlearn: 0.4431473\ttotal: 34m 22s\tremaining: 3h 46m 5s\n",
      "297:\tlearn: 0.4399172\ttotal: 34m 29s\tremaining: 3h 45m 55s\n",
      "298:\tlearn: 0.4370087\ttotal: 34m 35s\tremaining: 3h 45m 44s\n",
      "299:\tlearn: 0.4340132\ttotal: 34m 42s\tremaining: 3h 45m 33s\n",
      "300:\tlearn: 0.4308039\ttotal: 34m 48s\tremaining: 3h 45m 23s\n",
      "301:\tlearn: 0.4276617\ttotal: 34m 54s\tremaining: 3h 45m 11s\n",
      "302:\tlearn: 0.4248973\ttotal: 35m 1s\tremaining: 3h 45m 2s\n",
      "303:\tlearn: 0.4227788\ttotal: 35m 7s\tremaining: 3h 44m 51s\n",
      "304:\tlearn: 0.4195673\ttotal: 35m 13s\tremaining: 3h 44m 40s\n",
      "305:\tlearn: 0.4168267\ttotal: 35m 20s\tremaining: 3h 44m 30s\n",
      "306:\tlearn: 0.4139144\ttotal: 35m 26s\tremaining: 3h 44m 19s\n",
      "307:\tlearn: 0.4118188\ttotal: 35m 33s\tremaining: 3h 44m 10s\n",
      "308:\tlearn: 0.4102361\ttotal: 35m 39s\tremaining: 3h 43m 59s\n",
      "309:\tlearn: 0.4073191\ttotal: 35m 45s\tremaining: 3h 43m 48s\n",
      "310:\tlearn: 0.4049079\ttotal: 35m 52s\tremaining: 3h 43m 38s\n",
      "311:\tlearn: 0.4020780\ttotal: 35m 58s\tremaining: 3h 43m 28s\n",
      "312:\tlearn: 0.3990599\ttotal: 36m 5s\tremaining: 3h 43m 18s\n",
      "313:\tlearn: 0.3976590\ttotal: 36m 11s\tremaining: 3h 43m 7s\n",
      "314:\tlearn: 0.3951195\ttotal: 36m 17s\tremaining: 3h 42m 57s\n",
      "315:\tlearn: 0.3936422\ttotal: 36m 24s\tremaining: 3h 42m 47s\n",
      "316:\tlearn: 0.3908497\ttotal: 36m 30s\tremaining: 3h 42m 36s\n",
      "317:\tlearn: 0.3886951\ttotal: 36m 36s\tremaining: 3h 42m 27s\n",
      "318:\tlearn: 0.3858735\ttotal: 36m 43s\tremaining: 3h 42m 17s\n",
      "319:\tlearn: 0.3835832\ttotal: 36m 49s\tremaining: 3h 42m 8s\n",
      "320:\tlearn: 0.3809108\ttotal: 36m 56s\tremaining: 3h 41m 59s\n",
      "321:\tlearn: 0.3780363\ttotal: 37m 2s\tremaining: 3h 41m 48s\n",
      "322:\tlearn: 0.3758218\ttotal: 37m 9s\tremaining: 3h 41m 38s\n",
      "323:\tlearn: 0.3729209\ttotal: 37m 15s\tremaining: 3h 41m 28s\n",
      "324:\tlearn: 0.3701148\ttotal: 37m 21s\tremaining: 3h 41m 17s\n",
      "325:\tlearn: 0.3688158\ttotal: 37m 28s\tremaining: 3h 41m 7s\n",
      "326:\tlearn: 0.3665589\ttotal: 37m 34s\tremaining: 3h 40m 57s\n",
      "327:\tlearn: 0.3638326\ttotal: 37m 40s\tremaining: 3h 40m 48s\n",
      "328:\tlearn: 0.3615913\ttotal: 37m 47s\tremaining: 3h 40m 37s\n",
      "329:\tlearn: 0.3596106\ttotal: 37m 53s\tremaining: 3h 40m 27s\n",
      "330:\tlearn: 0.3575570\ttotal: 37m 59s\tremaining: 3h 40m 17s\n",
      "331:\tlearn: 0.3558032\ttotal: 38m 6s\tremaining: 3h 40m 7s\n",
      "332:\tlearn: 0.3532001\ttotal: 38m 12s\tremaining: 3h 39m 58s\n",
      "333:\tlearn: 0.3511010\ttotal: 38m 18s\tremaining: 3h 39m 48s\n",
      "334:\tlearn: 0.3487137\ttotal: 38m 25s\tremaining: 3h 39m 37s\n",
      "335:\tlearn: 0.3467158\ttotal: 38m 31s\tremaining: 3h 39m 29s\n",
      "336:\tlearn: 0.3453392\ttotal: 38m 39s\tremaining: 3h 39m 24s\n",
      "337:\tlearn: 0.3430633\ttotal: 38m 46s\tremaining: 3h 39m 18s\n",
      "338:\tlearn: 0.3409228\ttotal: 38m 52s\tremaining: 3h 39m 8s\n",
      "339:\tlearn: 0.3400880\ttotal: 38m 59s\tremaining: 3h 38m 59s\n",
      "340:\tlearn: 0.3382486\ttotal: 39m 5s\tremaining: 3h 38m 51s\n",
      "341:\tlearn: 0.3363828\ttotal: 39m 11s\tremaining: 3h 38m 41s\n",
      "342:\tlearn: 0.3347280\ttotal: 39m 18s\tremaining: 3h 38m 32s\n",
      "343:\tlearn: 0.3335855\ttotal: 39m 24s\tremaining: 3h 38m 22s\n",
      "344:\tlearn: 0.3321629\ttotal: 39m 31s\tremaining: 3h 38m 12s\n",
      "345:\tlearn: 0.3311455\ttotal: 39m 37s\tremaining: 3h 38m 3s\n",
      "346:\tlearn: 0.3296863\ttotal: 39m 43s\tremaining: 3h 37m 53s\n",
      "347:\tlearn: 0.3278974\ttotal: 39m 50s\tremaining: 3h 37m 44s\n",
      "348:\tlearn: 0.3267777\ttotal: 39m 56s\tremaining: 3h 37m 34s\n",
      "349:\tlearn: 0.3252832\ttotal: 40m 2s\tremaining: 3h 37m 23s\n",
      "350:\tlearn: 0.3236688\ttotal: 40m 9s\tremaining: 3h 37m 14s\n",
      "351:\tlearn: 0.3215954\ttotal: 40m 15s\tremaining: 3h 37m 4s\n",
      "352:\tlearn: 0.3201211\ttotal: 40m 22s\tremaining: 3h 36m 55s\n",
      "353:\tlearn: 0.3182783\ttotal: 40m 28s\tremaining: 3h 36m 45s\n",
      "354:\tlearn: 0.3170350\ttotal: 40m 34s\tremaining: 3h 36m 35s\n",
      "355:\tlearn: 0.3156330\ttotal: 40m 41s\tremaining: 3h 36m 27s\n",
      "356:\tlearn: 0.3138445\ttotal: 40m 47s\tremaining: 3h 36m 17s\n",
      "357:\tlearn: 0.3128957\ttotal: 40m 53s\tremaining: 3h 36m 9s\n",
      "358:\tlearn: 0.3111594\ttotal: 41m\tremaining: 3h 35m 59s\n",
      "359:\tlearn: 0.3101539\ttotal: 41m 6s\tremaining: 3h 35m 49s\n",
      "360:\tlearn: 0.3082177\ttotal: 41m 13s\tremaining: 3h 35m 40s\n",
      "361:\tlearn: 0.3072830\ttotal: 41m 19s\tremaining: 3h 35m 30s\n",
      "362:\tlearn: 0.3058241\ttotal: 41m 25s\tremaining: 3h 35m 21s\n",
      "363:\tlearn: 0.3041581\ttotal: 41m 32s\tremaining: 3h 35m 12s\n",
      "364:\tlearn: 0.3022645\ttotal: 41m 38s\tremaining: 3h 35m 2s\n",
      "365:\tlearn: 0.3006460\ttotal: 41m 44s\tremaining: 3h 34m 53s\n",
      "366:\tlearn: 0.2993106\ttotal: 41m 51s\tremaining: 3h 34m 43s\n",
      "367:\tlearn: 0.2976203\ttotal: 41m 57s\tremaining: 3h 34m 35s\n",
      "368:\tlearn: 0.2957241\ttotal: 42m 3s\tremaining: 3h 34m 25s\n",
      "369:\tlearn: 0.2944849\ttotal: 42m 10s\tremaining: 3h 34m 15s\n",
      "370:\tlearn: 0.2925922\ttotal: 42m 16s\tremaining: 3h 34m 6s\n",
      "371:\tlearn: 0.2912826\ttotal: 42m 22s\tremaining: 3h 33m 57s\n",
      "372:\tlearn: 0.2904939\ttotal: 42m 29s\tremaining: 3h 33m 49s\n",
      "373:\tlearn: 0.2893607\ttotal: 42m 35s\tremaining: 3h 33m 39s\n",
      "374:\tlearn: 0.2879818\ttotal: 42m 41s\tremaining: 3h 33m 29s\n",
      "375:\tlearn: 0.2867142\ttotal: 42m 48s\tremaining: 3h 33m 21s\n",
      "376:\tlearn: 0.2861444\ttotal: 42m 54s\tremaining: 3h 33m 11s\n",
      "377:\tlearn: 0.2849704\ttotal: 43m 1s\tremaining: 3h 33m 3s\n",
      "378:\tlearn: 0.2832369\ttotal: 43m 7s\tremaining: 3h 32m 53s\n",
      "379:\tlearn: 0.2819178\ttotal: 43m 13s\tremaining: 3h 32m 44s\n",
      "380:\tlearn: 0.2802982\ttotal: 43m 20s\tremaining: 3h 32m 35s\n",
      "381:\tlearn: 0.2786686\ttotal: 43m 26s\tremaining: 3h 32m 26s\n",
      "382:\tlearn: 0.2772479\ttotal: 43m 33s\tremaining: 3h 32m 17s\n",
      "383:\tlearn: 0.2758201\ttotal: 43m 39s\tremaining: 3h 32m 8s\n",
      "384:\tlearn: 0.2744376\ttotal: 43m 45s\tremaining: 3h 31m 58s\n",
      "385:\tlearn: 0.2735925\ttotal: 43m 52s\tremaining: 3h 31m 50s\n",
      "386:\tlearn: 0.2720973\ttotal: 43m 58s\tremaining: 3h 31m 41s\n",
      "387:\tlearn: 0.2711084\ttotal: 44m 4s\tremaining: 3h 31m 32s\n",
      "388:\tlearn: 0.2696651\ttotal: 44m 11s\tremaining: 3h 31m 23s\n",
      "389:\tlearn: 0.2688000\ttotal: 44m 17s\tremaining: 3h 31m 14s\n",
      "390:\tlearn: 0.2673809\ttotal: 44m 23s\tremaining: 3h 31m 5s\n",
      "391:\tlearn: 0.2665483\ttotal: 44m 30s\tremaining: 3h 30m 56s\n",
      "392:\tlearn: 0.2650881\ttotal: 44m 36s\tremaining: 3h 30m 47s\n",
      "393:\tlearn: 0.2635732\ttotal: 44m 42s\tremaining: 3h 30m 38s\n",
      "394:\tlearn: 0.2623243\ttotal: 44m 49s\tremaining: 3h 30m 29s\n",
      "395:\tlearn: 0.2609472\ttotal: 44m 55s\tremaining: 3h 30m 20s\n",
      "396:\tlearn: 0.2598995\ttotal: 45m 1s\tremaining: 3h 30m 11s\n",
      "397:\tlearn: 0.2586655\ttotal: 45m 8s\tremaining: 3h 30m 3s\n",
      "398:\tlearn: 0.2572307\ttotal: 45m 14s\tremaining: 3h 29m 54s\n",
      "399:\tlearn: 0.2559742\ttotal: 45m 21s\tremaining: 3h 29m 44s\n",
      "400:\tlearn: 0.2550268\ttotal: 45m 27s\tremaining: 3h 29m 36s\n",
      "401:\tlearn: 0.2540605\ttotal: 45m 33s\tremaining: 3h 29m 27s\n",
      "402:\tlearn: 0.2531315\ttotal: 45m 40s\tremaining: 3h 29m 18s\n",
      "403:\tlearn: 0.2521369\ttotal: 45m 46s\tremaining: 3h 29m 9s\n",
      "404:\tlearn: 0.2513435\ttotal: 45m 52s\tremaining: 3h 29m\n",
      "405:\tlearn: 0.2499221\ttotal: 45m 59s\tremaining: 3h 28m 52s\n",
      "406:\tlearn: 0.2486740\ttotal: 46m 5s\tremaining: 3h 28m 42s\n",
      "407:\tlearn: 0.2473707\ttotal: 46m 11s\tremaining: 3h 28m 34s\n",
      "408:\tlearn: 0.2462846\ttotal: 46m 18s\tremaining: 3h 28m 25s\n",
      "409:\tlearn: 0.2451501\ttotal: 46m 24s\tremaining: 3h 28m 16s\n",
      "410:\tlearn: 0.2439666\ttotal: 46m 31s\tremaining: 3h 28m 8s\n",
      "411:\tlearn: 0.2431361\ttotal: 46m 37s\tremaining: 3h 27m 58s\n",
      "412:\tlearn: 0.2421219\ttotal: 46m 43s\tremaining: 3h 27m 50s\n",
      "413:\tlearn: 0.2413663\ttotal: 46m 49s\tremaining: 3h 27m 41s\n",
      "414:\tlearn: 0.2409211\ttotal: 46m 56s\tremaining: 3h 27m 32s\n",
      "415:\tlearn: 0.2397383\ttotal: 47m 2s\tremaining: 3h 27m 24s\n",
      "416:\tlearn: 0.2384187\ttotal: 47m 9s\tremaining: 3h 27m 15s\n",
      "417:\tlearn: 0.2369333\ttotal: 47m 15s\tremaining: 3h 27m 7s\n",
      "418:\tlearn: 0.2361421\ttotal: 47m 21s\tremaining: 3h 26m 58s\n",
      "419:\tlearn: 0.2356939\ttotal: 47m 28s\tremaining: 3h 26m 49s\n",
      "420:\tlearn: 0.2344456\ttotal: 47m 34s\tremaining: 3h 26m 42s\n",
      "421:\tlearn: 0.2334438\ttotal: 47m 40s\tremaining: 3h 26m 32s\n",
      "422:\tlearn: 0.2324714\ttotal: 47m 47s\tremaining: 3h 26m 24s\n",
      "423:\tlearn: 0.2316193\ttotal: 47m 53s\tremaining: 3h 26m 15s\n",
      "424:\tlearn: 0.2303479\ttotal: 47m 59s\tremaining: 3h 26m 6s\n",
      "425:\tlearn: 0.2290864\ttotal: 48m 6s\tremaining: 3h 25m 58s\n",
      "426:\tlearn: 0.2284035\ttotal: 48m 12s\tremaining: 3h 25m 49s\n",
      "427:\tlearn: 0.2271294\ttotal: 48m 18s\tremaining: 3h 25m 40s\n",
      "428:\tlearn: 0.2261463\ttotal: 48m 25s\tremaining: 3h 25m 32s\n",
      "429:\tlearn: 0.2256122\ttotal: 48m 31s\tremaining: 3h 25m 23s\n",
      "430:\tlearn: 0.2249047\ttotal: 48m 38s\tremaining: 3h 25m 15s\n",
      "431:\tlearn: 0.2239574\ttotal: 48m 44s\tremaining: 3h 25m 7s\n",
      "432:\tlearn: 0.2230541\ttotal: 48m 50s\tremaining: 3h 24m 58s\n",
      "433:\tlearn: 0.2223641\ttotal: 48m 57s\tremaining: 3h 24m 50s\n",
      "434:\tlearn: 0.2214047\ttotal: 49m 3s\tremaining: 3h 24m 41s\n",
      "435:\tlearn: 0.2208136\ttotal: 49m 10s\tremaining: 3h 24m 33s\n",
      "436:\tlearn: 0.2196249\ttotal: 49m 16s\tremaining: 3h 24m 25s\n",
      "437:\tlearn: 0.2188531\ttotal: 49m 22s\tremaining: 3h 24m 16s\n",
      "438:\tlearn: 0.2180182\ttotal: 49m 29s\tremaining: 3h 24m 8s\n",
      "439:\tlearn: 0.2179138\ttotal: 49m 35s\tremaining: 3h 23m 59s\n",
      "440:\tlearn: 0.2174372\ttotal: 49m 41s\tremaining: 3h 23m 51s\n",
      "441:\tlearn: 0.2167218\ttotal: 49m 48s\tremaining: 3h 23m 42s\n",
      "442:\tlearn: 0.2158473\ttotal: 49m 54s\tremaining: 3h 23m 34s\n",
      "443:\tlearn: 0.2147338\ttotal: 50m\tremaining: 3h 23m 26s\n",
      "444:\tlearn: 0.2138021\ttotal: 50m 7s\tremaining: 3h 23m 17s\n",
      "445:\tlearn: 0.2126467\ttotal: 50m 13s\tremaining: 3h 23m 10s\n",
      "446:\tlearn: 0.2121413\ttotal: 50m 20s\tremaining: 3h 23m 1s\n",
      "447:\tlearn: 0.2111706\ttotal: 50m 26s\tremaining: 3h 22m 52s\n",
      "448:\tlearn: 0.2102275\ttotal: 50m 32s\tremaining: 3h 22m 44s\n",
      "449:\tlearn: 0.2091076\ttotal: 50m 39s\tremaining: 3h 22m 36s\n",
      "450:\tlearn: 0.2080682\ttotal: 50m 45s\tremaining: 3h 22m 28s\n",
      "451:\tlearn: 0.2071233\ttotal: 50m 51s\tremaining: 3h 22m 20s\n",
      "452:\tlearn: 0.2066222\ttotal: 50m 58s\tremaining: 3h 22m 11s\n",
      "453:\tlearn: 0.2061032\ttotal: 51m 4s\tremaining: 3h 22m 3s\n",
      "454:\tlearn: 0.2052207\ttotal: 51m 10s\tremaining: 3h 21m 54s\n",
      "455:\tlearn: 0.2043808\ttotal: 51m 17s\tremaining: 3h 21m 47s\n",
      "456:\tlearn: 0.2035809\ttotal: 51m 23s\tremaining: 3h 21m 38s\n",
      "457:\tlearn: 0.2026232\ttotal: 51m 29s\tremaining: 3h 21m 30s\n",
      "458:\tlearn: 0.2019779\ttotal: 51m 36s\tremaining: 3h 21m 22s\n",
      "459:\tlearn: 0.2012303\ttotal: 51m 42s\tremaining: 3h 21m 13s\n",
      "460:\tlearn: 0.2006437\ttotal: 51m 49s\tremaining: 3h 21m 6s\n",
      "461:\tlearn: 0.1997986\ttotal: 51m 55s\tremaining: 3h 20m 57s\n",
      "462:\tlearn: 0.1993640\ttotal: 52m 1s\tremaining: 3h 20m 49s\n",
      "463:\tlearn: 0.1985611\ttotal: 52m 8s\tremaining: 3h 20m 41s\n",
      "464:\tlearn: 0.1979302\ttotal: 52m 14s\tremaining: 3h 20m 33s\n",
      "465:\tlearn: 0.1973185\ttotal: 52m 21s\tremaining: 3h 20m 25s\n",
      "466:\tlearn: 0.1967642\ttotal: 52m 27s\tremaining: 3h 20m 17s\n",
      "467:\tlearn: 0.1962827\ttotal: 52m 33s\tremaining: 3h 20m 8s\n",
      "468:\tlearn: 0.1955348\ttotal: 52m 40s\tremaining: 3h 20m 1s\n",
      "469:\tlearn: 0.1948483\ttotal: 52m 46s\tremaining: 3h 19m 52s\n",
      "470:\tlearn: 0.1940584\ttotal: 52m 53s\tremaining: 3h 19m 44s\n",
      "471:\tlearn: 0.1933885\ttotal: 52m 59s\tremaining: 3h 19m 36s\n",
      "472:\tlearn: 0.1926620\ttotal: 53m 5s\tremaining: 3h 19m 28s\n",
      "473:\tlearn: 0.1920158\ttotal: 53m 12s\tremaining: 3h 19m 20s\n",
      "474:\tlearn: 0.1910192\ttotal: 53m 18s\tremaining: 3h 19m 12s\n",
      "475:\tlearn: 0.1902774\ttotal: 53m 24s\tremaining: 3h 19m 4s\n",
      "476:\tlearn: 0.1897346\ttotal: 53m 31s\tremaining: 3h 18m 56s\n",
      "477:\tlearn: 0.1895325\ttotal: 53m 37s\tremaining: 3h 18m 47s\n",
      "478:\tlearn: 0.1887886\ttotal: 53m 43s\tremaining: 3h 18m 40s\n",
      "479:\tlearn: 0.1881631\ttotal: 53m 50s\tremaining: 3h 18m 31s\n",
      "480:\tlearn: 0.1874919\ttotal: 53m 56s\tremaining: 3h 18m 24s\n",
      "481:\tlearn: 0.1867174\ttotal: 54m 3s\tremaining: 3h 18m 15s\n",
      "482:\tlearn: 0.1858850\ttotal: 54m 9s\tremaining: 3h 18m 7s\n",
      "483:\tlearn: 0.1853921\ttotal: 54m 15s\tremaining: 3h 17m 59s\n",
      "484:\tlearn: 0.1847824\ttotal: 54m 21s\tremaining: 3h 17m 50s\n",
      "485:\tlearn: 0.1842135\ttotal: 54m 28s\tremaining: 3h 17m 43s\n",
      "486:\tlearn: 0.1834926\ttotal: 54m 34s\tremaining: 3h 17m 35s\n",
      "487:\tlearn: 0.1828883\ttotal: 54m 41s\tremaining: 3h 17m 26s\n",
      "488:\tlearn: 0.1821842\ttotal: 54m 47s\tremaining: 3h 17m 19s\n",
      "489:\tlearn: 0.1815495\ttotal: 54m 53s\tremaining: 3h 17m 10s\n",
      "490:\tlearn: 0.1808072\ttotal: 55m\tremaining: 3h 17m 2s\n",
      "491:\tlearn: 0.1801013\ttotal: 55m 6s\tremaining: 3h 16m 54s\n",
      "492:\tlearn: 0.1793477\ttotal: 55m 12s\tremaining: 3h 16m 46s\n",
      "493:\tlearn: 0.1787438\ttotal: 55m 19s\tremaining: 3h 16m 39s\n",
      "494:\tlearn: 0.1787031\ttotal: 55m 25s\tremaining: 3h 16m 31s\n",
      "495:\tlearn: 0.1780047\ttotal: 55m 32s\tremaining: 3h 16m 24s\n",
      "496:\tlearn: 0.1775164\ttotal: 55m 38s\tremaining: 3h 16m 16s\n",
      "497:\tlearn: 0.1768485\ttotal: 55m 45s\tremaining: 3h 16m 7s\n",
      "498:\tlearn: 0.1760289\ttotal: 55m 51s\tremaining: 3h 16m\n",
      "499:\tlearn: 0.1755268\ttotal: 55m 57s\tremaining: 3h 15m 52s\n",
      "500:\tlearn: 0.1748760\ttotal: 56m 4s\tremaining: 3h 15m 44s\n",
      "501:\tlearn: 0.1742461\ttotal: 56m 10s\tremaining: 3h 15m 36s\n",
      "502:\tlearn: 0.1738908\ttotal: 56m 16s\tremaining: 3h 15m 28s\n",
      "503:\tlearn: 0.1731832\ttotal: 56m 23s\tremaining: 3h 15m 21s\n",
      "504:\tlearn: 0.1725644\ttotal: 56m 29s\tremaining: 3h 15m 12s\n",
      "505:\tlearn: 0.1721200\ttotal: 56m 35s\tremaining: 3h 15m 4s\n",
      "506:\tlearn: 0.1714399\ttotal: 56m 42s\tremaining: 3h 14m 56s\n",
      "507:\tlearn: 0.1709264\ttotal: 56m 48s\tremaining: 3h 14m 48s\n",
      "508:\tlearn: 0.1702233\ttotal: 56m 55s\tremaining: 3h 14m 41s\n",
      "509:\tlearn: 0.1696188\ttotal: 57m 1s\tremaining: 3h 14m 32s\n",
      "510:\tlearn: 0.1690506\ttotal: 57m 7s\tremaining: 3h 14m 24s\n",
      "511:\tlearn: 0.1683434\ttotal: 57m 14s\tremaining: 3h 14m 17s\n",
      "512:\tlearn: 0.1679657\ttotal: 57m 20s\tremaining: 3h 14m 9s\n",
      "513:\tlearn: 0.1674346\ttotal: 57m 26s\tremaining: 3h 14m 1s\n",
      "514:\tlearn: 0.1670290\ttotal: 57m 33s\tremaining: 3h 13m 53s\n",
      "515:\tlearn: 0.1664292\ttotal: 57m 39s\tremaining: 3h 13m 45s\n",
      "516:\tlearn: 0.1658049\ttotal: 57m 45s\tremaining: 3h 13m 37s\n",
      "517:\tlearn: 0.1650825\ttotal: 57m 52s\tremaining: 3h 13m 29s\n",
      "518:\tlearn: 0.1646760\ttotal: 57m 58s\tremaining: 3h 13m 22s\n",
      "519:\tlearn: 0.1642868\ttotal: 58m 4s\tremaining: 3h 13m 14s\n",
      "520:\tlearn: 0.1637752\ttotal: 58m 11s\tremaining: 3h 13m 6s\n",
      "521:\tlearn: 0.1631744\ttotal: 58m 17s\tremaining: 3h 12m 59s\n",
      "522:\tlearn: 0.1625306\ttotal: 58m 24s\tremaining: 3h 12m 51s\n",
      "523:\tlearn: 0.1619473\ttotal: 58m 30s\tremaining: 3h 12m 43s\n",
      "524:\tlearn: 0.1616153\ttotal: 58m 36s\tremaining: 3h 12m 35s\n",
      "525:\tlearn: 0.1610862\ttotal: 58m 43s\tremaining: 3h 12m 27s\n",
      "526:\tlearn: 0.1605508\ttotal: 58m 49s\tremaining: 3h 12m 20s\n",
      "527:\tlearn: 0.1601360\ttotal: 58m 55s\tremaining: 3h 12m 12s\n",
      "528:\tlearn: 0.1597148\ttotal: 59m 2s\tremaining: 3h 12m 4s\n",
      "529:\tlearn: 0.1591127\ttotal: 59m 8s\tremaining: 3h 11m 56s\n",
      "530:\tlearn: 0.1585451\ttotal: 59m 14s\tremaining: 3h 11m 48s\n",
      "531:\tlearn: 0.1579539\ttotal: 59m 21s\tremaining: 3h 11m 41s\n",
      "532:\tlearn: 0.1576345\ttotal: 59m 27s\tremaining: 3h 11m 33s\n",
      "533:\tlearn: 0.1569886\ttotal: 59m 34s\tremaining: 3h 11m 26s\n",
      "534:\tlearn: 0.1563547\ttotal: 59m 40s\tremaining: 3h 11m 18s\n",
      "535:\tlearn: 0.1558534\ttotal: 59m 46s\tremaining: 3h 11m 10s\n",
      "536:\tlearn: 0.1553174\ttotal: 59m 53s\tremaining: 3h 11m 2s\n",
      "537:\tlearn: 0.1547264\ttotal: 59m 59s\tremaining: 3h 10m 54s\n",
      "538:\tlearn: 0.1541183\ttotal: 1h 6s\tremaining: 3h 10m 47s\n",
      "539:\tlearn: 0.1534562\ttotal: 1h 12s\tremaining: 3h 10m 39s\n",
      "540:\tlearn: 0.1528907\ttotal: 1h 18s\tremaining: 3h 10m 31s\n",
      "541:\tlearn: 0.1523382\ttotal: 1h 25s\tremaining: 3h 10m 24s\n",
      "542:\tlearn: 0.1520386\ttotal: 1h 31s\tremaining: 3h 10m 16s\n",
      "543:\tlearn: 0.1515668\ttotal: 1h 37s\tremaining: 3h 10m 8s\n",
      "544:\tlearn: 0.1512678\ttotal: 1h 44s\tremaining: 3h 10m\n",
      "545:\tlearn: 0.1509687\ttotal: 1h 50s\tremaining: 3h 9m 52s\n",
      "546:\tlearn: 0.1504697\ttotal: 1h 57s\tremaining: 3h 9m 45s\n",
      "547:\tlearn: 0.1499481\ttotal: 1h 1m 3s\tremaining: 3h 9m 37s\n",
      "548:\tlearn: 0.1496443\ttotal: 1h 1m 9s\tremaining: 3h 9m 30s\n",
      "549:\tlearn: 0.1492082\ttotal: 1h 1m 16s\tremaining: 3h 9m 22s\n",
      "550:\tlearn: 0.1491438\ttotal: 1h 1m 22s\tremaining: 3h 9m 14s\n",
      "551:\tlearn: 0.1487548\ttotal: 1h 1m 28s\tremaining: 3h 9m 7s\n",
      "552:\tlearn: 0.1483723\ttotal: 1h 1m 35s\tremaining: 3h 8m 59s\n",
      "553:\tlearn: 0.1478205\ttotal: 1h 1m 41s\tremaining: 3h 8m 51s\n",
      "554:\tlearn: 0.1473253\ttotal: 1h 1m 47s\tremaining: 3h 8m 43s\n",
      "555:\tlearn: 0.1470156\ttotal: 1h 1m 54s\tremaining: 3h 8m 35s\n",
      "556:\tlearn: 0.1465322\ttotal: 1h 2m\tremaining: 3h 8m 28s\n",
      "557:\tlearn: 0.1463174\ttotal: 1h 2m 6s\tremaining: 3h 8m 20s\n",
      "558:\tlearn: 0.1460369\ttotal: 1h 2m 13s\tremaining: 3h 8m 13s\n",
      "559:\tlearn: 0.1455317\ttotal: 1h 2m 19s\tremaining: 3h 8m 5s\n",
      "560:\tlearn: 0.1450570\ttotal: 1h 2m 25s\tremaining: 3h 7m 57s\n",
      "561:\tlearn: 0.1447315\ttotal: 1h 2m 32s\tremaining: 3h 7m 50s\n",
      "562:\tlearn: 0.1442557\ttotal: 1h 2m 38s\tremaining: 3h 7m 42s\n",
      "563:\tlearn: 0.1437510\ttotal: 1h 2m 45s\tremaining: 3h 7m 35s\n",
      "564:\tlearn: 0.1431732\ttotal: 1h 2m 51s\tremaining: 3h 7m 27s\n",
      "565:\tlearn: 0.1427167\ttotal: 1h 2m 57s\tremaining: 3h 7m 19s\n",
      "566:\tlearn: 0.1423521\ttotal: 1h 3m 4s\tremaining: 3h 7m 12s\n",
      "567:\tlearn: 0.1420294\ttotal: 1h 3m 10s\tremaining: 3h 7m 4s\n",
      "568:\tlearn: 0.1417592\ttotal: 1h 3m 16s\tremaining: 3h 6m 56s\n",
      "569:\tlearn: 0.1413861\ttotal: 1h 3m 23s\tremaining: 3h 6m 48s\n",
      "570:\tlearn: 0.1410341\ttotal: 1h 3m 29s\tremaining: 3h 6m 41s\n",
      "571:\tlearn: 0.1405864\ttotal: 1h 3m 35s\tremaining: 3h 6m 33s\n",
      "572:\tlearn: 0.1402425\ttotal: 1h 3m 42s\tremaining: 3h 6m 25s\n",
      "573:\tlearn: 0.1397068\ttotal: 1h 3m 48s\tremaining: 3h 6m 18s\n",
      "574:\tlearn: 0.1393060\ttotal: 1h 3m 54s\tremaining: 3h 6m 10s\n",
      "575:\tlearn: 0.1391254\ttotal: 1h 4m 1s\tremaining: 3h 6m 3s\n",
      "576:\tlearn: 0.1388472\ttotal: 1h 4m 7s\tremaining: 3h 5m 55s\n",
      "577:\tlearn: 0.1384364\ttotal: 1h 4m 13s\tremaining: 3h 5m 48s\n",
      "578:\tlearn: 0.1380147\ttotal: 1h 4m 20s\tremaining: 3h 5m 40s\n",
      "579:\tlearn: 0.1376716\ttotal: 1h 4m 26s\tremaining: 3h 5m 32s\n",
      "580:\tlearn: 0.1374074\ttotal: 1h 4m 32s\tremaining: 3h 5m 24s\n",
      "581:\tlearn: 0.1371664\ttotal: 1h 4m 39s\tremaining: 3h 5m 17s\n",
      "582:\tlearn: 0.1368370\ttotal: 1h 4m 45s\tremaining: 3h 5m 10s\n",
      "583:\tlearn: 0.1363648\ttotal: 1h 4m 51s\tremaining: 3h 5m 2s\n",
      "584:\tlearn: 0.1358946\ttotal: 1h 4m 58s\tremaining: 3h 4m 55s\n",
      "585:\tlearn: 0.1355204\ttotal: 1h 5m 4s\tremaining: 3h 4m 47s\n",
      "586:\tlearn: 0.1351328\ttotal: 1h 5m 11s\tremaining: 3h 4m 40s\n",
      "587:\tlearn: 0.1347861\ttotal: 1h 5m 17s\tremaining: 3h 4m 33s\n",
      "588:\tlearn: 0.1345547\ttotal: 1h 5m 24s\tremaining: 3h 4m 26s\n",
      "589:\tlearn: 0.1340905\ttotal: 1h 5m 30s\tremaining: 3h 4m 18s\n",
      "590:\tlearn: 0.1339372\ttotal: 1h 5m 36s\tremaining: 3h 4m 10s\n",
      "591:\tlearn: 0.1336475\ttotal: 1h 5m 43s\tremaining: 3h 4m 3s\n",
      "592:\tlearn: 0.1333065\ttotal: 1h 5m 49s\tremaining: 3h 3m 56s\n",
      "593:\tlearn: 0.1330642\ttotal: 1h 5m 55s\tremaining: 3h 3m 48s\n",
      "594:\tlearn: 0.1325790\ttotal: 1h 6m 2s\tremaining: 3h 3m 41s\n",
      "595:\tlearn: 0.1321060\ttotal: 1h 6m 8s\tremaining: 3h 3m 33s\n",
      "596:\tlearn: 0.1317564\ttotal: 1h 6m 15s\tremaining: 3h 3m 26s\n",
      "597:\tlearn: 0.1314592\ttotal: 1h 6m 21s\tremaining: 3h 3m 18s\n",
      "598:\tlearn: 0.1311869\ttotal: 1h 6m 27s\tremaining: 3h 3m 11s\n",
      "599:\tlearn: 0.1307777\ttotal: 1h 6m 34s\tremaining: 3h 3m 3s\n",
      "600:\tlearn: 0.1303018\ttotal: 1h 6m 40s\tremaining: 3h 2m 56s\n",
      "601:\tlearn: 0.1298455\ttotal: 1h 6m 46s\tremaining: 3h 2m 49s\n",
      "602:\tlearn: 0.1294785\ttotal: 1h 6m 53s\tremaining: 3h 2m 41s\n",
      "603:\tlearn: 0.1294078\ttotal: 1h 6m 59s\tremaining: 3h 2m 33s\n",
      "604:\tlearn: 0.1289580\ttotal: 1h 7m 5s\tremaining: 3h 2m 26s\n",
      "605:\tlearn: 0.1285743\ttotal: 1h 7m 12s\tremaining: 3h 2m 18s\n",
      "606:\tlearn: 0.1281817\ttotal: 1h 7m 18s\tremaining: 3h 2m 11s\n",
      "607:\tlearn: 0.1278272\ttotal: 1h 7m 25s\tremaining: 3h 2m 4s\n",
      "608:\tlearn: 0.1275357\ttotal: 1h 7m 31s\tremaining: 3h 1m 56s\n",
      "609:\tlearn: 0.1272979\ttotal: 1h 7m 37s\tremaining: 3h 1m 49s\n",
      "610:\tlearn: 0.1269423\ttotal: 1h 7m 44s\tremaining: 3h 1m 41s\n",
      "611:\tlearn: 0.1265430\ttotal: 1h 7m 50s\tremaining: 3h 1m 34s\n",
      "612:\tlearn: 0.1261816\ttotal: 1h 7m 56s\tremaining: 3h 1m 27s\n",
      "613:\tlearn: 0.1257640\ttotal: 1h 8m 3s\tremaining: 3h 1m 19s\n",
      "614:\tlearn: 0.1254837\ttotal: 1h 8m 9s\tremaining: 3h 1m 12s\n",
      "615:\tlearn: 0.1251056\ttotal: 1h 8m 15s\tremaining: 3h 1m 4s\n",
      "616:\tlearn: 0.1249712\ttotal: 1h 8m 22s\tremaining: 3h 57s\n",
      "617:\tlearn: 0.1245316\ttotal: 1h 8m 28s\tremaining: 3h 50s\n",
      "618:\tlearn: 0.1242457\ttotal: 1h 8m 35s\tremaining: 3h 42s\n",
      "619:\tlearn: 0.1238691\ttotal: 1h 8m 41s\tremaining: 3h 35s\n",
      "620:\tlearn: 0.1234838\ttotal: 1h 8m 47s\tremaining: 3h 28s\n",
      "621:\tlearn: 0.1230541\ttotal: 1h 8m 54s\tremaining: 3h 21s\n",
      "622:\tlearn: 0.1227243\ttotal: 1h 9m\tremaining: 3h 13s\n",
      "623:\tlearn: 0.1223486\ttotal: 1h 9m 7s\tremaining: 3h 6s\n",
      "624:\tlearn: 0.1219696\ttotal: 1h 9m 13s\tremaining: 2h 59m 59s\n",
      "625:\tlearn: 0.1216441\ttotal: 1h 9m 19s\tremaining: 2h 59m 51s\n",
      "626:\tlearn: 0.1212647\ttotal: 1h 9m 26s\tremaining: 2h 59m 44s\n",
      "627:\tlearn: 0.1208873\ttotal: 1h 9m 32s\tremaining: 2h 59m 37s\n",
      "628:\tlearn: 0.1205603\ttotal: 1h 9m 38s\tremaining: 2h 59m 29s\n",
      "629:\tlearn: 0.1202525\ttotal: 1h 9m 45s\tremaining: 2h 59m 22s\n",
      "630:\tlearn: 0.1200822\ttotal: 1h 9m 51s\tremaining: 2h 59m 14s\n",
      "631:\tlearn: 0.1197177\ttotal: 1h 9m 58s\tremaining: 2h 59m 8s\n",
      "632:\tlearn: 0.1194201\ttotal: 1h 10m 4s\tremaining: 2h 59m\n",
      "633:\tlearn: 0.1190834\ttotal: 1h 10m 10s\tremaining: 2h 58m 53s\n",
      "634:\tlearn: 0.1189119\ttotal: 1h 10m 18s\tremaining: 2h 58m 47s\n",
      "635:\tlearn: 0.1187306\ttotal: 1h 10m 25s\tremaining: 2h 58m 44s\n",
      "636:\tlearn: 0.1183513\ttotal: 1h 10m 34s\tremaining: 2h 58m 42s\n",
      "637:\tlearn: 0.1181437\ttotal: 1h 10m 42s\tremaining: 2h 58m 39s\n",
      "638:\tlearn: 0.1177834\ttotal: 1h 10m 50s\tremaining: 2h 58m 35s\n",
      "639:\tlearn: 0.1175081\ttotal: 1h 10m 58s\tremaining: 2h 58m 32s\n",
      "640:\tlearn: 0.1172701\ttotal: 1h 11m 6s\tremaining: 2h 58m 28s\n",
      "641:\tlearn: 0.1169328\ttotal: 1h 11m 12s\tremaining: 2h 58m 22s\n",
      "642:\tlearn: 0.1166586\ttotal: 1h 11m 19s\tremaining: 2h 58m 15s\n",
      "643:\tlearn: 0.1162944\ttotal: 1h 11m 26s\tremaining: 2h 58m 8s\n",
      "644:\tlearn: 0.1159407\ttotal: 1h 11m 33s\tremaining: 2h 58m 2s\n",
      "645:\tlearn: 0.1156187\ttotal: 1h 11m 39s\tremaining: 2h 57m 56s\n",
      "646:\tlearn: 0.1154569\ttotal: 1h 11m 46s\tremaining: 2h 57m 50s\n",
      "647:\tlearn: 0.1151342\ttotal: 1h 11m 53s\tremaining: 2h 57m 43s\n",
      "648:\tlearn: 0.1148252\ttotal: 1h 11m 59s\tremaining: 2h 57m 36s\n",
      "649:\tlearn: 0.1145449\ttotal: 1h 12m 6s\tremaining: 2h 57m 29s\n",
      "650:\tlearn: 0.1142705\ttotal: 1h 12m 12s\tremaining: 2h 57m 21s\n",
      "651:\tlearn: 0.1139462\ttotal: 1h 12m 18s\tremaining: 2h 57m 14s\n",
      "652:\tlearn: 0.1136345\ttotal: 1h 12m 25s\tremaining: 2h 57m 7s\n",
      "653:\tlearn: 0.1133410\ttotal: 1h 12m 32s\tremaining: 2h 57m\n",
      "654:\tlearn: 0.1131001\ttotal: 1h 12m 39s\tremaining: 2h 56m 54s\n",
      "655:\tlearn: 0.1128148\ttotal: 1h 12m 45s\tremaining: 2h 56m 47s\n",
      "656:\tlearn: 0.1125730\ttotal: 1h 12m 52s\tremaining: 2h 56m 41s\n",
      "657:\tlearn: 0.1122188\ttotal: 1h 12m 59s\tremaining: 2h 56m 34s\n",
      "658:\tlearn: 0.1118516\ttotal: 1h 13m 5s\tremaining: 2h 56m 27s\n",
      "659:\tlearn: 0.1117128\ttotal: 1h 13m 12s\tremaining: 2h 56m 21s\n",
      "660:\tlearn: 0.1115831\ttotal: 1h 13m 18s\tremaining: 2h 56m 13s\n",
      "661:\tlearn: 0.1112906\ttotal: 1h 13m 25s\tremaining: 2h 56m 7s\n",
      "662:\tlearn: 0.1110709\ttotal: 1h 13m 31s\tremaining: 2h 56m\n",
      "663:\tlearn: 0.1108108\ttotal: 1h 13m 38s\tremaining: 2h 55m 52s\n",
      "664:\tlearn: 0.1106651\ttotal: 1h 13m 44s\tremaining: 2h 55m 46s\n",
      "665:\tlearn: 0.1103358\ttotal: 1h 13m 51s\tremaining: 2h 55m 39s\n",
      "666:\tlearn: 0.1099943\ttotal: 1h 13m 58s\tremaining: 2h 55m 32s\n",
      "667:\tlearn: 0.1097250\ttotal: 1h 14m 4s\tremaining: 2h 55m 25s\n",
      "668:\tlearn: 0.1096347\ttotal: 1h 14m 10s\tremaining: 2h 55m 18s\n",
      "669:\tlearn: 0.1093774\ttotal: 1h 14m 17s\tremaining: 2h 55m 11s\n",
      "670:\tlearn: 0.1090988\ttotal: 1h 14m 23s\tremaining: 2h 55m 4s\n",
      "671:\tlearn: 0.1087637\ttotal: 1h 14m 30s\tremaining: 2h 54m 58s\n",
      "672:\tlearn: 0.1085365\ttotal: 1h 14m 37s\tremaining: 2h 54m 51s\n",
      "673:\tlearn: 0.1083390\ttotal: 1h 14m 43s\tremaining: 2h 54m 43s\n",
      "674:\tlearn: 0.1081091\ttotal: 1h 14m 50s\tremaining: 2h 54m 37s\n",
      "675:\tlearn: 0.1078528\ttotal: 1h 14m 56s\tremaining: 2h 54m 29s\n",
      "676:\tlearn: 0.1075362\ttotal: 1h 15m 3s\tremaining: 2h 54m 23s\n",
      "677:\tlearn: 0.1073512\ttotal: 1h 15m 9s\tremaining: 2h 54m 16s\n",
      "678:\tlearn: 0.1071000\ttotal: 1h 15m 15s\tremaining: 2h 54m 8s\n",
      "679:\tlearn: 0.1068399\ttotal: 1h 15m 23s\tremaining: 2h 54m 3s\n",
      "680:\tlearn: 0.1066250\ttotal: 1h 15m 29s\tremaining: 2h 53m 55s\n",
      "681:\tlearn: 0.1063114\ttotal: 1h 15m 36s\tremaining: 2h 53m 48s\n",
      "682:\tlearn: 0.1062184\ttotal: 1h 15m 42s\tremaining: 2h 53m 41s\n",
      "683:\tlearn: 0.1059033\ttotal: 1h 15m 49s\tremaining: 2h 53m 35s\n",
      "684:\tlearn: 0.1057147\ttotal: 1h 15m 55s\tremaining: 2h 53m 28s\n",
      "685:\tlearn: 0.1055386\ttotal: 1h 16m 4s\tremaining: 2h 53m 25s\n",
      "686:\tlearn: 0.1052092\ttotal: 1h 16m 11s\tremaining: 2h 53m 20s\n",
      "687:\tlearn: 0.1049330\ttotal: 1h 16m 18s\tremaining: 2h 53m 15s\n",
      "688:\tlearn: 0.1048085\ttotal: 1h 16m 25s\tremaining: 2h 53m 8s\n",
      "689:\tlearn: 0.1045710\ttotal: 1h 16m 31s\tremaining: 2h 53m 1s\n",
      "690:\tlearn: 0.1042597\ttotal: 1h 16m 38s\tremaining: 2h 52m 55s\n",
      "691:\tlearn: 0.1040065\ttotal: 1h 16m 45s\tremaining: 2h 52m 49s\n",
      "692:\tlearn: 0.1037898\ttotal: 1h 16m 52s\tremaining: 2h 52m 42s\n",
      "693:\tlearn: 0.1035906\ttotal: 1h 16m 58s\tremaining: 2h 52m 35s\n",
      "694:\tlearn: 0.1033214\ttotal: 1h 17m 7s\tremaining: 2h 52m 34s\n",
      "695:\tlearn: 0.1031311\ttotal: 1h 17m 16s\tremaining: 2h 52m 31s\n",
      "696:\tlearn: 0.1030734\ttotal: 1h 17m 25s\tremaining: 2h 52m 30s\n",
      "697:\tlearn: 0.1028296\ttotal: 1h 17m 32s\tremaining: 2h 52m 25s\n",
      "698:\tlearn: 0.1026994\ttotal: 1h 17m 39s\tremaining: 2h 52m 18s\n",
      "699:\tlearn: 0.1024160\ttotal: 1h 17m 45s\tremaining: 2h 52m 11s\n",
      "700:\tlearn: 0.1022862\ttotal: 1h 17m 52s\tremaining: 2h 52m 4s\n",
      "701:\tlearn: 0.1020485\ttotal: 1h 17m 58s\tremaining: 2h 51m 57s\n",
      "702:\tlearn: 0.1018328\ttotal: 1h 18m 5s\tremaining: 2h 51m 50s\n",
      "703:\tlearn: 0.1016172\ttotal: 1h 18m 11s\tremaining: 2h 51m 42s\n",
      "704:\tlearn: 0.1013964\ttotal: 1h 18m 18s\tremaining: 2h 51m 35s\n",
      "705:\tlearn: 0.1011215\ttotal: 1h 18m 24s\tremaining: 2h 51m 28s\n",
      "706:\tlearn: 0.1010127\ttotal: 1h 18m 31s\tremaining: 2h 51m 22s\n",
      "707:\tlearn: 0.1008754\ttotal: 1h 18m 37s\tremaining: 2h 51m 14s\n",
      "708:\tlearn: 0.1005804\ttotal: 1h 18m 44s\tremaining: 2h 51m 7s\n",
      "709:\tlearn: 0.1003772\ttotal: 1h 18m 50s\tremaining: 2h 51m\n",
      "710:\tlearn: 0.1001307\ttotal: 1h 18m 56s\tremaining: 2h 50m 53s\n",
      "711:\tlearn: 0.1000344\ttotal: 1h 19m 3s\tremaining: 2h 50m 46s\n",
      "712:\tlearn: 0.0998945\ttotal: 1h 19m 9s\tremaining: 2h 50m 39s\n",
      "713:\tlearn: 0.0997844\ttotal: 1h 19m 16s\tremaining: 2h 50m 31s\n",
      "714:\tlearn: 0.0995322\ttotal: 1h 19m 22s\tremaining: 2h 50m 24s\n",
      "715:\tlearn: 0.0992927\ttotal: 1h 19m 28s\tremaining: 2h 50m 17s\n",
      "716:\tlearn: 0.0990501\ttotal: 1h 19m 35s\tremaining: 2h 50m 10s\n",
      "717:\tlearn: 0.0988253\ttotal: 1h 19m 41s\tremaining: 2h 50m 2s\n",
      "718:\tlearn: 0.0986363\ttotal: 1h 19m 48s\tremaining: 2h 49m 55s\n",
      "719:\tlearn: 0.0985082\ttotal: 1h 19m 54s\tremaining: 2h 49m 48s\n",
      "720:\tlearn: 0.0982709\ttotal: 1h 20m\tremaining: 2h 49m 40s\n",
      "721:\tlearn: 0.0981618\ttotal: 1h 20m 7s\tremaining: 2h 49m 34s\n",
      "722:\tlearn: 0.0980658\ttotal: 1h 20m 13s\tremaining: 2h 49m 26s\n",
      "723:\tlearn: 0.0977939\ttotal: 1h 20m 19s\tremaining: 2h 49m 19s\n",
      "724:\tlearn: 0.0976559\ttotal: 1h 20m 26s\tremaining: 2h 49m 11s\n",
      "725:\tlearn: 0.0974303\ttotal: 1h 20m 32s\tremaining: 2h 49m 4s\n",
      "726:\tlearn: 0.0971900\ttotal: 1h 20m 39s\tremaining: 2h 48m 57s\n",
      "727:\tlearn: 0.0970070\ttotal: 1h 20m 45s\tremaining: 2h 48m 50s\n",
      "728:\tlearn: 0.0967978\ttotal: 1h 20m 51s\tremaining: 2h 48m 42s\n",
      "729:\tlearn: 0.0965814\ttotal: 1h 20m 58s\tremaining: 2h 48m 35s\n",
      "730:\tlearn: 0.0963542\ttotal: 1h 21m 4s\tremaining: 2h 48m 28s\n",
      "731:\tlearn: 0.0960870\ttotal: 1h 21m 11s\tremaining: 2h 48m 21s\n",
      "732:\tlearn: 0.0958800\ttotal: 1h 21m 17s\tremaining: 2h 48m 14s\n",
      "733:\tlearn: 0.0956600\ttotal: 1h 21m 23s\tremaining: 2h 48m 6s\n",
      "734:\tlearn: 0.0953980\ttotal: 1h 21m 30s\tremaining: 2h 47m 59s\n",
      "735:\tlearn: 0.0951623\ttotal: 1h 21m 36s\tremaining: 2h 47m 52s\n",
      "736:\tlearn: 0.0950109\ttotal: 1h 21m 43s\tremaining: 2h 47m 45s\n",
      "737:\tlearn: 0.0948055\ttotal: 1h 21m 49s\tremaining: 2h 47m 38s\n",
      "738:\tlearn: 0.0945454\ttotal: 1h 21m 55s\tremaining: 2h 47m 30s\n",
      "739:\tlearn: 0.0943137\ttotal: 1h 22m 2s\tremaining: 2h 47m 23s\n",
      "740:\tlearn: 0.0940491\ttotal: 1h 22m 8s\tremaining: 2h 47m 16s\n",
      "741:\tlearn: 0.0937982\ttotal: 1h 22m 14s\tremaining: 2h 47m 9s\n",
      "742:\tlearn: 0.0936123\ttotal: 1h 22m 21s\tremaining: 2h 47m 2s\n",
      "743:\tlearn: 0.0934598\ttotal: 1h 22m 27s\tremaining: 2h 46m 54s\n",
      "744:\tlearn: 0.0933084\ttotal: 1h 22m 34s\tremaining: 2h 46m 47s\n",
      "745:\tlearn: 0.0930744\ttotal: 1h 22m 40s\tremaining: 2h 46m 40s\n",
      "746:\tlearn: 0.0928620\ttotal: 1h 22m 46s\tremaining: 2h 46m 33s\n",
      "747:\tlearn: 0.0925925\ttotal: 1h 22m 53s\tremaining: 2h 46m 26s\n",
      "748:\tlearn: 0.0924063\ttotal: 1h 22m 59s\tremaining: 2h 46m 19s\n",
      "749:\tlearn: 0.0921905\ttotal: 1h 23m 6s\tremaining: 2h 46m 12s\n",
      "750:\tlearn: 0.0919619\ttotal: 1h 23m 12s\tremaining: 2h 46m 4s\n",
      "751:\tlearn: 0.0918020\ttotal: 1h 23m 18s\tremaining: 2h 45m 57s\n",
      "752:\tlearn: 0.0917473\ttotal: 1h 23m 25s\tremaining: 2h 45m 50s\n",
      "753:\tlearn: 0.0914971\ttotal: 1h 23m 31s\tremaining: 2h 45m 43s\n",
      "754:\tlearn: 0.0913587\ttotal: 1h 23m 38s\tremaining: 2h 45m 36s\n",
      "755:\tlearn: 0.0911482\ttotal: 1h 23m 44s\tremaining: 2h 45m 29s\n",
      "756:\tlearn: 0.0909483\ttotal: 1h 23m 50s\tremaining: 2h 45m 22s\n",
      "757:\tlearn: 0.0908112\ttotal: 1h 23m 57s\tremaining: 2h 45m 14s\n",
      "758:\tlearn: 0.0906211\ttotal: 1h 24m 3s\tremaining: 2h 45m 7s\n",
      "759:\tlearn: 0.0904159\ttotal: 1h 24m 10s\tremaining: 2h 45m\n",
      "760:\tlearn: 0.0902923\ttotal: 1h 24m 16s\tremaining: 2h 44m 53s\n",
      "761:\tlearn: 0.0900963\ttotal: 1h 24m 23s\tremaining: 2h 44m 46s\n",
      "762:\tlearn: 0.0899095\ttotal: 1h 24m 29s\tremaining: 2h 44m 39s\n",
      "763:\tlearn: 0.0897236\ttotal: 1h 24m 35s\tremaining: 2h 44m 32s\n",
      "764:\tlearn: 0.0895005\ttotal: 1h 24m 42s\tremaining: 2h 44m 25s\n",
      "765:\tlearn: 0.0893634\ttotal: 1h 24m 48s\tremaining: 2h 44m 17s\n",
      "766:\tlearn: 0.0891477\ttotal: 1h 24m 54s\tremaining: 2h 44m 10s\n",
      "767:\tlearn: 0.0890165\ttotal: 1h 25m 1s\tremaining: 2h 44m 3s\n",
      "768:\tlearn: 0.0888936\ttotal: 1h 25m 7s\tremaining: 2h 43m 56s\n",
      "769:\tlearn: 0.0887355\ttotal: 1h 25m 13s\tremaining: 2h 43m 49s\n",
      "770:\tlearn: 0.0884968\ttotal: 1h 25m 20s\tremaining: 2h 43m 42s\n",
      "771:\tlearn: 0.0882926\ttotal: 1h 25m 26s\tremaining: 2h 43m 35s\n",
      "772:\tlearn: 0.0881881\ttotal: 1h 25m 33s\tremaining: 2h 43m 27s\n",
      "773:\tlearn: 0.0880293\ttotal: 1h 25m 39s\tremaining: 2h 43m 20s\n",
      "774:\tlearn: 0.0878839\ttotal: 1h 25m 45s\tremaining: 2h 43m 13s\n",
      "775:\tlearn: 0.0877372\ttotal: 1h 25m 52s\tremaining: 2h 43m 6s\n",
      "776:\tlearn: 0.0876632\ttotal: 1h 25m 58s\tremaining: 2h 42m 59s\n",
      "777:\tlearn: 0.0874443\ttotal: 1h 26m 4s\tremaining: 2h 42m 52s\n",
      "778:\tlearn: 0.0872844\ttotal: 1h 26m 11s\tremaining: 2h 42m 44s\n",
      "779:\tlearn: 0.0870829\ttotal: 1h 26m 17s\tremaining: 2h 42m 38s\n",
      "780:\tlearn: 0.0869517\ttotal: 1h 26m 24s\tremaining: 2h 42m 30s\n",
      "781:\tlearn: 0.0868168\ttotal: 1h 26m 30s\tremaining: 2h 42m 23s\n",
      "782:\tlearn: 0.0866631\ttotal: 1h 26m 36s\tremaining: 2h 42m 16s\n",
      "783:\tlearn: 0.0864695\ttotal: 1h 26m 43s\tremaining: 2h 42m 9s\n",
      "784:\tlearn: 0.0863695\ttotal: 1h 26m 49s\tremaining: 2h 42m 2s\n",
      "785:\tlearn: 0.0862361\ttotal: 1h 26m 55s\tremaining: 2h 41m 55s\n",
      "786:\tlearn: 0.0860050\ttotal: 1h 27m 2s\tremaining: 2h 41m 48s\n",
      "787:\tlearn: 0.0858635\ttotal: 1h 27m 8s\tremaining: 2h 41m 41s\n",
      "788:\tlearn: 0.0857512\ttotal: 1h 27m 15s\tremaining: 2h 41m 33s\n",
      "789:\tlearn: 0.0856175\ttotal: 1h 27m 21s\tremaining: 2h 41m 27s\n",
      "790:\tlearn: 0.0855072\ttotal: 1h 27m 27s\tremaining: 2h 41m 19s\n",
      "791:\tlearn: 0.0852784\ttotal: 1h 27m 34s\tremaining: 2h 41m 13s\n",
      "792:\tlearn: 0.0851596\ttotal: 1h 27m 40s\tremaining: 2h 41m 5s\n",
      "793:\tlearn: 0.0849744\ttotal: 1h 27m 47s\tremaining: 2h 40m 58s\n",
      "794:\tlearn: 0.0847804\ttotal: 1h 27m 53s\tremaining: 2h 40m 51s\n",
      "795:\tlearn: 0.0845727\ttotal: 1h 27m 59s\tremaining: 2h 40m 44s\n",
      "796:\tlearn: 0.0843339\ttotal: 1h 28m 6s\tremaining: 2h 40m 37s\n",
      "797:\tlearn: 0.0841952\ttotal: 1h 28m 12s\tremaining: 2h 40m 30s\n",
      "798:\tlearn: 0.0840634\ttotal: 1h 28m 19s\tremaining: 2h 40m 23s\n",
      "799:\tlearn: 0.0839425\ttotal: 1h 28m 25s\tremaining: 2h 40m 16s\n",
      "800:\tlearn: 0.0837861\ttotal: 1h 28m 32s\tremaining: 2h 40m 9s\n",
      "801:\tlearn: 0.0836293\ttotal: 1h 28m 38s\tremaining: 2h 40m 2s\n",
      "802:\tlearn: 0.0834522\ttotal: 1h 28m 44s\tremaining: 2h 39m 55s\n",
      "803:\tlearn: 0.0833321\ttotal: 1h 28m 51s\tremaining: 2h 39m 48s\n",
      "804:\tlearn: 0.0832294\ttotal: 1h 28m 57s\tremaining: 2h 39m 41s\n",
      "805:\tlearn: 0.0830847\ttotal: 1h 29m 4s\tremaining: 2h 39m 34s\n",
      "806:\tlearn: 0.0829956\ttotal: 1h 29m 10s\tremaining: 2h 39m 27s\n",
      "807:\tlearn: 0.0828239\ttotal: 1h 29m 16s\tremaining: 2h 39m 20s\n",
      "808:\tlearn: 0.0826848\ttotal: 1h 29m 23s\tremaining: 2h 39m 13s\n",
      "809:\tlearn: 0.0824986\ttotal: 1h 29m 29s\tremaining: 2h 39m 6s\n",
      "810:\tlearn: 0.0823783\ttotal: 1h 29m 36s\tremaining: 2h 38m 59s\n",
      "811:\tlearn: 0.0822103\ttotal: 1h 29m 42s\tremaining: 2h 38m 52s\n",
      "812:\tlearn: 0.0820391\ttotal: 1h 29m 48s\tremaining: 2h 38m 45s\n",
      "813:\tlearn: 0.0818704\ttotal: 1h 29m 55s\tremaining: 2h 38m 37s\n",
      "814:\tlearn: 0.0817054\ttotal: 1h 30m 1s\tremaining: 2h 38m 30s\n",
      "815:\tlearn: 0.0815663\ttotal: 1h 30m 7s\tremaining: 2h 38m 23s\n",
      "816:\tlearn: 0.0813982\ttotal: 1h 30m 14s\tremaining: 2h 38m 16s\n",
      "817:\tlearn: 0.0812088\ttotal: 1h 30m 20s\tremaining: 2h 38m 9s\n",
      "818:\tlearn: 0.0810369\ttotal: 1h 30m 27s\tremaining: 2h 38m 2s\n",
      "819:\tlearn: 0.0808634\ttotal: 1h 30m 33s\tremaining: 2h 37m 55s\n",
      "820:\tlearn: 0.0807390\ttotal: 1h 30m 39s\tremaining: 2h 37m 48s\n",
      "821:\tlearn: 0.0806358\ttotal: 1h 30m 46s\tremaining: 2h 37m 41s\n",
      "822:\tlearn: 0.0804928\ttotal: 1h 30m 52s\tremaining: 2h 37m 34s\n",
      "823:\tlearn: 0.0803725\ttotal: 1h 30m 59s\tremaining: 2h 37m 27s\n",
      "824:\tlearn: 0.0802169\ttotal: 1h 31m 5s\tremaining: 2h 37m 20s\n",
      "825:\tlearn: 0.0800746\ttotal: 1h 31m 11s\tremaining: 2h 37m 13s\n",
      "826:\tlearn: 0.0799018\ttotal: 1h 31m 18s\tremaining: 2h 37m 6s\n",
      "827:\tlearn: 0.0797559\ttotal: 1h 31m 24s\tremaining: 2h 36m 59s\n",
      "828:\tlearn: 0.0796224\ttotal: 1h 31m 31s\tremaining: 2h 36m 52s\n",
      "829:\tlearn: 0.0794483\ttotal: 1h 31m 37s\tremaining: 2h 36m 45s\n",
      "830:\tlearn: 0.0793204\ttotal: 1h 31m 43s\tremaining: 2h 36m 38s\n",
      "831:\tlearn: 0.0791544\ttotal: 1h 31m 50s\tremaining: 2h 36m 31s\n",
      "832:\tlearn: 0.0790284\ttotal: 1h 31m 56s\tremaining: 2h 36m 24s\n",
      "833:\tlearn: 0.0788348\ttotal: 1h 32m 3s\tremaining: 2h 36m 17s\n",
      "834:\tlearn: 0.0786726\ttotal: 1h 32m 9s\tremaining: 2h 36m 10s\n",
      "835:\tlearn: 0.0785284\ttotal: 1h 32m 15s\tremaining: 2h 36m 3s\n",
      "836:\tlearn: 0.0784498\ttotal: 1h 32m 22s\tremaining: 2h 35m 56s\n",
      "837:\tlearn: 0.0783888\ttotal: 1h 32m 28s\tremaining: 2h 35m 49s\n",
      "838:\tlearn: 0.0782557\ttotal: 1h 32m 35s\tremaining: 2h 35m 42s\n",
      "839:\tlearn: 0.0781986\ttotal: 1h 32m 41s\tremaining: 2h 35m 35s\n",
      "840:\tlearn: 0.0780360\ttotal: 1h 32m 47s\tremaining: 2h 35m 28s\n",
      "841:\tlearn: 0.0779094\ttotal: 1h 32m 54s\tremaining: 2h 35m 21s\n",
      "842:\tlearn: 0.0777494\ttotal: 1h 33m\tremaining: 2h 35m 14s\n",
      "843:\tlearn: 0.0776528\ttotal: 1h 33m 7s\tremaining: 2h 35m 7s\n",
      "844:\tlearn: 0.0775050\ttotal: 1h 33m 13s\tremaining: 2h 35m\n",
      "845:\tlearn: 0.0773610\ttotal: 1h 33m 20s\tremaining: 2h 34m 53s\n",
      "846:\tlearn: 0.0772069\ttotal: 1h 33m 26s\tremaining: 2h 34m 46s\n",
      "847:\tlearn: 0.0770537\ttotal: 1h 33m 32s\tremaining: 2h 34m 39s\n",
      "848:\tlearn: 0.0769409\ttotal: 1h 33m 39s\tremaining: 2h 34m 32s\n",
      "849:\tlearn: 0.0767780\ttotal: 1h 33m 45s\tremaining: 2h 34m 25s\n",
      "850:\tlearn: 0.0766157\ttotal: 1h 33m 52s\tremaining: 2h 34m 18s\n",
      "851:\tlearn: 0.0765655\ttotal: 1h 33m 58s\tremaining: 2h 34m 11s\n",
      "852:\tlearn: 0.0764017\ttotal: 1h 34m 4s\tremaining: 2h 34m 4s\n",
      "853:\tlearn: 0.0762312\ttotal: 1h 34m 11s\tremaining: 2h 33m 57s\n",
      "854:\tlearn: 0.0761208\ttotal: 1h 34m 17s\tremaining: 2h 33m 51s\n",
      "855:\tlearn: 0.0759787\ttotal: 1h 34m 24s\tremaining: 2h 33m 44s\n",
      "856:\tlearn: 0.0758317\ttotal: 1h 34m 30s\tremaining: 2h 33m 37s\n",
      "857:\tlearn: 0.0756982\ttotal: 1h 34m 36s\tremaining: 2h 33m 30s\n",
      "858:\tlearn: 0.0755522\ttotal: 1h 34m 43s\tremaining: 2h 33m 23s\n",
      "859:\tlearn: 0.0754016\ttotal: 1h 34m 49s\tremaining: 2h 33m 16s\n",
      "860:\tlearn: 0.0752404\ttotal: 1h 34m 56s\tremaining: 2h 33m 9s\n",
      "861:\tlearn: 0.0751221\ttotal: 1h 35m 2s\tremaining: 2h 33m 2s\n",
      "862:\tlearn: 0.0749880\ttotal: 1h 35m 9s\tremaining: 2h 32m 55s\n",
      "863:\tlearn: 0.0749141\ttotal: 1h 35m 15s\tremaining: 2h 32m 48s\n",
      "864:\tlearn: 0.0747655\ttotal: 1h 35m 21s\tremaining: 2h 32m 41s\n",
      "865:\tlearn: 0.0746828\ttotal: 1h 35m 28s\tremaining: 2h 32m 34s\n",
      "866:\tlearn: 0.0745852\ttotal: 1h 35m 34s\tremaining: 2h 32m 27s\n",
      "867:\tlearn: 0.0744566\ttotal: 1h 35m 40s\tremaining: 2h 32m 20s\n",
      "868:\tlearn: 0.0742818\ttotal: 1h 35m 47s\tremaining: 2h 32m 13s\n",
      "869:\tlearn: 0.0741294\ttotal: 1h 35m 53s\tremaining: 2h 32m 6s\n",
      "870:\tlearn: 0.0740545\ttotal: 1h 36m\tremaining: 2h 31m 59s\n",
      "871:\tlearn: 0.0739511\ttotal: 1h 36m 6s\tremaining: 2h 31m 52s\n",
      "872:\tlearn: 0.0739072\ttotal: 1h 36m 12s\tremaining: 2h 31m 45s\n",
      "873:\tlearn: 0.0737962\ttotal: 1h 36m 19s\tremaining: 2h 31m 38s\n",
      "874:\tlearn: 0.0736443\ttotal: 1h 36m 25s\tremaining: 2h 31m 31s\n",
      "875:\tlearn: 0.0734984\ttotal: 1h 36m 32s\tremaining: 2h 31m 24s\n",
      "876:\tlearn: 0.0733398\ttotal: 1h 36m 38s\tremaining: 2h 31m 18s\n",
      "877:\tlearn: 0.0731918\ttotal: 1h 36m 45s\tremaining: 2h 31m 11s\n",
      "878:\tlearn: 0.0730407\ttotal: 1h 36m 51s\tremaining: 2h 31m 4s\n",
      "879:\tlearn: 0.0729236\ttotal: 1h 36m 57s\tremaining: 2h 30m 57s\n",
      "880:\tlearn: 0.0727948\ttotal: 1h 37m 4s\tremaining: 2h 30m 50s\n",
      "881:\tlearn: 0.0726503\ttotal: 1h 37m 10s\tremaining: 2h 30m 43s\n",
      "882:\tlearn: 0.0725117\ttotal: 1h 37m 16s\tremaining: 2h 30m 36s\n",
      "883:\tlearn: 0.0723967\ttotal: 1h 37m 23s\tremaining: 2h 30m 29s\n",
      "884:\tlearn: 0.0722821\ttotal: 1h 37m 29s\tremaining: 2h 30m 22s\n",
      "885:\tlearn: 0.0721695\ttotal: 1h 37m 36s\tremaining: 2h 30m 15s\n",
      "886:\tlearn: 0.0720575\ttotal: 1h 37m 42s\tremaining: 2h 30m 8s\n",
      "887:\tlearn: 0.0719097\ttotal: 1h 37m 48s\tremaining: 2h 30m 1s\n",
      "888:\tlearn: 0.0718136\ttotal: 1h 37m 55s\tremaining: 2h 29m 54s\n",
      "889:\tlearn: 0.0716564\ttotal: 1h 38m 1s\tremaining: 2h 29m 48s\n",
      "890:\tlearn: 0.0715279\ttotal: 1h 38m 8s\tremaining: 2h 29m 41s\n",
      "891:\tlearn: 0.0714449\ttotal: 1h 38m 14s\tremaining: 2h 29m 34s\n",
      "892:\tlearn: 0.0713334\ttotal: 1h 38m 21s\tremaining: 2h 29m 27s\n",
      "893:\tlearn: 0.0712242\ttotal: 1h 38m 27s\tremaining: 2h 29m 20s\n",
      "894:\tlearn: 0.0710713\ttotal: 1h 38m 33s\tremaining: 2h 29m 13s\n",
      "895:\tlearn: 0.0709257\ttotal: 1h 38m 40s\tremaining: 2h 29m 6s\n",
      "896:\tlearn: 0.0708742\ttotal: 1h 38m 46s\tremaining: 2h 28m 59s\n",
      "897:\tlearn: 0.0707407\ttotal: 1h 38m 53s\tremaining: 2h 28m 52s\n",
      "898:\tlearn: 0.0706022\ttotal: 1h 38m 59s\tremaining: 2h 28m 45s\n",
      "899:\tlearn: 0.0704720\ttotal: 1h 39m 5s\tremaining: 2h 28m 38s\n",
      "900:\tlearn: 0.0703241\ttotal: 1h 39m 12s\tremaining: 2h 28m 31s\n",
      "901:\tlearn: 0.0702552\ttotal: 1h 39m 18s\tremaining: 2h 28m 25s\n",
      "902:\tlearn: 0.0701128\ttotal: 1h 39m 25s\tremaining: 2h 28m 18s\n",
      "903:\tlearn: 0.0700136\ttotal: 1h 39m 31s\tremaining: 2h 28m 11s\n",
      "904:\tlearn: 0.0698737\ttotal: 1h 39m 38s\tremaining: 2h 28m 4s\n",
      "905:\tlearn: 0.0698044\ttotal: 1h 39m 44s\tremaining: 2h 27m 57s\n",
      "906:\tlearn: 0.0696818\ttotal: 1h 39m 50s\tremaining: 2h 27m 50s\n",
      "907:\tlearn: 0.0695339\ttotal: 1h 39m 57s\tremaining: 2h 27m 43s\n",
      "908:\tlearn: 0.0693873\ttotal: 1h 40m 3s\tremaining: 2h 27m 36s\n",
      "909:\tlearn: 0.0692917\ttotal: 1h 40m 10s\tremaining: 2h 27m 29s\n",
      "910:\tlearn: 0.0691570\ttotal: 1h 40m 16s\tremaining: 2h 27m 22s\n",
      "911:\tlearn: 0.0690655\ttotal: 1h 40m 22s\tremaining: 2h 27m 16s\n",
      "912:\tlearn: 0.0689238\ttotal: 1h 40m 29s\tremaining: 2h 27m 9s\n",
      "913:\tlearn: 0.0688188\ttotal: 1h 40m 35s\tremaining: 2h 27m 2s\n",
      "914:\tlearn: 0.0686841\ttotal: 1h 40m 42s\tremaining: 2h 26m 55s\n",
      "915:\tlearn: 0.0685640\ttotal: 1h 40m 48s\tremaining: 2h 26m 48s\n",
      "916:\tlearn: 0.0684818\ttotal: 1h 40m 54s\tremaining: 2h 26m 41s\n",
      "917:\tlearn: 0.0683553\ttotal: 1h 41m 1s\tremaining: 2h 26m 34s\n",
      "918:\tlearn: 0.0682237\ttotal: 1h 41m 7s\tremaining: 2h 26m 27s\n",
      "919:\tlearn: 0.0681073\ttotal: 1h 41m 14s\tremaining: 2h 26m 21s\n",
      "920:\tlearn: 0.0679905\ttotal: 1h 41m 20s\tremaining: 2h 26m 14s\n",
      "921:\tlearn: 0.0678647\ttotal: 1h 41m 27s\tremaining: 2h 26m 7s\n",
      "922:\tlearn: 0.0678206\ttotal: 1h 41m 33s\tremaining: 2h 26m\n",
      "923:\tlearn: 0.0677078\ttotal: 1h 41m 39s\tremaining: 2h 25m 53s\n",
      "924:\tlearn: 0.0675711\ttotal: 1h 41m 46s\tremaining: 2h 25m 46s\n",
      "925:\tlearn: 0.0674258\ttotal: 1h 41m 52s\tremaining: 2h 25m 39s\n",
      "926:\tlearn: 0.0673682\ttotal: 1h 41m 59s\tremaining: 2h 25m 33s\n",
      "927:\tlearn: 0.0672294\ttotal: 1h 42m 5s\tremaining: 2h 25m 26s\n",
      "928:\tlearn: 0.0671512\ttotal: 1h 42m 11s\tremaining: 2h 25m 19s\n",
      "929:\tlearn: 0.0670991\ttotal: 1h 42m 18s\tremaining: 2h 25m 12s\n",
      "930:\tlearn: 0.0670117\ttotal: 1h 42m 24s\tremaining: 2h 25m 5s\n",
      "931:\tlearn: 0.0668855\ttotal: 1h 42m 31s\tremaining: 2h 24m 58s\n",
      "932:\tlearn: 0.0668127\ttotal: 1h 42m 37s\tremaining: 2h 24m 51s\n",
      "933:\tlearn: 0.0667005\ttotal: 1h 42m 43s\tremaining: 2h 24m 44s\n",
      "934:\tlearn: 0.0665666\ttotal: 1h 42m 50s\tremaining: 2h 24m 38s\n",
      "935:\tlearn: 0.0664441\ttotal: 1h 42m 56s\tremaining: 2h 24m 31s\n",
      "936:\tlearn: 0.0663944\ttotal: 1h 43m 3s\tremaining: 2h 24m 24s\n",
      "937:\tlearn: 0.0662783\ttotal: 1h 43m 9s\tremaining: 2h 24m 17s\n",
      "938:\tlearn: 0.0661604\ttotal: 1h 43m 15s\tremaining: 2h 24m 10s\n",
      "939:\tlearn: 0.0660575\ttotal: 1h 43m 22s\tremaining: 2h 24m 3s\n",
      "940:\tlearn: 0.0659377\ttotal: 1h 43m 28s\tremaining: 2h 23m 57s\n",
      "941:\tlearn: 0.0658932\ttotal: 1h 43m 35s\tremaining: 2h 23m 50s\n",
      "942:\tlearn: 0.0657873\ttotal: 1h 43m 41s\tremaining: 2h 23m 43s\n",
      "943:\tlearn: 0.0656684\ttotal: 1h 43m 48s\tremaining: 2h 23m 36s\n",
      "944:\tlearn: 0.0655672\ttotal: 1h 43m 54s\tremaining: 2h 23m 29s\n",
      "945:\tlearn: 0.0654846\ttotal: 1h 44m 1s\tremaining: 2h 23m 22s\n",
      "946:\tlearn: 0.0653974\ttotal: 1h 44m 7s\tremaining: 2h 23m 16s\n",
      "947:\tlearn: 0.0653332\ttotal: 1h 44m 13s\tremaining: 2h 23m 9s\n",
      "948:\tlearn: 0.0652177\ttotal: 1h 44m 20s\tremaining: 2h 23m 2s\n",
      "949:\tlearn: 0.0651396\ttotal: 1h 44m 26s\tremaining: 2h 22m 55s\n",
      "950:\tlearn: 0.0650465\ttotal: 1h 44m 32s\tremaining: 2h 22m 48s\n",
      "951:\tlearn: 0.0649266\ttotal: 1h 44m 39s\tremaining: 2h 22m 41s\n",
      "952:\tlearn: 0.0648879\ttotal: 1h 44m 45s\tremaining: 2h 22m 34s\n",
      "953:\tlearn: 0.0648240\ttotal: 1h 44m 52s\tremaining: 2h 22m 27s\n",
      "954:\tlearn: 0.0647389\ttotal: 1h 44m 58s\tremaining: 2h 22m 21s\n",
      "955:\tlearn: 0.0646302\ttotal: 1h 45m 4s\tremaining: 2h 22m 14s\n",
      "956:\tlearn: 0.0645269\ttotal: 1h 45m 11s\tremaining: 2h 22m 7s\n",
      "957:\tlearn: 0.0644017\ttotal: 1h 45m 17s\tremaining: 2h 22m\n",
      "958:\tlearn: 0.0642831\ttotal: 1h 45m 24s\tremaining: 2h 21m 53s\n",
      "959:\tlearn: 0.0642116\ttotal: 1h 45m 30s\tremaining: 2h 21m 46s\n",
      "960:\tlearn: 0.0641439\ttotal: 1h 45m 36s\tremaining: 2h 21m 39s\n",
      "961:\tlearn: 0.0640173\ttotal: 1h 45m 43s\tremaining: 2h 21m 33s\n",
      "962:\tlearn: 0.0638946\ttotal: 1h 45m 49s\tremaining: 2h 21m 26s\n",
      "963:\tlearn: 0.0637849\ttotal: 1h 45m 56s\tremaining: 2h 21m 19s\n",
      "964:\tlearn: 0.0637064\ttotal: 1h 46m 2s\tremaining: 2h 21m 12s\n",
      "965:\tlearn: 0.0636117\ttotal: 1h 46m 9s\tremaining: 2h 21m 5s\n",
      "966:\tlearn: 0.0634846\ttotal: 1h 46m 15s\tremaining: 2h 20m 58s\n",
      "967:\tlearn: 0.0634102\ttotal: 1h 46m 21s\tremaining: 2h 20m 52s\n",
      "968:\tlearn: 0.0633417\ttotal: 1h 46m 28s\tremaining: 2h 20m 45s\n",
      "969:\tlearn: 0.0632541\ttotal: 1h 46m 34s\tremaining: 2h 20m 38s\n",
      "970:\tlearn: 0.0631551\ttotal: 1h 46m 40s\tremaining: 2h 20m 31s\n",
      "971:\tlearn: 0.0630420\ttotal: 1h 46m 47s\tremaining: 2h 20m 24s\n",
      "972:\tlearn: 0.0629619\ttotal: 1h 46m 53s\tremaining: 2h 20m 17s\n",
      "973:\tlearn: 0.0628344\ttotal: 1h 47m\tremaining: 2h 20m 10s\n",
      "974:\tlearn: 0.0627245\ttotal: 1h 47m 6s\tremaining: 2h 20m 4s\n",
      "975:\tlearn: 0.0626080\ttotal: 1h 47m 13s\tremaining: 2h 19m 57s\n",
      "976:\tlearn: 0.0625103\ttotal: 1h 47m 19s\tremaining: 2h 19m 50s\n",
      "977:\tlearn: 0.0623980\ttotal: 1h 47m 25s\tremaining: 2h 19m 43s\n",
      "978:\tlearn: 0.0622970\ttotal: 1h 47m 32s\tremaining: 2h 19m 36s\n",
      "979:\tlearn: 0.0621948\ttotal: 1h 47m 39s\tremaining: 2h 19m 30s\n",
      "980:\tlearn: 0.0620922\ttotal: 1h 47m 45s\tremaining: 2h 19m 23s\n",
      "981:\tlearn: 0.0620229\ttotal: 1h 47m 52s\tremaining: 2h 19m 17s\n",
      "982:\tlearn: 0.0619282\ttotal: 1h 47m 58s\tremaining: 2h 19m 10s\n",
      "983:\tlearn: 0.0617973\ttotal: 1h 48m 4s\tremaining: 2h 19m 3s\n",
      "984:\tlearn: 0.0617198\ttotal: 1h 48m 11s\tremaining: 2h 18m 56s\n",
      "985:\tlearn: 0.0616388\ttotal: 1h 48m 17s\tremaining: 2h 18m 49s\n",
      "986:\tlearn: 0.0615223\ttotal: 1h 48m 24s\tremaining: 2h 18m 43s\n",
      "987:\tlearn: 0.0614463\ttotal: 1h 48m 30s\tremaining: 2h 18m 36s\n",
      "988:\tlearn: 0.0613784\ttotal: 1h 48m 37s\tremaining: 2h 18m 29s\n",
      "989:\tlearn: 0.0612915\ttotal: 1h 48m 43s\tremaining: 2h 18m 22s\n",
      "990:\tlearn: 0.0612092\ttotal: 1h 48m 49s\tremaining: 2h 18m 15s\n",
      "991:\tlearn: 0.0611136\ttotal: 1h 48m 56s\tremaining: 2h 18m 9s\n",
      "992:\tlearn: 0.0609969\ttotal: 1h 49m 2s\tremaining: 2h 18m 2s\n",
      "993:\tlearn: 0.0609070\ttotal: 1h 49m 9s\tremaining: 2h 17m 55s\n",
      "994:\tlearn: 0.0608555\ttotal: 1h 49m 15s\tremaining: 2h 17m 48s\n",
      "995:\tlearn: 0.0607710\ttotal: 1h 49m 21s\tremaining: 2h 17m 41s\n",
      "996:\tlearn: 0.0606631\ttotal: 1h 49m 28s\tremaining: 2h 17m 35s\n",
      "997:\tlearn: 0.0605538\ttotal: 1h 49m 34s\tremaining: 2h 17m 28s\n",
      "998:\tlearn: 0.0604727\ttotal: 1h 49m 41s\tremaining: 2h 17m 21s\n",
      "999:\tlearn: 0.0603999\ttotal: 1h 49m 47s\tremaining: 2h 17m 14s\n",
      "1000:\tlearn: 0.0603197\ttotal: 1h 49m 54s\tremaining: 2h 17m 7s\n",
      "1001:\tlearn: 0.0602425\ttotal: 1h 50m\tremaining: 2h 17m 1s\n",
      "1002:\tlearn: 0.0601460\ttotal: 1h 50m 6s\tremaining: 2h 16m 54s\n",
      "1003:\tlearn: 0.0600472\ttotal: 1h 50m 13s\tremaining: 2h 16m 47s\n",
      "1004:\tlearn: 0.0599502\ttotal: 1h 50m 19s\tremaining: 2h 16m 40s\n",
      "1005:\tlearn: 0.0598639\ttotal: 1h 50m 26s\tremaining: 2h 16m 33s\n",
      "1006:\tlearn: 0.0597923\ttotal: 1h 50m 32s\tremaining: 2h 16m 27s\n",
      "1007:\tlearn: 0.0597065\ttotal: 1h 50m 38s\tremaining: 2h 16m 20s\n",
      "1008:\tlearn: 0.0596358\ttotal: 1h 50m 45s\tremaining: 2h 16m 13s\n",
      "1009:\tlearn: 0.0595632\ttotal: 1h 50m 51s\tremaining: 2h 16m 6s\n",
      "1010:\tlearn: 0.0594783\ttotal: 1h 50m 58s\tremaining: 2h 15m 59s\n",
      "1011:\tlearn: 0.0594061\ttotal: 1h 51m 4s\tremaining: 2h 15m 52s\n",
      "1012:\tlearn: 0.0593835\ttotal: 1h 51m 10s\tremaining: 2h 15m 46s\n",
      "1013:\tlearn: 0.0592724\ttotal: 1h 51m 17s\tremaining: 2h 15m 39s\n",
      "1014:\tlearn: 0.0592036\ttotal: 1h 51m 23s\tremaining: 2h 15m 32s\n",
      "1015:\tlearn: 0.0591484\ttotal: 1h 51m 30s\tremaining: 2h 15m 25s\n",
      "1016:\tlearn: 0.0590702\ttotal: 1h 51m 36s\tremaining: 2h 15m 19s\n",
      "1017:\tlearn: 0.0590089\ttotal: 1h 51m 43s\tremaining: 2h 15m 12s\n",
      "1018:\tlearn: 0.0589202\ttotal: 1h 51m 49s\tremaining: 2h 15m 5s\n",
      "1019:\tlearn: 0.0588359\ttotal: 1h 51m 56s\tremaining: 2h 14m 58s\n",
      "1020:\tlearn: 0.0587384\ttotal: 1h 52m 2s\tremaining: 2h 14m 51s\n",
      "1021:\tlearn: 0.0586470\ttotal: 1h 52m 8s\tremaining: 2h 14m 45s\n",
      "1022:\tlearn: 0.0585452\ttotal: 1h 52m 15s\tremaining: 2h 14m 38s\n",
      "1023:\tlearn: 0.0584615\ttotal: 1h 52m 21s\tremaining: 2h 14m 31s\n",
      "1024:\tlearn: 0.0583605\ttotal: 1h 52m 27s\tremaining: 2h 14m 24s\n",
      "1025:\tlearn: 0.0582657\ttotal: 1h 52m 34s\tremaining: 2h 14m 17s\n",
      "1026:\tlearn: 0.0582068\ttotal: 1h 52m 40s\tremaining: 2h 14m 10s\n",
      "1027:\tlearn: 0.0581138\ttotal: 1h 52m 47s\tremaining: 2h 14m 4s\n",
      "1028:\tlearn: 0.0580252\ttotal: 1h 52m 53s\tremaining: 2h 13m 57s\n",
      "1029:\tlearn: 0.0579601\ttotal: 1h 52m 59s\tremaining: 2h 13m 50s\n",
      "1030:\tlearn: 0.0578699\ttotal: 1h 53m 6s\tremaining: 2h 13m 43s\n",
      "1031:\tlearn: 0.0577882\ttotal: 1h 53m 12s\tremaining: 2h 13m 37s\n",
      "1032:\tlearn: 0.0577408\ttotal: 1h 53m 19s\tremaining: 2h 13m 30s\n",
      "1033:\tlearn: 0.0576907\ttotal: 1h 53m 25s\tremaining: 2h 13m 23s\n",
      "1034:\tlearn: 0.0576329\ttotal: 1h 53m 32s\tremaining: 2h 13m 17s\n",
      "1035:\tlearn: 0.0575573\ttotal: 1h 53m 38s\tremaining: 2h 13m 10s\n",
      "1036:\tlearn: 0.0574879\ttotal: 1h 53m 45s\tremaining: 2h 13m 3s\n",
      "1037:\tlearn: 0.0573859\ttotal: 1h 53m 51s\tremaining: 2h 12m 56s\n",
      "1038:\tlearn: 0.0573345\ttotal: 1h 53m 57s\tremaining: 2h 12m 49s\n",
      "1039:\tlearn: 0.0572530\ttotal: 1h 54m 4s\tremaining: 2h 12m 43s\n",
      "1040:\tlearn: 0.0571648\ttotal: 1h 54m 10s\tremaining: 2h 12m 36s\n",
      "1041:\tlearn: 0.0570762\ttotal: 1h 54m 17s\tremaining: 2h 12m 29s\n",
      "1042:\tlearn: 0.0569950\ttotal: 1h 54m 23s\tremaining: 2h 12m 22s\n",
      "1043:\tlearn: 0.0568900\ttotal: 1h 54m 29s\tremaining: 2h 12m 15s\n",
      "1044:\tlearn: 0.0568399\ttotal: 1h 54m 36s\tremaining: 2h 12m 9s\n",
      "1045:\tlearn: 0.0567955\ttotal: 1h 54m 42s\tremaining: 2h 12m 2s\n",
      "1046:\tlearn: 0.0566968\ttotal: 1h 54m 49s\tremaining: 2h 11m 55s\n",
      "1047:\tlearn: 0.0566245\ttotal: 1h 54m 55s\tremaining: 2h 11m 48s\n",
      "1048:\tlearn: 0.0565641\ttotal: 1h 55m 2s\tremaining: 2h 11m 42s\n",
      "1049:\tlearn: 0.0564785\ttotal: 1h 55m 8s\tremaining: 2h 11m 35s\n",
      "1050:\tlearn: 0.0563738\ttotal: 1h 55m 14s\tremaining: 2h 11m 28s\n",
      "1051:\tlearn: 0.0563124\ttotal: 1h 55m 21s\tremaining: 2h 11m 21s\n",
      "1052:\tlearn: 0.0562234\ttotal: 1h 55m 27s\tremaining: 2h 11m 14s\n",
      "1053:\tlearn: 0.0561853\ttotal: 1h 55m 34s\tremaining: 2h 11m 8s\n",
      "1054:\tlearn: 0.0560704\ttotal: 1h 55m 40s\tremaining: 2h 11m 1s\n",
      "1055:\tlearn: 0.0559805\ttotal: 1h 55m 46s\tremaining: 2h 10m 54s\n",
      "1056:\tlearn: 0.0559127\ttotal: 1h 55m 53s\tremaining: 2h 10m 47s\n",
      "1057:\tlearn: 0.0558292\ttotal: 1h 55m 59s\tremaining: 2h 10m 41s\n",
      "1058:\tlearn: 0.0557448\ttotal: 1h 56m 6s\tremaining: 2h 10m 34s\n",
      "1059:\tlearn: 0.0557133\ttotal: 1h 56m 12s\tremaining: 2h 10m 27s\n",
      "1060:\tlearn: 0.0556247\ttotal: 1h 56m 18s\tremaining: 2h 10m 20s\n",
      "1061:\tlearn: 0.0555869\ttotal: 1h 56m 25s\tremaining: 2h 10m 14s\n",
      "1062:\tlearn: 0.0554981\ttotal: 1h 56m 31s\tremaining: 2h 10m 7s\n",
      "1063:\tlearn: 0.0554184\ttotal: 1h 56m 38s\tremaining: 2h 10m\n",
      "1064:\tlearn: 0.0553853\ttotal: 1h 56m 44s\tremaining: 2h 9m 53s\n",
      "1065:\tlearn: 0.0552993\ttotal: 1h 56m 51s\tremaining: 2h 9m 47s\n",
      "1066:\tlearn: 0.0552069\ttotal: 1h 56m 57s\tremaining: 2h 9m 40s\n",
      "1067:\tlearn: 0.0551537\ttotal: 1h 57m 3s\tremaining: 2h 9m 33s\n",
      "1068:\tlearn: 0.0550778\ttotal: 1h 57m 10s\tremaining: 2h 9m 26s\n",
      "1069:\tlearn: 0.0550208\ttotal: 1h 57m 16s\tremaining: 2h 9m 20s\n",
      "1070:\tlearn: 0.0549381\ttotal: 1h 57m 23s\tremaining: 2h 9m 13s\n",
      "1071:\tlearn: 0.0548509\ttotal: 1h 57m 29s\tremaining: 2h 9m 6s\n",
      "1072:\tlearn: 0.0547653\ttotal: 1h 57m 35s\tremaining: 2h 8m 59s\n",
      "1073:\tlearn: 0.0547079\ttotal: 1h 57m 42s\tremaining: 2h 8m 53s\n",
      "1074:\tlearn: 0.0546467\ttotal: 1h 57m 48s\tremaining: 2h 8m 46s\n",
      "1075:\tlearn: 0.0545608\ttotal: 1h 57m 55s\tremaining: 2h 8m 39s\n",
      "1076:\tlearn: 0.0545092\ttotal: 1h 58m 1s\tremaining: 2h 8m 32s\n",
      "1077:\tlearn: 0.0544127\ttotal: 1h 58m 7s\tremaining: 2h 8m 26s\n",
      "1078:\tlearn: 0.0543138\ttotal: 1h 58m 14s\tremaining: 2h 8m 19s\n",
      "1079:\tlearn: 0.0542557\ttotal: 1h 58m 20s\tremaining: 2h 8m 12s\n",
      "1080:\tlearn: 0.0541590\ttotal: 1h 58m 27s\tremaining: 2h 8m 5s\n",
      "1081:\tlearn: 0.0540848\ttotal: 1h 58m 33s\tremaining: 2h 7m 59s\n",
      "1082:\tlearn: 0.0540009\ttotal: 1h 58m 40s\tremaining: 2h 7m 52s\n",
      "1083:\tlearn: 0.0539323\ttotal: 1h 58m 46s\tremaining: 2h 7m 45s\n",
      "1084:\tlearn: 0.0538697\ttotal: 1h 58m 52s\tremaining: 2h 7m 38s\n",
      "1085:\tlearn: 0.0538214\ttotal: 1h 58m 59s\tremaining: 2h 7m 32s\n",
      "1086:\tlearn: 0.0537292\ttotal: 1h 59m 5s\tremaining: 2h 7m 25s\n",
      "1087:\tlearn: 0.0536512\ttotal: 1h 59m 12s\tremaining: 2h 7m 18s\n",
      "1088:\tlearn: 0.0535747\ttotal: 1h 59m 18s\tremaining: 2h 7m 11s\n",
      "1089:\tlearn: 0.0535360\ttotal: 1h 59m 25s\tremaining: 2h 7m 5s\n",
      "1090:\tlearn: 0.0534628\ttotal: 1h 59m 31s\tremaining: 2h 6m 58s\n",
      "1091:\tlearn: 0.0534051\ttotal: 1h 59m 37s\tremaining: 2h 6m 51s\n",
      "1092:\tlearn: 0.0533460\ttotal: 1h 59m 44s\tremaining: 2h 6m 44s\n",
      "1093:\tlearn: 0.0532949\ttotal: 1h 59m 50s\tremaining: 2h 6m 38s\n",
      "1094:\tlearn: 0.0532157\ttotal: 1h 59m 57s\tremaining: 2h 6m 31s\n",
      "1095:\tlearn: 0.0531402\ttotal: 2h 3s\tremaining: 2h 6m 24s\n",
      "1096:\tlearn: 0.0530707\ttotal: 2h 10s\tremaining: 2h 6m 18s\n",
      "1097:\tlearn: 0.0529903\ttotal: 2h 16s\tremaining: 2h 6m 11s\n",
      "1098:\tlearn: 0.0529167\ttotal: 2h 22s\tremaining: 2h 6m 4s\n",
      "1099:\tlearn: 0.0528300\ttotal: 2h 29s\tremaining: 2h 5m 57s\n",
      "1100:\tlearn: 0.0527792\ttotal: 2h 35s\tremaining: 2h 5m 51s\n",
      "1101:\tlearn: 0.0526877\ttotal: 2h 42s\tremaining: 2h 5m 44s\n",
      "1102:\tlearn: 0.0526085\ttotal: 2h 48s\tremaining: 2h 5m 37s\n",
      "1103:\tlearn: 0.0525336\ttotal: 2h 55s\tremaining: 2h 5m 31s\n",
      "1104:\tlearn: 0.0524569\ttotal: 2h 1m 1s\tremaining: 2h 5m 24s\n",
      "1105:\tlearn: 0.0523879\ttotal: 2h 1m 7s\tremaining: 2h 5m 17s\n",
      "1106:\tlearn: 0.0523165\ttotal: 2h 1m 14s\tremaining: 2h 5m 10s\n",
      "1107:\tlearn: 0.0522816\ttotal: 2h 1m 20s\tremaining: 2h 5m 3s\n",
      "1108:\tlearn: 0.0522114\ttotal: 2h 1m 27s\tremaining: 2h 4m 57s\n",
      "1109:\tlearn: 0.0522056\ttotal: 2h 1m 33s\tremaining: 2h 4m 50s\n",
      "1110:\tlearn: 0.0521646\ttotal: 2h 1m 39s\tremaining: 2h 4m 43s\n",
      "1111:\tlearn: 0.0520795\ttotal: 2h 1m 46s\tremaining: 2h 4m 37s\n",
      "1112:\tlearn: 0.0520097\ttotal: 2h 1m 52s\tremaining: 2h 4m 30s\n",
      "1113:\tlearn: 0.0519391\ttotal: 2h 1m 59s\tremaining: 2h 4m 23s\n",
      "1114:\tlearn: 0.0518796\ttotal: 2h 2m 5s\tremaining: 2h 4m 16s\n",
      "1115:\tlearn: 0.0518195\ttotal: 2h 2m 11s\tremaining: 2h 4m 10s\n",
      "1116:\tlearn: 0.0517637\ttotal: 2h 2m 18s\tremaining: 2h 4m 3s\n",
      "1117:\tlearn: 0.0517293\ttotal: 2h 2m 24s\tremaining: 2h 3m 56s\n",
      "1118:\tlearn: 0.0516778\ttotal: 2h 2m 31s\tremaining: 2h 3m 50s\n",
      "1119:\tlearn: 0.0515970\ttotal: 2h 2m 37s\tremaining: 2h 3m 43s\n",
      "1120:\tlearn: 0.0515277\ttotal: 2h 2m 43s\tremaining: 2h 3m 36s\n",
      "1121:\tlearn: 0.0514894\ttotal: 2h 2m 50s\tremaining: 2h 3m 29s\n",
      "1122:\tlearn: 0.0514196\ttotal: 2h 2m 56s\tremaining: 2h 3m 23s\n",
      "1123:\tlearn: 0.0513439\ttotal: 2h 3m 3s\tremaining: 2h 3m 16s\n",
      "1124:\tlearn: 0.0512880\ttotal: 2h 3m 9s\tremaining: 2h 3m 9s\n",
      "1125:\tlearn: 0.0512146\ttotal: 2h 3m 16s\tremaining: 2h 3m 2s\n",
      "1126:\tlearn: 0.0511623\ttotal: 2h 3m 22s\tremaining: 2h 2m 56s\n",
      "1127:\tlearn: 0.0511144\ttotal: 2h 3m 28s\tremaining: 2h 2m 49s\n",
      "1128:\tlearn: 0.0510515\ttotal: 2h 3m 35s\tremaining: 2h 2m 42s\n",
      "1129:\tlearn: 0.0510244\ttotal: 2h 3m 41s\tremaining: 2h 2m 36s\n",
      "1130:\tlearn: 0.0509748\ttotal: 2h 3m 48s\tremaining: 2h 2m 29s\n",
      "1131:\tlearn: 0.0509255\ttotal: 2h 3m 54s\tremaining: 2h 2m 22s\n",
      "1132:\tlearn: 0.0508709\ttotal: 2h 4m\tremaining: 2h 2m 15s\n",
      "1133:\tlearn: 0.0508506\ttotal: 2h 4m 7s\tremaining: 2h 2m 9s\n",
      "1134:\tlearn: 0.0507920\ttotal: 2h 4m 13s\tremaining: 2h 2m 2s\n",
      "1135:\tlearn: 0.0507128\ttotal: 2h 4m 20s\tremaining: 2h 1m 55s\n",
      "1136:\tlearn: 0.0506467\ttotal: 2h 4m 26s\tremaining: 2h 1m 49s\n",
      "1137:\tlearn: 0.0505918\ttotal: 2h 4m 33s\tremaining: 2h 1m 42s\n",
      "1138:\tlearn: 0.0505660\ttotal: 2h 4m 39s\tremaining: 2h 1m 35s\n",
      "1139:\tlearn: 0.0504923\ttotal: 2h 4m 45s\tremaining: 2h 1m 28s\n",
      "1140:\tlearn: 0.0504356\ttotal: 2h 4m 52s\tremaining: 2h 1m 22s\n",
      "1141:\tlearn: 0.0503678\ttotal: 2h 4m 58s\tremaining: 2h 1m 15s\n",
      "1142:\tlearn: 0.0502813\ttotal: 2h 5m 5s\tremaining: 2h 1m 8s\n",
      "1143:\tlearn: 0.0502125\ttotal: 2h 5m 11s\tremaining: 2h 1m 2s\n",
      "1144:\tlearn: 0.0501396\ttotal: 2h 5m 18s\tremaining: 2h 55s\n",
      "1145:\tlearn: 0.0500956\ttotal: 2h 5m 24s\tremaining: 2h 48s\n",
      "1146:\tlearn: 0.0500487\ttotal: 2h 5m 30s\tremaining: 2h 42s\n",
      "1147:\tlearn: 0.0499953\ttotal: 2h 5m 37s\tremaining: 2h 35s\n",
      "1148:\tlearn: 0.0499311\ttotal: 2h 5m 43s\tremaining: 2h 28s\n",
      "1149:\tlearn: 0.0498589\ttotal: 2h 5m 50s\tremaining: 2h 21s\n",
      "1150:\tlearn: 0.0497885\ttotal: 2h 5m 56s\tremaining: 2h 15s\n",
      "1151:\tlearn: 0.0497609\ttotal: 2h 6m 3s\tremaining: 2h 8s\n",
      "1152:\tlearn: 0.0497146\ttotal: 2h 6m 9s\tremaining: 2h 1s\n",
      "1153:\tlearn: 0.0496640\ttotal: 2h 6m 16s\tremaining: 1h 59m 55s\n",
      "1154:\tlearn: 0.0496218\ttotal: 2h 6m 22s\tremaining: 1h 59m 48s\n",
      "1155:\tlearn: 0.0495797\ttotal: 2h 6m 28s\tremaining: 1h 59m 41s\n",
      "1156:\tlearn: 0.0495512\ttotal: 2h 6m 35s\tremaining: 1h 59m 35s\n",
      "1157:\tlearn: 0.0495037\ttotal: 2h 6m 41s\tremaining: 1h 59m 28s\n",
      "1158:\tlearn: 0.0494568\ttotal: 2h 6m 48s\tremaining: 1h 59m 21s\n",
      "1159:\tlearn: 0.0493830\ttotal: 2h 6m 54s\tremaining: 1h 59m 15s\n",
      "1160:\tlearn: 0.0493169\ttotal: 2h 7m\tremaining: 1h 59m 8s\n",
      "1161:\tlearn: 0.0492487\ttotal: 2h 7m 7s\tremaining: 1h 59m 1s\n",
      "1162:\tlearn: 0.0491809\ttotal: 2h 7m 13s\tremaining: 1h 58m 54s\n",
      "1163:\tlearn: 0.0491238\ttotal: 2h 7m 20s\tremaining: 1h 58m 48s\n",
      "1164:\tlearn: 0.0490512\ttotal: 2h 7m 26s\tremaining: 1h 58m 41s\n",
      "1165:\tlearn: 0.0489860\ttotal: 2h 7m 33s\tremaining: 1h 58m 34s\n",
      "1166:\tlearn: 0.0489352\ttotal: 2h 7m 39s\tremaining: 1h 58m 28s\n",
      "1167:\tlearn: 0.0489036\ttotal: 2h 7m 46s\tremaining: 1h 58m 21s\n",
      "1168:\tlearn: 0.0488249\ttotal: 2h 7m 52s\tremaining: 1h 58m 15s\n",
      "1169:\tlearn: 0.0487896\ttotal: 2h 7m 58s\tremaining: 1h 58m 8s\n",
      "1170:\tlearn: 0.0487310\ttotal: 2h 8m 5s\tremaining: 1h 58m 1s\n",
      "1171:\tlearn: 0.0486616\ttotal: 2h 8m 11s\tremaining: 1h 57m 54s\n",
      "1172:\tlearn: 0.0486167\ttotal: 2h 8m 18s\tremaining: 1h 57m 48s\n",
      "1173:\tlearn: 0.0485916\ttotal: 2h 8m 24s\tremaining: 1h 57m 41s\n",
      "1174:\tlearn: 0.0485184\ttotal: 2h 8m 31s\tremaining: 1h 57m 34s\n",
      "1175:\tlearn: 0.0484733\ttotal: 2h 8m 37s\tremaining: 1h 57m 28s\n",
      "1176:\tlearn: 0.0484145\ttotal: 2h 8m 43s\tremaining: 1h 57m 21s\n",
      "1177:\tlearn: 0.0483808\ttotal: 2h 8m 50s\tremaining: 1h 57m 14s\n",
      "1178:\tlearn: 0.0483297\ttotal: 2h 8m 56s\tremaining: 1h 57m 7s\n",
      "1179:\tlearn: 0.0482652\ttotal: 2h 9m 3s\tremaining: 1h 57m 1s\n",
      "1180:\tlearn: 0.0482114\ttotal: 2h 9m 9s\tremaining: 1h 56m 54s\n",
      "1181:\tlearn: 0.0481561\ttotal: 2h 9m 15s\tremaining: 1h 56m 47s\n",
      "1182:\tlearn: 0.0481041\ttotal: 2h 9m 22s\tremaining: 1h 56m 41s\n",
      "1183:\tlearn: 0.0480517\ttotal: 2h 9m 28s\tremaining: 1h 56m 34s\n",
      "1184:\tlearn: 0.0479858\ttotal: 2h 9m 35s\tremaining: 1h 56m 27s\n",
      "1185:\tlearn: 0.0479152\ttotal: 2h 9m 41s\tremaining: 1h 56m 20s\n",
      "1186:\tlearn: 0.0478731\ttotal: 2h 9m 47s\tremaining: 1h 56m 14s\n",
      "1187:\tlearn: 0.0478333\ttotal: 2h 9m 54s\tremaining: 1h 56m 7s\n",
      "1188:\tlearn: 0.0477661\ttotal: 2h 10m\tremaining: 1h 56m\n",
      "1189:\tlearn: 0.0477324\ttotal: 2h 10m 7s\tremaining: 1h 55m 54s\n",
      "1190:\tlearn: 0.0477050\ttotal: 2h 10m 13s\tremaining: 1h 55m 47s\n",
      "1191:\tlearn: 0.0476533\ttotal: 2h 10m 19s\tremaining: 1h 55m 40s\n",
      "1192:\tlearn: 0.0475926\ttotal: 2h 10m 26s\tremaining: 1h 55m 34s\n",
      "1193:\tlearn: 0.0475452\ttotal: 2h 10m 32s\tremaining: 1h 55m 27s\n",
      "1194:\tlearn: 0.0474949\ttotal: 2h 10m 39s\tremaining: 1h 55m 20s\n",
      "1195:\tlearn: 0.0474415\ttotal: 2h 10m 45s\tremaining: 1h 55m 14s\n",
      "1196:\tlearn: 0.0473961\ttotal: 2h 10m 51s\tremaining: 1h 55m 7s\n",
      "1197:\tlearn: 0.0473217\ttotal: 2h 10m 58s\tremaining: 1h 55m\n",
      "1198:\tlearn: 0.0472625\ttotal: 2h 11m 4s\tremaining: 1h 54m 54s\n",
      "1199:\tlearn: 0.0472192\ttotal: 2h 11m 11s\tremaining: 1h 54m 47s\n",
      "1200:\tlearn: 0.0471620\ttotal: 2h 11m 17s\tremaining: 1h 54m 40s\n",
      "1201:\tlearn: 0.0471171\ttotal: 2h 11m 24s\tremaining: 1h 54m 34s\n",
      "1202:\tlearn: 0.0470540\ttotal: 2h 11m 30s\tremaining: 1h 54m 27s\n",
      "1203:\tlearn: 0.0470009\ttotal: 2h 11m 37s\tremaining: 1h 54m 20s\n",
      "1204:\tlearn: 0.0469339\ttotal: 2h 11m 43s\tremaining: 1h 54m 13s\n",
      "1205:\tlearn: 0.0468577\ttotal: 2h 11m 49s\tremaining: 1h 54m 7s\n",
      "1206:\tlearn: 0.0467944\ttotal: 2h 11m 56s\tremaining: 1h 54m\n",
      "1207:\tlearn: 0.0467593\ttotal: 2h 12m 2s\tremaining: 1h 53m 53s\n",
      "1208:\tlearn: 0.0466983\ttotal: 2h 12m 9s\tremaining: 1h 53m 47s\n",
      "1209:\tlearn: 0.0466509\ttotal: 2h 12m 15s\tremaining: 1h 53m 40s\n",
      "1210:\tlearn: 0.0466023\ttotal: 2h 12m 21s\tremaining: 1h 53m 33s\n",
      "1211:\tlearn: 0.0465421\ttotal: 2h 12m 28s\tremaining: 1h 53m 27s\n",
      "1212:\tlearn: 0.0464836\ttotal: 2h 12m 34s\tremaining: 1h 53m 20s\n",
      "1213:\tlearn: 0.0464319\ttotal: 2h 12m 41s\tremaining: 1h 53m 13s\n",
      "1214:\tlearn: 0.0463888\ttotal: 2h 12m 47s\tremaining: 1h 53m 7s\n",
      "1215:\tlearn: 0.0463314\ttotal: 2h 12m 53s\tremaining: 1h 53m\n",
      "1216:\tlearn: 0.0462637\ttotal: 2h 13m\tremaining: 1h 52m 53s\n",
      "1217:\tlearn: 0.0461994\ttotal: 2h 13m 6s\tremaining: 1h 52m 47s\n",
      "1218:\tlearn: 0.0461481\ttotal: 2h 13m 13s\tremaining: 1h 52m 40s\n",
      "1219:\tlearn: 0.0461115\ttotal: 2h 13m 19s\tremaining: 1h 52m 33s\n",
      "1220:\tlearn: 0.0460891\ttotal: 2h 13m 25s\tremaining: 1h 52m 27s\n",
      "1221:\tlearn: 0.0460274\ttotal: 2h 13m 32s\tremaining: 1h 52m 20s\n",
      "1222:\tlearn: 0.0459818\ttotal: 2h 13m 38s\tremaining: 1h 52m 13s\n",
      "1223:\tlearn: 0.0459282\ttotal: 2h 13m 45s\tremaining: 1h 52m 7s\n",
      "1224:\tlearn: 0.0458675\ttotal: 2h 13m 51s\tremaining: 1h 52m\n",
      "1225:\tlearn: 0.0458245\ttotal: 2h 13m 58s\tremaining: 1h 51m 53s\n",
      "1226:\tlearn: 0.0458048\ttotal: 2h 14m 4s\tremaining: 1h 51m 47s\n",
      "1227:\tlearn: 0.0457762\ttotal: 2h 14m 10s\tremaining: 1h 51m 40s\n",
      "1228:\tlearn: 0.0457331\ttotal: 2h 14m 17s\tremaining: 1h 51m 33s\n",
      "1229:\tlearn: 0.0456897\ttotal: 2h 14m 23s\tremaining: 1h 51m 27s\n",
      "1230:\tlearn: 0.0456415\ttotal: 2h 14m 30s\tremaining: 1h 51m 20s\n",
      "1231:\tlearn: 0.0456066\ttotal: 2h 14m 36s\tremaining: 1h 51m 13s\n",
      "1232:\tlearn: 0.0455404\ttotal: 2h 14m 43s\tremaining: 1h 51m 7s\n",
      "1233:\tlearn: 0.0454737\ttotal: 2h 14m 49s\tremaining: 1h 51m\n",
      "1234:\tlearn: 0.0454170\ttotal: 2h 14m 56s\tremaining: 1h 50m 53s\n",
      "1235:\tlearn: 0.0453643\ttotal: 2h 15m 2s\tremaining: 1h 50m 47s\n",
      "1236:\tlearn: 0.0452972\ttotal: 2h 15m 8s\tremaining: 1h 50m 40s\n",
      "1237:\tlearn: 0.0452457\ttotal: 2h 15m 15s\tremaining: 1h 50m 33s\n",
      "1238:\tlearn: 0.0451992\ttotal: 2h 15m 21s\tremaining: 1h 50m 27s\n",
      "1239:\tlearn: 0.0451379\ttotal: 2h 15m 28s\tremaining: 1h 50m 20s\n",
      "1240:\tlearn: 0.0450969\ttotal: 2h 15m 34s\tremaining: 1h 50m 13s\n",
      "1241:\tlearn: 0.0450254\ttotal: 2h 15m 41s\tremaining: 1h 50m 7s\n",
      "1242:\tlearn: 0.0449850\ttotal: 2h 15m 47s\tremaining: 1h 50m\n",
      "1243:\tlearn: 0.0449614\ttotal: 2h 15m 53s\tremaining: 1h 49m 53s\n",
      "1244:\tlearn: 0.0448987\ttotal: 2h 16m\tremaining: 1h 49m 47s\n",
      "1245:\tlearn: 0.0448405\ttotal: 2h 16m 6s\tremaining: 1h 49m 40s\n",
      "1246:\tlearn: 0.0448080\ttotal: 2h 16m 13s\tremaining: 1h 49m 33s\n",
      "1247:\tlearn: 0.0447429\ttotal: 2h 16m 19s\tremaining: 1h 49m 27s\n",
      "1248:\tlearn: 0.0446863\ttotal: 2h 16m 25s\tremaining: 1h 49m 20s\n",
      "1249:\tlearn: 0.0446357\ttotal: 2h 16m 32s\tremaining: 1h 49m 13s\n",
      "1250:\tlearn: 0.0445848\ttotal: 2h 16m 38s\tremaining: 1h 49m 7s\n",
      "1251:\tlearn: 0.0445270\ttotal: 2h 16m 45s\tremaining: 1h 49m\n",
      "1252:\tlearn: 0.0444761\ttotal: 2h 16m 51s\tremaining: 1h 48m 53s\n",
      "1253:\tlearn: 0.0444169\ttotal: 2h 16m 58s\tremaining: 1h 48m 47s\n",
      "1254:\tlearn: 0.0443584\ttotal: 2h 17m 4s\tremaining: 1h 48m 40s\n",
      "1255:\tlearn: 0.0443142\ttotal: 2h 17m 10s\tremaining: 1h 48m 33s\n",
      "1256:\tlearn: 0.0442521\ttotal: 2h 17m 17s\tremaining: 1h 48m 27s\n",
      "1257:\tlearn: 0.0441992\ttotal: 2h 17m 23s\tremaining: 1h 48m 20s\n",
      "1258:\tlearn: 0.0441553\ttotal: 2h 17m 30s\tremaining: 1h 48m 13s\n",
      "1259:\tlearn: 0.0441017\ttotal: 2h 17m 36s\tremaining: 1h 48m 7s\n",
      "1260:\tlearn: 0.0440733\ttotal: 2h 17m 43s\tremaining: 1h 48m\n",
      "1261:\tlearn: 0.0440252\ttotal: 2h 17m 49s\tremaining: 1h 47m 54s\n",
      "1262:\tlearn: 0.0439644\ttotal: 2h 17m 56s\tremaining: 1h 47m 47s\n",
      "1263:\tlearn: 0.0439152\ttotal: 2h 18m 2s\tremaining: 1h 47m 41s\n",
      "1264:\tlearn: 0.0438516\ttotal: 2h 18m 9s\tremaining: 1h 47m 34s\n",
      "1265:\tlearn: 0.0437957\ttotal: 2h 18m 15s\tremaining: 1h 47m 27s\n",
      "1266:\tlearn: 0.0437530\ttotal: 2h 18m 22s\tremaining: 1h 47m 21s\n",
      "1267:\tlearn: 0.0437239\ttotal: 2h 18m 28s\tremaining: 1h 47m 14s\n",
      "1268:\tlearn: 0.0436734\ttotal: 2h 18m 34s\tremaining: 1h 47m 7s\n",
      "1269:\tlearn: 0.0436202\ttotal: 2h 18m 41s\tremaining: 1h 47m 1s\n",
      "1270:\tlearn: 0.0435656\ttotal: 2h 18m 47s\tremaining: 1h 46m 54s\n",
      "1271:\tlearn: 0.0435186\ttotal: 2h 18m 54s\tremaining: 1h 46m 47s\n",
      "1272:\tlearn: 0.0434811\ttotal: 2h 19m\tremaining: 1h 46m 41s\n",
      "1273:\tlearn: 0.0434457\ttotal: 2h 19m 7s\tremaining: 1h 46m 34s\n",
      "1274:\tlearn: 0.0433919\ttotal: 2h 19m 13s\tremaining: 1h 46m 28s\n",
      "1275:\tlearn: 0.0433382\ttotal: 2h 19m 20s\tremaining: 1h 46m 21s\n",
      "1276:\tlearn: 0.0432929\ttotal: 2h 19m 26s\tremaining: 1h 46m 14s\n",
      "1277:\tlearn: 0.0432529\ttotal: 2h 19m 32s\tremaining: 1h 46m 8s\n",
      "1278:\tlearn: 0.0432495\ttotal: 2h 19m 39s\tremaining: 1h 46m 1s\n",
      "1279:\tlearn: 0.0431973\ttotal: 2h 19m 45s\tremaining: 1h 45m 54s\n",
      "1280:\tlearn: 0.0431547\ttotal: 2h 19m 52s\tremaining: 1h 45m 48s\n",
      "1281:\tlearn: 0.0431015\ttotal: 2h 19m 58s\tremaining: 1h 45m 41s\n",
      "1282:\tlearn: 0.0430654\ttotal: 2h 20m 5s\tremaining: 1h 45m 34s\n",
      "1283:\tlearn: 0.0430047\ttotal: 2h 20m 11s\tremaining: 1h 45m 28s\n",
      "1284:\tlearn: 0.0429728\ttotal: 2h 20m 17s\tremaining: 1h 45m 21s\n",
      "1285:\tlearn: 0.0429212\ttotal: 2h 20m 24s\tremaining: 1h 45m 15s\n",
      "1286:\tlearn: 0.0428750\ttotal: 2h 20m 30s\tremaining: 1h 45m 8s\n",
      "1287:\tlearn: 0.0428331\ttotal: 2h 20m 37s\tremaining: 1h 45m 1s\n",
      "1288:\tlearn: 0.0427739\ttotal: 2h 20m 43s\tremaining: 1h 44m 55s\n",
      "1289:\tlearn: 0.0427277\ttotal: 2h 20m 50s\tremaining: 1h 44m 48s\n",
      "1290:\tlearn: 0.0426764\ttotal: 2h 20m 56s\tremaining: 1h 44m 41s\n",
      "1291:\tlearn: 0.0426311\ttotal: 2h 21m 2s\tremaining: 1h 44m 35s\n",
      "1292:\tlearn: 0.0426055\ttotal: 2h 21m 9s\tremaining: 1h 44m 28s\n",
      "1293:\tlearn: 0.0425572\ttotal: 2h 21m 15s\tremaining: 1h 44m 21s\n",
      "1294:\tlearn: 0.0424981\ttotal: 2h 21m 22s\tremaining: 1h 44m 15s\n",
      "1295:\tlearn: 0.0424478\ttotal: 2h 21m 28s\tremaining: 1h 44m 8s\n",
      "1296:\tlearn: 0.0424069\ttotal: 2h 21m 35s\tremaining: 1h 44m 1s\n",
      "1297:\tlearn: 0.0423701\ttotal: 2h 21m 41s\tremaining: 1h 43m 55s\n",
      "1298:\tlearn: 0.0423208\ttotal: 2h 21m 48s\tremaining: 1h 43m 48s\n",
      "1299:\tlearn: 0.0422691\ttotal: 2h 21m 54s\tremaining: 1h 43m 42s\n",
      "1300:\tlearn: 0.0422115\ttotal: 2h 22m\tremaining: 1h 43m 35s\n",
      "1301:\tlearn: 0.0421524\ttotal: 2h 22m 7s\tremaining: 1h 43m 28s\n",
      "1302:\tlearn: 0.0421243\ttotal: 2h 22m 13s\tremaining: 1h 43m 22s\n",
      "1303:\tlearn: 0.0420741\ttotal: 2h 22m 20s\tremaining: 1h 43m 15s\n",
      "1304:\tlearn: 0.0420238\ttotal: 2h 22m 26s\tremaining: 1h 43m 8s\n",
      "1305:\tlearn: 0.0419949\ttotal: 2h 22m 33s\tremaining: 1h 43m 2s\n",
      "1306:\tlearn: 0.0419534\ttotal: 2h 22m 39s\tremaining: 1h 42m 55s\n",
      "1307:\tlearn: 0.0419135\ttotal: 2h 22m 45s\tremaining: 1h 42m 49s\n",
      "1308:\tlearn: 0.0418554\ttotal: 2h 22m 52s\tremaining: 1h 42m 42s\n",
      "1309:\tlearn: 0.0418300\ttotal: 2h 22m 58s\tremaining: 1h 42m 35s\n",
      "1310:\tlearn: 0.0417870\ttotal: 2h 23m 5s\tremaining: 1h 42m 29s\n",
      "1311:\tlearn: 0.0417503\ttotal: 2h 23m 11s\tremaining: 1h 42m 22s\n",
      "1312:\tlearn: 0.0417239\ttotal: 2h 23m 18s\tremaining: 1h 42m 15s\n",
      "1313:\tlearn: 0.0416907\ttotal: 2h 23m 24s\tremaining: 1h 42m 9s\n",
      "1314:\tlearn: 0.0416483\ttotal: 2h 23m 30s\tremaining: 1h 42m 2s\n",
      "1315:\tlearn: 0.0416041\ttotal: 2h 23m 37s\tremaining: 1h 41m 56s\n",
      "1316:\tlearn: 0.0415771\ttotal: 2h 23m 43s\tremaining: 1h 41m 49s\n",
      "1317:\tlearn: 0.0415385\ttotal: 2h 23m 50s\tremaining: 1h 41m 42s\n",
      "1318:\tlearn: 0.0414869\ttotal: 2h 23m 56s\tremaining: 1h 41m 36s\n",
      "1319:\tlearn: 0.0414528\ttotal: 2h 24m 3s\tremaining: 1h 41m 29s\n",
      "1320:\tlearn: 0.0414027\ttotal: 2h 24m 9s\tremaining: 1h 41m 22s\n",
      "1321:\tlearn: 0.0413633\ttotal: 2h 24m 16s\tremaining: 1h 41m 16s\n",
      "1322:\tlearn: 0.0413109\ttotal: 2h 24m 22s\tremaining: 1h 41m 9s\n",
      "1323:\tlearn: 0.0412842\ttotal: 2h 24m 29s\tremaining: 1h 41m 3s\n",
      "1324:\tlearn: 0.0412336\ttotal: 2h 24m 35s\tremaining: 1h 40m 56s\n",
      "1325:\tlearn: 0.0411820\ttotal: 2h 24m 41s\tremaining: 1h 40m 49s\n",
      "1326:\tlearn: 0.0411504\ttotal: 2h 24m 48s\tremaining: 1h 40m 43s\n",
      "1327:\tlearn: 0.0411120\ttotal: 2h 24m 54s\tremaining: 1h 40m 36s\n",
      "1328:\tlearn: 0.0410681\ttotal: 2h 25m 1s\tremaining: 1h 40m 29s\n",
      "1329:\tlearn: 0.0410407\ttotal: 2h 25m 7s\tremaining: 1h 40m 23s\n",
      "1330:\tlearn: 0.0410029\ttotal: 2h 25m 13s\tremaining: 1h 40m 16s\n",
      "1331:\tlearn: 0.0409510\ttotal: 2h 25m 20s\tremaining: 1h 40m 9s\n",
      "1332:\tlearn: 0.0409003\ttotal: 2h 25m 26s\tremaining: 1h 40m 3s\n",
      "1333:\tlearn: 0.0408416\ttotal: 2h 25m 33s\tremaining: 1h 39m 56s\n",
      "1334:\tlearn: 0.0407874\ttotal: 2h 25m 39s\tremaining: 1h 39m 49s\n",
      "1335:\tlearn: 0.0407492\ttotal: 2h 25m 46s\tremaining: 1h 39m 43s\n",
      "1336:\tlearn: 0.0407052\ttotal: 2h 25m 52s\tremaining: 1h 39m 36s\n",
      "1337:\tlearn: 0.0406564\ttotal: 2h 25m 58s\tremaining: 1h 39m 30s\n",
      "1338:\tlearn: 0.0406220\ttotal: 2h 26m 5s\tremaining: 1h 39m 23s\n",
      "1339:\tlearn: 0.0405680\ttotal: 2h 26m 11s\tremaining: 1h 39m 16s\n",
      "1340:\tlearn: 0.0405203\ttotal: 2h 26m 18s\tremaining: 1h 39m 10s\n",
      "1341:\tlearn: 0.0404799\ttotal: 2h 26m 24s\tremaining: 1h 39m 3s\n",
      "1342:\tlearn: 0.0404459\ttotal: 2h 26m 31s\tremaining: 1h 38m 57s\n",
      "1343:\tlearn: 0.0404088\ttotal: 2h 26m 37s\tremaining: 1h 38m 50s\n",
      "1344:\tlearn: 0.0403618\ttotal: 2h 26m 43s\tremaining: 1h 38m 43s\n",
      "1345:\tlearn: 0.0403301\ttotal: 2h 26m 50s\tremaining: 1h 38m 37s\n",
      "1346:\tlearn: 0.0402951\ttotal: 2h 26m 56s\tremaining: 1h 38m 30s\n",
      "1347:\tlearn: 0.0402530\ttotal: 2h 27m 3s\tremaining: 1h 38m 24s\n",
      "1348:\tlearn: 0.0402033\ttotal: 2h 27m 9s\tremaining: 1h 38m 17s\n",
      "1349:\tlearn: 0.0401556\ttotal: 2h 27m 16s\tremaining: 1h 38m 10s\n",
      "1350:\tlearn: 0.0401051\ttotal: 2h 27m 22s\tremaining: 1h 38m 4s\n",
      "1351:\tlearn: 0.0400560\ttotal: 2h 27m 28s\tremaining: 1h 37m 57s\n",
      "1352:\tlearn: 0.0400243\ttotal: 2h 27m 35s\tremaining: 1h 37m 50s\n",
      "1353:\tlearn: 0.0399768\ttotal: 2h 27m 41s\tremaining: 1h 37m 44s\n",
      "1354:\tlearn: 0.0399268\ttotal: 2h 27m 48s\tremaining: 1h 37m 37s\n",
      "1355:\tlearn: 0.0398990\ttotal: 2h 27m 54s\tremaining: 1h 37m 31s\n",
      "1356:\tlearn: 0.0398507\ttotal: 2h 28m 1s\tremaining: 1h 37m 24s\n",
      "1357:\tlearn: 0.0398142\ttotal: 2h 28m 7s\tremaining: 1h 37m 17s\n",
      "1358:\tlearn: 0.0397692\ttotal: 2h 28m 14s\tremaining: 1h 37m 11s\n",
      "1359:\tlearn: 0.0397244\ttotal: 2h 28m 20s\tremaining: 1h 37m 4s\n",
      "1360:\tlearn: 0.0396785\ttotal: 2h 28m 27s\tremaining: 1h 36m 58s\n",
      "1361:\tlearn: 0.0396278\ttotal: 2h 28m 33s\tremaining: 1h 36m 51s\n",
      "1362:\tlearn: 0.0395821\ttotal: 2h 28m 39s\tremaining: 1h 36m 44s\n",
      "1363:\tlearn: 0.0395314\ttotal: 2h 28m 46s\tremaining: 1h 36m 38s\n",
      "1364:\tlearn: 0.0394798\ttotal: 2h 28m 52s\tremaining: 1h 36m 31s\n",
      "1365:\tlearn: 0.0394307\ttotal: 2h 28m 59s\tremaining: 1h 36m 24s\n",
      "1366:\tlearn: 0.0393904\ttotal: 2h 29m 5s\tremaining: 1h 36m 18s\n",
      "1367:\tlearn: 0.0393458\ttotal: 2h 29m 12s\tremaining: 1h 36m 11s\n",
      "1368:\tlearn: 0.0393058\ttotal: 2h 29m 18s\tremaining: 1h 36m 5s\n",
      "1369:\tlearn: 0.0392610\ttotal: 2h 29m 24s\tremaining: 1h 35m 58s\n",
      "1370:\tlearn: 0.0392131\ttotal: 2h 29m 31s\tremaining: 1h 35m 51s\n",
      "1371:\tlearn: 0.0391779\ttotal: 2h 29m 37s\tremaining: 1h 35m 45s\n",
      "1372:\tlearn: 0.0391442\ttotal: 2h 29m 44s\tremaining: 1h 35m 38s\n",
      "1373:\tlearn: 0.0391085\ttotal: 2h 29m 50s\tremaining: 1h 35m 32s\n",
      "1374:\tlearn: 0.0390658\ttotal: 2h 29m 56s\tremaining: 1h 35m 25s\n",
      "1375:\tlearn: 0.0390251\ttotal: 2h 30m 3s\tremaining: 1h 35m 18s\n",
      "1376:\tlearn: 0.0389799\ttotal: 2h 30m 9s\tremaining: 1h 35m 12s\n",
      "1377:\tlearn: 0.0389586\ttotal: 2h 30m 16s\tremaining: 1h 35m 5s\n",
      "1378:\tlearn: 0.0389216\ttotal: 2h 30m 22s\tremaining: 1h 34m 58s\n",
      "1379:\tlearn: 0.0388816\ttotal: 2h 30m 29s\tremaining: 1h 34m 52s\n",
      "1380:\tlearn: 0.0388363\ttotal: 2h 30m 35s\tremaining: 1h 34m 45s\n",
      "1381:\tlearn: 0.0387935\ttotal: 2h 30m 41s\tremaining: 1h 34m 38s\n",
      "1382:\tlearn: 0.0387665\ttotal: 2h 30m 48s\tremaining: 1h 34m 32s\n",
      "1383:\tlearn: 0.0387305\ttotal: 2h 30m 54s\tremaining: 1h 34m 25s\n",
      "1384:\tlearn: 0.0386911\ttotal: 2h 31m 1s\tremaining: 1h 34m 19s\n",
      "1385:\tlearn: 0.0386498\ttotal: 2h 31m 7s\tremaining: 1h 34m 12s\n",
      "1386:\tlearn: 0.0386092\ttotal: 2h 31m 14s\tremaining: 1h 34m 5s\n",
      "1387:\tlearn: 0.0385659\ttotal: 2h 31m 20s\tremaining: 1h 33m 59s\n",
      "1388:\tlearn: 0.0385262\ttotal: 2h 31m 27s\tremaining: 1h 33m 52s\n",
      "1389:\tlearn: 0.0384869\ttotal: 2h 31m 33s\tremaining: 1h 33m 46s\n",
      "1390:\tlearn: 0.0384446\ttotal: 2h 31m 39s\tremaining: 1h 33m 39s\n",
      "1391:\tlearn: 0.0384135\ttotal: 2h 31m 46s\tremaining: 1h 33m 32s\n",
      "1392:\tlearn: 0.0383841\ttotal: 2h 31m 52s\tremaining: 1h 33m 26s\n",
      "1393:\tlearn: 0.0383533\ttotal: 2h 31m 59s\tremaining: 1h 33m 19s\n",
      "1394:\tlearn: 0.0383078\ttotal: 2h 32m 5s\tremaining: 1h 33m 13s\n",
      "1395:\tlearn: 0.0382721\ttotal: 2h 32m 11s\tremaining: 1h 33m 6s\n",
      "1396:\tlearn: 0.0382417\ttotal: 2h 32m 18s\tremaining: 1h 32m 59s\n",
      "1397:\tlearn: 0.0382069\ttotal: 2h 32m 24s\tremaining: 1h 32m 53s\n",
      "1398:\tlearn: 0.0381582\ttotal: 2h 32m 31s\tremaining: 1h 32m 46s\n",
      "1399:\tlearn: 0.0381223\ttotal: 2h 32m 37s\tremaining: 1h 32m 39s\n",
      "1400:\tlearn: 0.0380791\ttotal: 2h 32m 44s\tremaining: 1h 32m 33s\n",
      "1401:\tlearn: 0.0380369\ttotal: 2h 32m 50s\tremaining: 1h 32m 26s\n",
      "1402:\tlearn: 0.0379970\ttotal: 2h 32m 56s\tremaining: 1h 32m 20s\n",
      "1403:\tlearn: 0.0379647\ttotal: 2h 33m 3s\tremaining: 1h 32m 13s\n",
      "1404:\tlearn: 0.0379240\ttotal: 2h 33m 9s\tremaining: 1h 32m 6s\n",
      "1405:\tlearn: 0.0378829\ttotal: 2h 33m 16s\tremaining: 1h 32m\n",
      "1406:\tlearn: 0.0378492\ttotal: 2h 33m 22s\tremaining: 1h 31m 53s\n",
      "1407:\tlearn: 0.0378051\ttotal: 2h 33m 29s\tremaining: 1h 31m 47s\n",
      "1408:\tlearn: 0.0377712\ttotal: 2h 33m 35s\tremaining: 1h 31m 40s\n",
      "1409:\tlearn: 0.0377433\ttotal: 2h 33m 42s\tremaining: 1h 31m 33s\n",
      "1410:\tlearn: 0.0377072\ttotal: 2h 33m 48s\tremaining: 1h 31m 27s\n",
      "1411:\tlearn: 0.0376725\ttotal: 2h 33m 54s\tremaining: 1h 31m 20s\n",
      "1412:\tlearn: 0.0376466\ttotal: 2h 34m 1s\tremaining: 1h 31m 14s\n",
      "1413:\tlearn: 0.0376215\ttotal: 2h 34m 7s\tremaining: 1h 31m 7s\n",
      "1414:\tlearn: 0.0375958\ttotal: 2h 34m 14s\tremaining: 1h 31m\n",
      "1415:\tlearn: 0.0375640\ttotal: 2h 34m 20s\tremaining: 1h 30m 54s\n",
      "1416:\tlearn: 0.0375205\ttotal: 2h 34m 27s\tremaining: 1h 30m 47s\n",
      "1417:\tlearn: 0.0374753\ttotal: 2h 34m 33s\tremaining: 1h 30m 41s\n",
      "1418:\tlearn: 0.0374309\ttotal: 2h 34m 39s\tremaining: 1h 30m 34s\n",
      "1419:\tlearn: 0.0373868\ttotal: 2h 34m 46s\tremaining: 1h 30m 28s\n",
      "1420:\tlearn: 0.0373624\ttotal: 2h 34m 52s\tremaining: 1h 30m 21s\n",
      "1421:\tlearn: 0.0373373\ttotal: 2h 34m 59s\tremaining: 1h 30m 14s\n",
      "1422:\tlearn: 0.0372940\ttotal: 2h 35m 5s\tremaining: 1h 30m 8s\n",
      "1423:\tlearn: 0.0372590\ttotal: 2h 35m 12s\tremaining: 1h 30m 1s\n",
      "1424:\tlearn: 0.0372208\ttotal: 2h 35m 18s\tremaining: 1h 29m 54s\n",
      "1425:\tlearn: 0.0371881\ttotal: 2h 35m 25s\tremaining: 1h 29m 48s\n",
      "1426:\tlearn: 0.0371541\ttotal: 2h 35m 31s\tremaining: 1h 29m 41s\n",
      "1427:\tlearn: 0.0371164\ttotal: 2h 35m 38s\tremaining: 1h 29m 35s\n",
      "1428:\tlearn: 0.0370809\ttotal: 2h 35m 44s\tremaining: 1h 29m 28s\n",
      "1429:\tlearn: 0.0370397\ttotal: 2h 35m 50s\tremaining: 1h 29m 22s\n",
      "1430:\tlearn: 0.0370064\ttotal: 2h 35m 57s\tremaining: 1h 29m 15s\n",
      "1431:\tlearn: 0.0369867\ttotal: 2h 36m 3s\tremaining: 1h 29m 8s\n",
      "1432:\tlearn: 0.0369481\ttotal: 2h 36m 10s\tremaining: 1h 29m 2s\n",
      "1433:\tlearn: 0.0369169\ttotal: 2h 36m 16s\tremaining: 1h 28m 55s\n",
      "1434:\tlearn: 0.0368799\ttotal: 2h 36m 23s\tremaining: 1h 28m 49s\n",
      "1435:\tlearn: 0.0368439\ttotal: 2h 36m 29s\tremaining: 1h 28m 42s\n",
      "1436:\tlearn: 0.0367961\ttotal: 2h 36m 35s\tremaining: 1h 28m 35s\n",
      "1437:\tlearn: 0.0367616\ttotal: 2h 36m 42s\tremaining: 1h 28m 29s\n",
      "1438:\tlearn: 0.0367401\ttotal: 2h 36m 48s\tremaining: 1h 28m 22s\n",
      "1439:\tlearn: 0.0367077\ttotal: 2h 36m 55s\tremaining: 1h 28m 16s\n",
      "1440:\tlearn: 0.0366581\ttotal: 2h 37m 1s\tremaining: 1h 28m 9s\n",
      "1441:\tlearn: 0.0366272\ttotal: 2h 37m 7s\tremaining: 1h 28m 2s\n",
      "1442:\tlearn: 0.0366026\ttotal: 2h 37m 14s\tremaining: 1h 27m 56s\n",
      "1443:\tlearn: 0.0365693\ttotal: 2h 37m 20s\tremaining: 1h 27m 49s\n",
      "1444:\tlearn: 0.0365412\ttotal: 2h 37m 27s\tremaining: 1h 27m 43s\n",
      "1445:\tlearn: 0.0365164\ttotal: 2h 37m 33s\tremaining: 1h 27m 36s\n",
      "1446:\tlearn: 0.0364785\ttotal: 2h 37m 39s\tremaining: 1h 27m 29s\n",
      "1447:\tlearn: 0.0364426\ttotal: 2h 37m 46s\tremaining: 1h 27m 23s\n",
      "1448:\tlearn: 0.0364044\ttotal: 2h 37m 52s\tremaining: 1h 27m 16s\n",
      "1449:\tlearn: 0.0363805\ttotal: 2h 37m 59s\tremaining: 1h 27m 10s\n",
      "1450:\tlearn: 0.0363502\ttotal: 2h 38m 5s\tremaining: 1h 27m 3s\n",
      "1451:\tlearn: 0.0363182\ttotal: 2h 38m 12s\tremaining: 1h 26m 56s\n",
      "1452:\tlearn: 0.0362836\ttotal: 2h 38m 18s\tremaining: 1h 26m 50s\n",
      "1453:\tlearn: 0.0362503\ttotal: 2h 38m 25s\tremaining: 1h 26m 43s\n",
      "1454:\tlearn: 0.0362133\ttotal: 2h 38m 31s\tremaining: 1h 26m 37s\n",
      "1455:\tlearn: 0.0361784\ttotal: 2h 38m 38s\tremaining: 1h 26m 30s\n",
      "1456:\tlearn: 0.0361403\ttotal: 2h 38m 44s\tremaining: 1h 26m 23s\n",
      "1457:\tlearn: 0.0361088\ttotal: 2h 38m 50s\tremaining: 1h 26m 17s\n",
      "1458:\tlearn: 0.0360752\ttotal: 2h 38m 57s\tremaining: 1h 26m 10s\n",
      "1459:\tlearn: 0.0360334\ttotal: 2h 39m 3s\tremaining: 1h 26m 4s\n",
      "1460:\tlearn: 0.0360107\ttotal: 2h 39m 10s\tremaining: 1h 25m 57s\n",
      "1461:\tlearn: 0.0359722\ttotal: 2h 39m 16s\tremaining: 1h 25m 50s\n",
      "1462:\tlearn: 0.0359430\ttotal: 2h 39m 23s\tremaining: 1h 25m 44s\n",
      "1463:\tlearn: 0.0359048\ttotal: 2h 39m 29s\tremaining: 1h 25m 37s\n",
      "1464:\tlearn: 0.0358759\ttotal: 2h 39m 36s\tremaining: 1h 25m 31s\n",
      "1465:\tlearn: 0.0358462\ttotal: 2h 39m 42s\tremaining: 1h 25m 24s\n",
      "1466:\tlearn: 0.0358062\ttotal: 2h 39m 48s\tremaining: 1h 25m 17s\n",
      "1467:\tlearn: 0.0357695\ttotal: 2h 39m 55s\tremaining: 1h 25m 11s\n",
      "1468:\tlearn: 0.0357304\ttotal: 2h 40m 1s\tremaining: 1h 25m 4s\n",
      "1469:\tlearn: 0.0356996\ttotal: 2h 40m 8s\tremaining: 1h 24m 58s\n",
      "1470:\tlearn: 0.0356671\ttotal: 2h 40m 14s\tremaining: 1h 24m 51s\n",
      "1471:\tlearn: 0.0356361\ttotal: 2h 40m 20s\tremaining: 1h 24m 44s\n",
      "1472:\tlearn: 0.0355984\ttotal: 2h 40m 27s\tremaining: 1h 24m 38s\n",
      "1473:\tlearn: 0.0355501\ttotal: 2h 40m 33s\tremaining: 1h 24m 31s\n",
      "1474:\tlearn: 0.0355161\ttotal: 2h 40m 40s\tremaining: 1h 24m 25s\n",
      "1475:\tlearn: 0.0354900\ttotal: 2h 40m 46s\tremaining: 1h 24m 18s\n",
      "1476:\tlearn: 0.0354593\ttotal: 2h 40m 53s\tremaining: 1h 24m 12s\n",
      "1477:\tlearn: 0.0354229\ttotal: 2h 40m 59s\tremaining: 1h 24m 5s\n",
      "1478:\tlearn: 0.0353845\ttotal: 2h 41m 6s\tremaining: 1h 23m 58s\n",
      "1479:\tlearn: 0.0353520\ttotal: 2h 41m 12s\tremaining: 1h 23m 52s\n",
      "1480:\tlearn: 0.0353279\ttotal: 2h 41m 19s\tremaining: 1h 23m 45s\n",
      "1481:\tlearn: 0.0352882\ttotal: 2h 41m 25s\tremaining: 1h 23m 39s\n",
      "1482:\tlearn: 0.0352486\ttotal: 2h 41m 31s\tremaining: 1h 23m 32s\n",
      "1483:\tlearn: 0.0352219\ttotal: 2h 41m 38s\tremaining: 1h 23m 25s\n",
      "1484:\tlearn: 0.0351933\ttotal: 2h 41m 44s\tremaining: 1h 23m 19s\n",
      "1485:\tlearn: 0.0351563\ttotal: 2h 41m 51s\tremaining: 1h 23m 12s\n",
      "1486:\tlearn: 0.0351200\ttotal: 2h 41m 57s\tremaining: 1h 23m 6s\n",
      "1487:\tlearn: 0.0350901\ttotal: 2h 42m 4s\tremaining: 1h 22m 59s\n",
      "1488:\tlearn: 0.0350592\ttotal: 2h 42m 10s\tremaining: 1h 22m 53s\n",
      "1489:\tlearn: 0.0350287\ttotal: 2h 42m 17s\tremaining: 1h 22m 46s\n",
      "1490:\tlearn: 0.0349968\ttotal: 2h 42m 23s\tremaining: 1h 22m 39s\n",
      "1491:\tlearn: 0.0349552\ttotal: 2h 42m 29s\tremaining: 1h 22m 33s\n",
      "1492:\tlearn: 0.0349393\ttotal: 2h 42m 36s\tremaining: 1h 22m 26s\n",
      "1493:\tlearn: 0.0349068\ttotal: 2h 42m 42s\tremaining: 1h 22m 20s\n",
      "1494:\tlearn: 0.0348729\ttotal: 2h 42m 49s\tremaining: 1h 22m 13s\n",
      "1495:\tlearn: 0.0348456\ttotal: 2h 42m 55s\tremaining: 1h 22m 6s\n",
      "1496:\tlearn: 0.0348049\ttotal: 2h 43m 1s\tremaining: 1h 22m\n",
      "1497:\tlearn: 0.0347697\ttotal: 2h 43m 8s\tremaining: 1h 21m 53s\n",
      "1498:\tlearn: 0.0347273\ttotal: 2h 43m 14s\tremaining: 1h 21m 47s\n",
      "1499:\tlearn: 0.0346920\ttotal: 2h 43m 21s\tremaining: 1h 21m 40s\n",
      "1500:\tlearn: 0.0346607\ttotal: 2h 43m 27s\tremaining: 1h 21m 33s\n",
      "1501:\tlearn: 0.0346324\ttotal: 2h 43m 33s\tremaining: 1h 21m 27s\n",
      "1502:\tlearn: 0.0345976\ttotal: 2h 43m 40s\tremaining: 1h 21m 20s\n",
      "1503:\tlearn: 0.0345599\ttotal: 2h 43m 46s\tremaining: 1h 21m 14s\n",
      "1504:\tlearn: 0.0345240\ttotal: 2h 43m 53s\tremaining: 1h 21m 7s\n",
      "1505:\tlearn: 0.0344857\ttotal: 2h 43m 59s\tremaining: 1h 21m 1s\n",
      "1506:\tlearn: 0.0344478\ttotal: 2h 44m 5s\tremaining: 1h 20m 54s\n",
      "1507:\tlearn: 0.0344099\ttotal: 2h 44m 12s\tremaining: 1h 20m 47s\n",
      "1508:\tlearn: 0.0343754\ttotal: 2h 44m 18s\tremaining: 1h 20m 41s\n",
      "1509:\tlearn: 0.0343404\ttotal: 2h 44m 25s\tremaining: 1h 20m 34s\n",
      "1510:\tlearn: 0.0343054\ttotal: 2h 44m 31s\tremaining: 1h 20m 28s\n",
      "1511:\tlearn: 0.0342777\ttotal: 2h 44m 38s\tremaining: 1h 20m 21s\n",
      "1512:\tlearn: 0.0342514\ttotal: 2h 44m 44s\tremaining: 1h 20m 14s\n",
      "1513:\tlearn: 0.0342145\ttotal: 2h 44m 50s\tremaining: 1h 20m 8s\n",
      "1514:\tlearn: 0.0341959\ttotal: 2h 44m 57s\tremaining: 1h 20m 1s\n",
      "1515:\tlearn: 0.0341697\ttotal: 2h 45m 3s\tremaining: 1h 19m 55s\n",
      "1516:\tlearn: 0.0341455\ttotal: 2h 45m 10s\tremaining: 1h 19m 48s\n",
      "1517:\tlearn: 0.0341134\ttotal: 2h 45m 16s\tremaining: 1h 19m 42s\n",
      "1518:\tlearn: 0.0340909\ttotal: 2h 45m 23s\tremaining: 1h 19m 35s\n",
      "1519:\tlearn: 0.0340633\ttotal: 2h 45m 29s\tremaining: 1h 19m 28s\n",
      "1520:\tlearn: 0.0340411\ttotal: 2h 45m 36s\tremaining: 1h 19m 22s\n",
      "1521:\tlearn: 0.0340195\ttotal: 2h 45m 42s\tremaining: 1h 19m 15s\n",
      "1522:\tlearn: 0.0339836\ttotal: 2h 45m 48s\tremaining: 1h 19m 9s\n",
      "1523:\tlearn: 0.0339572\ttotal: 2h 45m 55s\tremaining: 1h 19m 2s\n",
      "1524:\tlearn: 0.0339333\ttotal: 2h 46m 1s\tremaining: 1h 18m 55s\n",
      "1525:\tlearn: 0.0339052\ttotal: 2h 46m 8s\tremaining: 1h 18m 49s\n",
      "1526:\tlearn: 0.0338849\ttotal: 2h 46m 14s\tremaining: 1h 18m 42s\n",
      "1527:\tlearn: 0.0338525\ttotal: 2h 46m 20s\tremaining: 1h 18m 36s\n",
      "1528:\tlearn: 0.0338144\ttotal: 2h 46m 27s\tremaining: 1h 18m 29s\n",
      "1529:\tlearn: 0.0337881\ttotal: 2h 46m 33s\tremaining: 1h 18m 23s\n",
      "1530:\tlearn: 0.0337448\ttotal: 2h 46m 40s\tremaining: 1h 18m 16s\n",
      "1531:\tlearn: 0.0337192\ttotal: 2h 46m 46s\tremaining: 1h 18m 9s\n",
      "1532:\tlearn: 0.0336857\ttotal: 2h 46m 53s\tremaining: 1h 18m 3s\n",
      "1533:\tlearn: 0.0336509\ttotal: 2h 46m 59s\tremaining: 1h 17m 56s\n",
      "1534:\tlearn: 0.0336308\ttotal: 2h 47m 6s\tremaining: 1h 17m 50s\n",
      "1535:\tlearn: 0.0336049\ttotal: 2h 47m 12s\tremaining: 1h 17m 43s\n",
      "1536:\tlearn: 0.0335665\ttotal: 2h 47m 18s\tremaining: 1h 17m 36s\n",
      "1537:\tlearn: 0.0335434\ttotal: 2h 47m 25s\tremaining: 1h 17m 30s\n",
      "1538:\tlearn: 0.0335140\ttotal: 2h 47m 31s\tremaining: 1h 17m 23s\n",
      "1539:\tlearn: 0.0334966\ttotal: 2h 47m 38s\tremaining: 1h 17m 17s\n",
      "1540:\tlearn: 0.0334653\ttotal: 2h 47m 44s\tremaining: 1h 17m 10s\n",
      "1541:\tlearn: 0.0334320\ttotal: 2h 47m 51s\tremaining: 1h 17m 4s\n",
      "1542:\tlearn: 0.0334061\ttotal: 2h 47m 57s\tremaining: 1h 16m 57s\n",
      "1543:\tlearn: 0.0333786\ttotal: 2h 48m 3s\tremaining: 1h 16m 50s\n",
      "1544:\tlearn: 0.0333433\ttotal: 2h 48m 10s\tremaining: 1h 16m 44s\n",
      "1545:\tlearn: 0.0333174\ttotal: 2h 48m 16s\tremaining: 1h 16m 37s\n",
      "1546:\tlearn: 0.0332919\ttotal: 2h 48m 23s\tremaining: 1h 16m 31s\n",
      "1547:\tlearn: 0.0332703\ttotal: 2h 48m 29s\tremaining: 1h 16m 24s\n",
      "1548:\tlearn: 0.0332427\ttotal: 2h 48m 36s\tremaining: 1h 16m 18s\n",
      "1549:\tlearn: 0.0332168\ttotal: 2h 48m 42s\tremaining: 1h 16m 11s\n",
      "1550:\tlearn: 0.0331759\ttotal: 2h 48m 49s\tremaining: 1h 16m 4s\n",
      "1551:\tlearn: 0.0331437\ttotal: 2h 48m 55s\tremaining: 1h 15m 58s\n",
      "1552:\tlearn: 0.0331198\ttotal: 2h 49m 2s\tremaining: 1h 15m 51s\n",
      "1553:\tlearn: 0.0331082\ttotal: 2h 49m 8s\tremaining: 1h 15m 45s\n",
      "1554:\tlearn: 0.0330829\ttotal: 2h 49m 14s\tremaining: 1h 15m 38s\n",
      "1555:\tlearn: 0.0330554\ttotal: 2h 49m 21s\tremaining: 1h 15m 32s\n",
      "1556:\tlearn: 0.0330222\ttotal: 2h 49m 27s\tremaining: 1h 15m 25s\n",
      "1557:\tlearn: 0.0329807\ttotal: 2h 49m 34s\tremaining: 1h 15m 19s\n",
      "1558:\tlearn: 0.0329508\ttotal: 2h 49m 40s\tremaining: 1h 15m 12s\n",
      "1559:\tlearn: 0.0329284\ttotal: 2h 49m 47s\tremaining: 1h 15m 5s\n",
      "1560:\tlearn: 0.0328989\ttotal: 2h 49m 53s\tremaining: 1h 14m 59s\n",
      "1561:\tlearn: 0.0328789\ttotal: 2h 50m\tremaining: 1h 14m 52s\n",
      "1562:\tlearn: 0.0328565\ttotal: 2h 50m 6s\tremaining: 1h 14m 46s\n",
      "1563:\tlearn: 0.0328251\ttotal: 2h 50m 13s\tremaining: 1h 14m 39s\n",
      "1564:\tlearn: 0.0328044\ttotal: 2h 50m 19s\tremaining: 1h 14m 33s\n",
      "1565:\tlearn: 0.0327860\ttotal: 2h 50m 26s\tremaining: 1h 14m 26s\n",
      "1566:\tlearn: 0.0327595\ttotal: 2h 50m 32s\tremaining: 1h 14m 20s\n",
      "1567:\tlearn: 0.0327318\ttotal: 2h 50m 39s\tremaining: 1h 14m 13s\n",
      "1568:\tlearn: 0.0327100\ttotal: 2h 50m 45s\tremaining: 1h 14m 6s\n",
      "1569:\tlearn: 0.0326727\ttotal: 2h 50m 52s\tremaining: 1h 14m\n",
      "1570:\tlearn: 0.0326425\ttotal: 2h 50m 58s\tremaining: 1h 13m 53s\n",
      "1571:\tlearn: 0.0326101\ttotal: 2h 51m 5s\tremaining: 1h 13m 47s\n",
      "1572:\tlearn: 0.0325859\ttotal: 2h 51m 11s\tremaining: 1h 13m 40s\n",
      "1573:\tlearn: 0.0325660\ttotal: 2h 51m 17s\tremaining: 1h 13m 34s\n",
      "1574:\tlearn: 0.0325447\ttotal: 2h 51m 24s\tremaining: 1h 13m 27s\n",
      "1575:\tlearn: 0.0325310\ttotal: 2h 51m 30s\tremaining: 1h 13m 21s\n",
      "1576:\tlearn: 0.0324947\ttotal: 2h 51m 37s\tremaining: 1h 13m 14s\n",
      "1577:\tlearn: 0.0324703\ttotal: 2h 51m 43s\tremaining: 1h 13m 7s\n",
      "1578:\tlearn: 0.0324524\ttotal: 2h 51m 50s\tremaining: 1h 13m 1s\n",
      "1579:\tlearn: 0.0324177\ttotal: 2h 51m 56s\tremaining: 1h 12m 54s\n",
      "1580:\tlearn: 0.0323858\ttotal: 2h 52m 3s\tremaining: 1h 12m 48s\n",
      "1581:\tlearn: 0.0323731\ttotal: 2h 52m 9s\tremaining: 1h 12m 41s\n",
      "1582:\tlearn: 0.0323504\ttotal: 2h 52m 15s\tremaining: 1h 12m 35s\n",
      "1583:\tlearn: 0.0323171\ttotal: 2h 52m 22s\tremaining: 1h 12m 28s\n",
      "1584:\tlearn: 0.0322924\ttotal: 2h 52m 28s\tremaining: 1h 12m 21s\n",
      "1585:\tlearn: 0.0322643\ttotal: 2h 52m 35s\tremaining: 1h 12m 15s\n",
      "1586:\tlearn: 0.0322412\ttotal: 2h 52m 41s\tremaining: 1h 12m 8s\n",
      "1587:\tlearn: 0.0322247\ttotal: 2h 52m 48s\tremaining: 1h 12m 2s\n",
      "1588:\tlearn: 0.0321959\ttotal: 2h 52m 54s\tremaining: 1h 11m 55s\n",
      "1589:\tlearn: 0.0321654\ttotal: 2h 53m 1s\tremaining: 1h 11m 49s\n",
      "1590:\tlearn: 0.0321345\ttotal: 2h 53m 7s\tremaining: 1h 11m 42s\n",
      "1591:\tlearn: 0.0321143\ttotal: 2h 53m 13s\tremaining: 1h 11m 36s\n",
      "1592:\tlearn: 0.0320853\ttotal: 2h 53m 20s\tremaining: 1h 11m 29s\n",
      "1593:\tlearn: 0.0320603\ttotal: 2h 53m 26s\tremaining: 1h 11m 22s\n",
      "1594:\tlearn: 0.0320310\ttotal: 2h 53m 33s\tremaining: 1h 11m 16s\n",
      "1595:\tlearn: 0.0320196\ttotal: 2h 53m 39s\tremaining: 1h 11m 9s\n",
      "1596:\tlearn: 0.0319930\ttotal: 2h 53m 46s\tremaining: 1h 11m 3s\n",
      "1597:\tlearn: 0.0319670\ttotal: 2h 53m 52s\tremaining: 1h 10m 56s\n",
      "1598:\tlearn: 0.0319400\ttotal: 2h 53m 59s\tremaining: 1h 10m 50s\n",
      "1599:\tlearn: 0.0319136\ttotal: 2h 54m 5s\tremaining: 1h 10m 43s\n",
      "1600:\tlearn: 0.0318842\ttotal: 2h 54m 12s\tremaining: 1h 10m 36s\n",
      "1601:\tlearn: 0.0318561\ttotal: 2h 54m 18s\tremaining: 1h 10m 30s\n",
      "1602:\tlearn: 0.0318296\ttotal: 2h 54m 25s\tremaining: 1h 10m 23s\n",
      "1603:\tlearn: 0.0318175\ttotal: 2h 54m 31s\tremaining: 1h 10m 17s\n",
      "1604:\tlearn: 0.0317850\ttotal: 2h 54m 39s\tremaining: 1h 10m 11s\n",
      "1605:\tlearn: 0.0317617\ttotal: 2h 54m 46s\tremaining: 1h 10m 5s\n",
      "1606:\tlearn: 0.0317511\ttotal: 2h 54m 53s\tremaining: 1h 9m 58s\n",
      "1607:\tlearn: 0.0317385\ttotal: 2h 54m 59s\tremaining: 1h 9m 52s\n",
      "1608:\tlearn: 0.0317155\ttotal: 2h 55m 6s\tremaining: 1h 9m 45s\n",
      "1609:\tlearn: 0.0316865\ttotal: 2h 55m 12s\tremaining: 1h 9m 39s\n",
      "1610:\tlearn: 0.0316572\ttotal: 2h 55m 19s\tremaining: 1h 9m 32s\n",
      "1611:\tlearn: 0.0316248\ttotal: 2h 55m 26s\tremaining: 1h 9m 26s\n",
      "1612:\tlearn: 0.0315982\ttotal: 2h 55m 32s\tremaining: 1h 9m 19s\n",
      "1613:\tlearn: 0.0315706\ttotal: 2h 55m 39s\tremaining: 1h 9m 12s\n",
      "1614:\tlearn: 0.0315513\ttotal: 2h 55m 45s\tremaining: 1h 9m 6s\n",
      "1615:\tlearn: 0.0315312\ttotal: 2h 55m 52s\tremaining: 1h 8m 59s\n",
      "1616:\tlearn: 0.0315003\ttotal: 2h 55m 58s\tremaining: 1h 8m 53s\n",
      "1617:\tlearn: 0.0314778\ttotal: 2h 56m 4s\tremaining: 1h 8m 46s\n",
      "1618:\tlearn: 0.0314672\ttotal: 2h 56m 11s\tremaining: 1h 8m 40s\n",
      "1619:\tlearn: 0.0314417\ttotal: 2h 56m 17s\tremaining: 1h 8m 33s\n",
      "1620:\tlearn: 0.0314111\ttotal: 2h 56m 24s\tremaining: 1h 8m 26s\n",
      "1621:\tlearn: 0.0313749\ttotal: 2h 56m 30s\tremaining: 1h 8m 20s\n",
      "1622:\tlearn: 0.0313503\ttotal: 2h 56m 36s\tremaining: 1h 8m 13s\n",
      "1623:\tlearn: 0.0313207\ttotal: 2h 56m 43s\tremaining: 1h 8m 7s\n",
      "1624:\tlearn: 0.0313013\ttotal: 2h 56m 49s\tremaining: 1h 8m\n",
      "1625:\tlearn: 0.0312728\ttotal: 2h 56m 56s\tremaining: 1h 7m 54s\n",
      "1626:\tlearn: 0.0312493\ttotal: 2h 57m 2s\tremaining: 1h 7m 47s\n",
      "1627:\tlearn: 0.0312324\ttotal: 2h 57m 9s\tremaining: 1h 7m 40s\n",
      "1628:\tlearn: 0.0312072\ttotal: 2h 57m 15s\tremaining: 1h 7m 34s\n",
      "1629:\tlearn: 0.0311746\ttotal: 2h 57m 21s\tremaining: 1h 7m 27s\n",
      "1630:\tlearn: 0.0311440\ttotal: 2h 57m 28s\tremaining: 1h 7m 21s\n",
      "1631:\tlearn: 0.0311246\ttotal: 2h 57m 34s\tremaining: 1h 7m 14s\n",
      "1632:\tlearn: 0.0310930\ttotal: 2h 57m 41s\tremaining: 1h 7m 8s\n",
      "1633:\tlearn: 0.0310811\ttotal: 2h 57m 47s\tremaining: 1h 7m 1s\n",
      "1634:\tlearn: 0.0310524\ttotal: 2h 57m 54s\tremaining: 1h 6m 55s\n",
      "1635:\tlearn: 0.0310344\ttotal: 2h 58m\tremaining: 1h 6m 48s\n",
      "1636:\tlearn: 0.0310119\ttotal: 2h 58m 7s\tremaining: 1h 6m 41s\n",
      "1637:\tlearn: 0.0309850\ttotal: 2h 58m 13s\tremaining: 1h 6m 35s\n",
      "1638:\tlearn: 0.0309554\ttotal: 2h 58m 20s\tremaining: 1h 6m 28s\n",
      "1639:\tlearn: 0.0309258\ttotal: 2h 58m 26s\tremaining: 1h 6m 22s\n",
      "1640:\tlearn: 0.0309088\ttotal: 2h 58m 33s\tremaining: 1h 6m 15s\n",
      "1641:\tlearn: 0.0308762\ttotal: 2h 58m 39s\tremaining: 1h 6m 9s\n",
      "1642:\tlearn: 0.0308489\ttotal: 2h 58m 45s\tremaining: 1h 6m 2s\n",
      "1643:\tlearn: 0.0308246\ttotal: 2h 58m 52s\tremaining: 1h 5m 56s\n",
      "1644:\tlearn: 0.0307994\ttotal: 2h 58m 58s\tremaining: 1h 5m 49s\n",
      "1645:\tlearn: 0.0307800\ttotal: 2h 59m 5s\tremaining: 1h 5m 42s\n",
      "1646:\tlearn: 0.0307507\ttotal: 2h 59m 11s\tremaining: 1h 5m 36s\n",
      "1647:\tlearn: 0.0307206\ttotal: 2h 59m 18s\tremaining: 1h 5m 29s\n",
      "1648:\tlearn: 0.0306929\ttotal: 2h 59m 24s\tremaining: 1h 5m 23s\n",
      "1649:\tlearn: 0.0306610\ttotal: 2h 59m 30s\tremaining: 1h 5m 16s\n",
      "1650:\tlearn: 0.0306337\ttotal: 2h 59m 37s\tremaining: 1h 5m 10s\n",
      "1651:\tlearn: 0.0306173\ttotal: 2h 59m 43s\tremaining: 1h 5m 3s\n",
      "1652:\tlearn: 0.0305958\ttotal: 2h 59m 50s\tremaining: 1h 4m 56s\n",
      "1653:\tlearn: 0.0305798\ttotal: 2h 59m 56s\tremaining: 1h 4m 50s\n",
      "1654:\tlearn: 0.0305694\ttotal: 3h 2s\tremaining: 1h 4m 43s\n",
      "1655:\tlearn: 0.0305460\ttotal: 3h 9s\tremaining: 1h 4m 37s\n",
      "1656:\tlearn: 0.0305198\ttotal: 3h 15s\tremaining: 1h 4m 30s\n",
      "1657:\tlearn: 0.0305005\ttotal: 3h 22s\tremaining: 1h 4m 24s\n",
      "1658:\tlearn: 0.0304715\ttotal: 3h 28s\tremaining: 1h 4m 17s\n",
      "1659:\tlearn: 0.0304498\ttotal: 3h 34s\tremaining: 1h 4m 10s\n",
      "1660:\tlearn: 0.0304229\ttotal: 3h 41s\tremaining: 1h 4m 4s\n",
      "1661:\tlearn: 0.0304005\ttotal: 3h 47s\tremaining: 1h 3m 57s\n",
      "1662:\tlearn: 0.0303888\ttotal: 3h 54s\tremaining: 1h 3m 51s\n",
      "1663:\tlearn: 0.0303658\ttotal: 3h 1m\tremaining: 1h 3m 44s\n",
      "1664:\tlearn: 0.0303473\ttotal: 3h 1m 7s\tremaining: 1h 3m 38s\n",
      "1665:\tlearn: 0.0303271\ttotal: 3h 1m 13s\tremaining: 1h 3m 31s\n",
      "1666:\tlearn: 0.0303022\ttotal: 3h 1m 20s\tremaining: 1h 3m 25s\n",
      "1667:\tlearn: 0.0302792\ttotal: 3h 1m 26s\tremaining: 1h 3m 18s\n",
      "1668:\tlearn: 0.0302628\ttotal: 3h 1m 32s\tremaining: 1h 3m 11s\n",
      "1669:\tlearn: 0.0302339\ttotal: 3h 1m 39s\tremaining: 1h 3m 5s\n",
      "1670:\tlearn: 0.0302158\ttotal: 3h 1m 45s\tremaining: 1h 2m 58s\n",
      "1671:\tlearn: 0.0301996\ttotal: 3h 1m 52s\tremaining: 1h 2m 52s\n",
      "1672:\tlearn: 0.0301783\ttotal: 3h 1m 58s\tremaining: 1h 2m 45s\n",
      "1673:\tlearn: 0.0301517\ttotal: 3h 2m 5s\tremaining: 1h 2m 39s\n",
      "1674:\tlearn: 0.0301212\ttotal: 3h 2m 11s\tremaining: 1h 2m 32s\n",
      "1675:\tlearn: 0.0300972\ttotal: 3h 2m 18s\tremaining: 1h 2m 26s\n",
      "1676:\tlearn: 0.0300614\ttotal: 3h 2m 24s\tremaining: 1h 2m 19s\n",
      "1677:\tlearn: 0.0300293\ttotal: 3h 2m 30s\tremaining: 1h 2m 12s\n",
      "1678:\tlearn: 0.0300059\ttotal: 3h 2m 37s\tremaining: 1h 2m 6s\n",
      "1679:\tlearn: 0.0299785\ttotal: 3h 2m 43s\tremaining: 1h 1m 59s\n",
      "1680:\tlearn: 0.0299540\ttotal: 3h 2m 50s\tremaining: 1h 1m 53s\n",
      "1681:\tlearn: 0.0299292\ttotal: 3h 2m 56s\tremaining: 1h 1m 46s\n",
      "1682:\tlearn: 0.0299085\ttotal: 3h 3m 3s\tremaining: 1h 1m 40s\n",
      "1683:\tlearn: 0.0298889\ttotal: 3h 3m 9s\tremaining: 1h 1m 33s\n",
      "1684:\tlearn: 0.0298755\ttotal: 3h 3m 16s\tremaining: 1h 1m 27s\n",
      "1685:\tlearn: 0.0298509\ttotal: 3h 3m 22s\tremaining: 1h 1m 20s\n",
      "1686:\tlearn: 0.0298208\ttotal: 3h 3m 28s\tremaining: 1h 1m 13s\n",
      "1687:\tlearn: 0.0297993\ttotal: 3h 3m 35s\tremaining: 1h 1m 7s\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap_out --no-stderr\n",
    "\n",
    "#video_train_aug=video_train\n",
    "#train_labels_aug=train_labels\n",
    "\n",
    "#for lbl in x_train:\n",
    "#    video_train_aug['img:'+lbl] = x_train[lbl]\n",
    "#    train_labels_aug['img:'+lbl] = y_train[lbl]\n",
    "\n",
    "video_classifier = ClassifierVideoCatboost(model)\n",
    "video_classifier.fit(video_train, train_labels)\n",
    "#video_classifier.fit(video_train_aug, train_labels_aug)\n",
    "y_video_out = video_classifier.classify_videos(video_test)\n",
    "\n",
    "print(check_test(y_video_out, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_train_aug=video_train\n",
    "#train_labels_aug=train_labels\n",
    "\n",
    "#for lbl in x_train:\n",
    "#    video_train_aug['img:'+lbl] = x_train[lbl]\n",
    "#    train_labels_aug['img:'+lbl] = y_train[lbl]\n",
    "\n",
    "video_classifier = ClassifierRandomForest(model)\n",
    "video_classifier.fit(video_train, train_labels)\n",
    "#video_classifier.fit(video_train_aug, train_labels_aug)\n",
    "y_video_out = video_classifier.classify_videos(video_test)\n",
    "\n",
    "print(check_test(y_video_out, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHRr5eHf8cS7"
   },
   "outputs": [],
   "source": [
    "# %%capture cap_out --no-stderr\n",
    "\n",
    "video_train_aug=video_train\n",
    "train_labels_aug=train_labels\n",
    "\n",
    "for lbl in x_train:\n",
    "    video_train_aug['img:'+lbl] = x_train[lbl]\n",
    "    train_labels_aug['img:'+lbl] = y_train[lbl]\n",
    "\n",
    "video_classifier = ClassifierVideo(model)\n",
    "#video_classifier.fit(video_train, train_labels)\n",
    "video_classifier.fit(video_train_aug, train_labels_aug)\n",
    "y_video_out = video_classifier.classify_videos(video_test)\n",
    "\n",
    "print(check_test(y_video_out, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khAmArs3p5Tt"
   },
   "outputs": [],
   "source": [
    "y_video_out = video_classifier.classify_videos(video_test)\n",
    "\n",
    "print(check_test(y_video_out, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAoP8fz0VNi-"
   },
   "outputs": [],
   "source": [
    "with open('fc7-heq-bottleneck-2.15-all.txt', 'w') as f:\n",
    "    f.write(cap_out.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wSLl0mpb8cS-",
    "outputId": "d1b4c514-124a-4aca-d7db-c897ab7b0ed5"
   },
   "outputs": [],
   "source": [
    "print(check_test(y_video_out, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGj2CiU78cTB"
   },
   "outputs": [],
   "source": [
    "video_classifier.pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g7qWFs1BgEwz",
    "outputId": "d2eec45c-2e40-4a7d-f352-b60113567bc0"
   },
   "outputs": [],
   "source": [
    "img_classifier = ClassifierVideo(model)\n",
    "img_classifier.fit(x_train, y_train)\n",
    "y_out = img_classifier.classify_images(x_test)\n",
    "print(check_test(y_out, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ace Recognition task - video tests.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
