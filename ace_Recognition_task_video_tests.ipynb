{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znzWDP4N8cRn"
   },
   "source": [
    "# Face recognition using neural network features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUey7NiG8cRq"
   },
   "source": [
    "In this task, you have to construct face recognizer based on features extracted from the neural network. The task consists of two parts: image classification and video classification. In the first one you should classify distinct images and in the second one you will deal with short video sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "q-DupBs-wz6F",
    "outputId": "87169e0c-17ad-4e4e-a1b8-3dad6d5926fd"
   },
   "outputs": [],
   "source": [
    "# !pip install mtcnn\n",
    "# !conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJgKREpP8cRs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lZrAaqQw8cRx",
    "outputId": "21fdcebd-26cb-4a79-dcb7-2c589a4aeda2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from copy import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SZ19PNFAaI_"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unpack(filename):\n",
    "    with zipfile.ZipFile(filename) as zf:\n",
    "        zf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "F_C8UHF2Am2Z",
    "outputId": "2521d485-c62c-43ae-85c8-b531103deeb9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "assignment_dir = 'face-recognition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njBxmkGt8cR0"
   },
   "source": [
    "First of all, you have you have to read the data. Run the cell below to unpack data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVu-Hvau8cR1"
   },
   "outputs": [],
   "source": [
    "# from get_data import unpack\n",
    "#unpack(assignment_dir + '/Face_Recognition_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BUXXCYBKlwy"
   },
   "outputs": [],
   "source": [
    "images_processed=True\n",
    "videos_processed=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRnR7EDWvO3Y"
   },
   "outputs": [],
   "source": [
    "# !unzip '/content/drive/My Drive/face-recognition/Face_Recognition_data.zip' -d '/content/drive/My Drive/face-recognition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q400JXHp8cR4"
   },
   "source": [
    "### Reading data for image and video classification (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kVl390l8cR5"
   },
   "source": [
    "Implement function $\\tt{load}$\\_$\\tt{image}$\\_$\\tt{data}$. It should return a tuple of 4 dictionaries: the first two are training images and labels, the second two are testing ones. The keys of the dictionaries are the names of the image files and the values are 3-dimensional numpy arrays (for images) or strings with the names (for labels).\n",
    "\n",
    "$\\tt{dir}$\\_$\\tt{name}$ is the name of directory with data for image classification. If 'Face_Recofnition_data' directory is located in the same directory as this notebook, then the default value can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_C6qbsj8cR6"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_image_data(dir_name):\n",
    "    \"\"\"Your implementation\"\"\"\n",
    "    images_train={}\n",
    "    images_test={}\n",
    "    labels_train={}\n",
    "    labels_test={}\n",
    "\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/train/images/*.jpg\")):\n",
    "      images_train[im_path.split('/')[-1]] = io.imread(im_path)\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/test/images/*.jpg\")):\n",
    "      images_test[im_path.split('/')[-1]] = io.imread(im_path)  \n",
    "\n",
    "    labels=pd.read_csv(dir_name+'/train/y_train.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_train[labels.iloc[rowidx,0]] = labels.iloc[rowidx,1]\n",
    "\n",
    "\n",
    "    labels=pd.read_csv(dir_name+'/test/y_test.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_test[labels.iloc[rowidx,0]] = labels.iloc[rowidx,1]\n",
    "    \n",
    "    \n",
    " \n",
    "    return images_train, labels_train, images_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TloxdDpK8cR9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661 \ttraining images\n",
      "808 \ttesting images\n"
     ]
    }
   ],
   "source": [
    "if not images_processed:\n",
    "  x_train, y_train, x_test, y_test = load_image_data(assignment_dir + \"/Face_Recognition_data/image_classification\")\n",
    "  np.savez_compressed(assignment_dir+'/loaded_images.npz',x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test)\n",
    "else:\n",
    "  with np.load(assignment_dir + \"/loaded_images.npz\", allow_pickle=True) as data:\n",
    "    x_train = data['x_train'].item()\n",
    "    y_train = data['y_train'].item()\n",
    "    x_test = data['x_test'].item()\n",
    "    y_test = data['y_test'].item()\n",
    "    \n",
    "print(len(x_train), '\\ttraining images')\n",
    "print(len(x_test), '\\ttesting images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSFbVqqq8cSB"
   },
   "outputs": [],
   "source": [
    "def visualize(data, labels, function = lambda x:x[0], n_cols = 5, n_rows=1):\n",
    "    figure(figsize = (3*n_cols,3*n_rows))\n",
    "    for n,i in enumerate(np.random.choice(list(data.keys()), size = n_cols*n_rows)):\n",
    "        plt.subplot(n_rows,n_cols,n+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(function([data[i]]))\n",
    "        plt.title(labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKL8sKaV8cSE"
   },
   "source": [
    "That is how the data looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJJFsX1x8cSI"
   },
   "source": [
    "Let us now read the video classification data, as well. You have to implement function to load video data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fTf4Edj8cSJ"
   },
   "source": [
    "Function $\\tt{load}$\\_$\\tt{video}$\\_$\\tt{data}$ should also return a tuple of 4 dictionaries: the first two are training images and labels, the second two are testing videos and labels. The training data is in the same format as in image classification task. The keys of testing data and labels are video ids and the values are the lists of frames and the strings with names, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpxUKpip8cSK"
   },
   "outputs": [],
   "source": [
    "def load_video_data(dir_name = 'Face_Recognition_data/video_classification'):\n",
    "    images_train={}\n",
    "    videos_test={}\n",
    "    labels_train={}\n",
    "    labels_test={}\n",
    "\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/train/images/*.jpg\")):\n",
    "      images_train[im_path.split('/')[-1]] = io.imread(im_path)\n",
    "    \n",
    "    labels=pd.read_csv(dir_name+'/train/y_train.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_train[str(labels.iloc[rowidx,0])] = labels.iloc[rowidx,1]\n",
    "\n",
    "    for im_path in sorted(glob.glob(dir_name + \"/test/videos/*/\")):\n",
    "      video_id=im_path.split('/')[-2]\n",
    "      print(video_id)\n",
    "      filenames = glob.glob(dir_name + \"/test/videos/\"+video_id+\"/*.jpg\")\n",
    "      sorted_filenames = sorted(filenames, key=lambda x:int(x.split('/')[-1][:-4]))\n",
    "      videos_test[video_id] = []\n",
    "      for fn in sorted_filenames:\n",
    "        videos_test[video_id].append(io.imread(fn))\n",
    "      \n",
    "\n",
    "    labels=pd.read_csv(dir_name+'/test/y_test.csv')\n",
    "    for rowidx in range(labels.shape[0]):\n",
    "      labels_test[str(labels.iloc[rowidx,0])] = labels.iloc[rowidx,1]\n",
    "\n",
    "      # images_test[im_path.split('/')[-1]] = io.imread(im_path)  \n",
    "  \n",
    "\n",
    "    return images_train, labels_train, videos_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVGLJte58cSN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729 \ttraining images\n",
      "70 \ttesting videos\n"
     ]
    }
   ],
   "source": [
    "if not videos_processed:\n",
    "  video_train, train_labels, video_test, test_labels = load_video_data(assignment_dir + \"/Face_Recognition_data/video_classification\")\n",
    "  np.savez_compressed(assignment_dir+'/loaded_videos.npz',video_train=video_train, train_labels=train_labels, \n",
    "                    video_test=video_test, test_labels=test_labels)\n",
    "else:\n",
    "  with np.load(assignment_dir + \"/loaded_videos.npz\", allow_pickle=True) as data:\n",
    "    video_train = data['video_train'].item()\n",
    "    train_labels = data['train_labels'].item()\n",
    "    video_test = data['video_test'].item()\n",
    "    test_labels = data['test_labels'].item()  \n",
    "\n",
    "\n",
    "print(len(video_train), '\\ttraining images')\n",
    "print(len(video_test), '\\ttesting videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xy3POFf8cSW"
   },
   "source": [
    "### Preprocessing (3 points)\n",
    "You have to implement preprocessing function in the cell below.\n",
    "Getting a list of images as an input the this function should detect the face on each image, find the facial keypoints () and then crop and normalize the image according to these keypoints. The output of this function is the list of images which contain only the aligned face and should be converted to the tensor of the shape $(N, 224, 224, 3)\\ $ where $N$ is the length of the initial list. You can add extra arguments to the preprocess function if necessary (i.e. flag $\\tt{is}$\\_$\\tt{video}$ to determine if the list of images is video sequence or not).\n",
    "\n",
    "For face detection and facial keypoint regression you can use your models from the previous tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxnViArxRpNB"
   },
   "source": [
    "\n",
    "---\n",
    "From the above wording of the instructions, we conclude that we are not forced to use the models from previous tasks but can use also other models of our choosing for the pre-processing task.\n",
    "\n",
    "Exactly this we will do as we anticipate a heap of problems with the previous models, as those models have been trained for fixed resolution and with just small datasets. Instead, we base the pre-processing on face and facial landmark detections of the MTCNN model of the ipazc/MTCNN project (http://github.com/ipazc/mtcnn).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6DKcVXPfQai"
   },
   "outputs": [],
   "source": [
    "# from week 1 assignment\n",
    "from skimage import transform\n",
    "\n",
    "def transform_face(image, eyes, size_multiplier = 2.15):\n",
    "    e=np.array(eyes)\n",
    "    center = np.mean(e,axis=0, keepdims=True)\n",
    "    diff = e[1]-e[0]\n",
    "    dist=np.sqrt(np.sum(diff*diff))\n",
    "    angle = np.arctan2(diff[1],diff[0])\n",
    "    \n",
    "    img_rotated = transform.rotate(image,np.degrees(angle), center=center)\n",
    "\n",
    "    #plt.imshow(img_rotated)\n",
    "    #print('Rotated image')\n",
    "    #plt.show()\n",
    "\n",
    "    face_extent = int(size_multiplier*dist) \n",
    "\n",
    "    # print('Face extent: ', face_extent)\n",
    "\n",
    "    box_left = int(center[0,0]-face_extent) \n",
    "    box_right = int(box_left + 2* face_extent)\n",
    "\n",
    "    box_top = int(center[0,1]-face_extent) \n",
    "    box_bottom = int(box_top + 2* face_extent)\n",
    "\n",
    "    pad=max(0,-box_left,-box_top,box_bottom-image.shape[0]-1, box_right-image.shape[1]-1)\n",
    "    img_crop = np.pad(img_rotated, ((pad,pad),(pad,pad),(0,0)))[box_top+pad:box_bottom+1+pad, box_left+pad:box_right+1+pad]\n",
    "\n",
    "    BOTTLENECK_SIZE = 90\n",
    "    img_crop = transform.resize(img_crop, (BOTTLENECK_SIZE, BOTTLENECK_SIZE))\n",
    "    \n",
    "    return transform.resize(img_crop, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gcqFMJK8cSX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "\n",
    "import copy\n",
    "\n",
    "def equalize_color_img(img):\n",
    "  img_eq = np.zeros_like(img)\n",
    "  img_eq[:,:,0] = exposure.equalize_hist(img[:,:,0])\n",
    "  img_eq[:,:,1] = exposure.equalize_hist(img[:,:,1])\n",
    "  img_eq[:,:,2] = exposure.equalize_hist(img[:,:,2])\n",
    "  return img_eq\n",
    "\n",
    "def distance_from_center(img, detection):\n",
    "    # img is numpay array\n",
    "    # detection is the face detection object from MTCNN detector\n",
    "\n",
    "    x, y, width, height = detection['box']\n",
    "    center_x = (img.shape[1]-1)/2.0\n",
    "    center_y = (img.shape[0]-1)/2.0\n",
    "    face_x = x + width/2.0\n",
    "    face_y = y + height/2.0\n",
    "    dx = center_x - face_x\n",
    "    dy = center_y - face_y\n",
    "    return np.sqrt(dx*dx+dy*dy)\n",
    "\n",
    "def measure_blur(img):\n",
    "  return np.var(filters.laplace(img[:,:,0])) + np.var(filters.laplace(img[:,:,1])) + np.var(filters.laplace(img[:,:,2]))\n",
    "\n",
    "def preprocess_imgs(imgs, size_multiplier=2.15):\n",
    "    ret_imgs=[]\n",
    "    detector = MTCNN()\n",
    "    n_images = len(imgs)\n",
    "    processed_img = 0\n",
    "\n",
    "    for img in imgs:\n",
    "      processed_img += 1\n",
    "      if processed_img%10 == 1: \n",
    "          print ('Preprocessing image {}/{}'.format(processed_img,n_images))\n",
    "      #plt.imshow(img)\n",
    "      #plt.title('Source image')\n",
    "      #plt.show()\n",
    "\n",
    "      faces = detector.detect_faces(img)\n",
    "      #for face in faces:\n",
    "\t    #  print(face)\n",
    "       \n",
    "      #choose the face that is closest to the image center\n",
    "      if len(faces) < 1:\n",
    "        ret_imgs.append(np.zeros((224,224,3)))\n",
    "        continue\n",
    "\n",
    "      min_ind=0\n",
    "      min_dist = distance_from_center(img, faces[0])\n",
    "      for i in range(1,len(faces)):\n",
    "        dist = distance_from_center(img, faces[i])\n",
    "        if dist < min_dist:\n",
    "          min_ind = i\n",
    "          min_dist = dist     \n",
    "       \n",
    "      #plt.imshow(img)\n",
    "      #ax = plt.gca()\n",
    "      face=faces[min_ind]\n",
    "\n",
    "      #x, y, width, height = face['box']\n",
    "      #rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "      #ax.add_patch(rect)\n",
    "      #dot = Circle(face['keypoints']['left_eye'], radius=2, color='green')\n",
    "      #ax.add_patch(dot)\n",
    "      #dot = Circle(face['keypoints']['right_eye'], radius=2, color='blue')\n",
    "      #ax.add_patch(dot)\n",
    "      #plt.show() \n",
    "\n",
    "      if face['confidence']< 0.9:\n",
    "        ret_imgs.append(np.zeros((224,224,3)))\n",
    "        continue\n",
    "\n",
    "      eyes=[face['keypoints']['left_eye'], face['keypoints']['right_eye']]  \n",
    "      #print(eyes)\n",
    "      img_transformed = equalize_color_img(transform_face(img, eyes, \n",
    "                                                          size_multiplier=size_multiplier))\n",
    "      \n",
    "      #blur = np.var(filters.laplace(img_transformed[:,:,0])) + np.var(filters.laplace(img_transformed[:,:,1])) + np.var(filters.laplace(img_transformed[:,:,2]))\n",
    "      #print('Blur: ',blur)\n",
    "\n",
    "      img_blurred=copy.deepcopy(img_transformed) \n",
    "\n",
    "      #sigma=1\n",
    "      #for i in range(5):\n",
    "      #  img_blurred=filters.gaussian(img_blurred)\n",
    "      #sharpness = measure_blur(img_blurred)\n",
    "      #MAX_SHARPNESS = 0.0005\n",
    "      #while sharpness > MAX_SHARPNESS:\n",
    "      #  img_blurred=filters.gaussian(img_blurred)\n",
    "      #  sharpness = measure_blur(img_blurred)\n",
    "        #print('Blur after {} iterations of Gaussian blurring: {}'.format(i+1,blur))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "      #plt.imshow(img_transformed)\n",
    "      #plt.show()\n",
    "\n",
    "      ret_imgs.append(img_blurred)\n",
    "    return ret_imgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLIbD5We8cSb"
   },
   "source": [
    "#### Visualization of preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bG1EI8788cSh"
   },
   "source": [
    "The neural network is already trained on the other face dataset. You should use this network as feature extractor to get descriptors of the faces. You can choose any hidden layer you need (or several layers) to extract features and any classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrvXOnn-8cSi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc6/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc7/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 500)               2048500   \n",
      "_________________________________________________________________\n",
      "prob (Activation)            (None, 500)               0         \n",
      "=================================================================\n",
      "Total params: 136,309,044\n",
      "Trainable params: 136,309,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(assignment_dir + '/face_recognition_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9CBRzUJ8cSl"
   },
   "source": [
    "Here is an example of using the network as feature extractor. The shape of input tensor has to be (n_images, 224, 224, 3), so you can input several images simultaneously and get their face descriptors of shape (n_images, n_components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-ApWK778cSl"
   },
   "outputs": [],
   "source": [
    "def get_layer_output(images, layer = 'fc7'):\n",
    "    assert len(images.shape)==4, 'Wrong input dimentionality!'\n",
    "    assert images.shape[1:]==(224,224,3), 'Wrong input shape!'\n",
    "    \n",
    "    layers=layer.split('+')\n",
    "    n_img = images.shape[0]\n",
    "\n",
    "    output=np.zeros((images.shape[0],0))\n",
    "\n",
    "    batch_size = 2\n",
    "    \n",
    "    for l in layers: \n",
    "      network_output = model.get_layer(l).output\n",
    "      feature_extraction_model = Model(model.input, network_output)\n",
    "         \n",
    "      layer_output=zeros((n_img,feature_extraction_model.predict(images[0,:,:,:].reshape(1,224,224,3)).shape[1]))\n",
    "    \n",
    "      \n",
    "    \n",
    "      for i in range(int(n_img/batch_size)):\n",
    "        layer_output[i*batch_size:min(n_img,(i+1)*batch_size),:]=feature_extraction_model.predict(\n",
    "            images[i*batch_size:min(n_img,(i+1)*batch_size),:,:,:])    \n",
    "    \n",
    "      output=np.hstack((output,layer_output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOaAKwX18cSo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.resize(x_train['0.jpg'], (224,224)).reshape(1,224,224,3)\n",
    "out = get_layer_output(img)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJLDs5QP8cSr"
   },
   "source": [
    "### Training classifier (2 points)\n",
    "\n",
    "\n",
    "You have to implement class $\\tt{Classifier}$ with methods $\\tt{fit}$, $\\tt{classify}$\\_$\\tt{images}$ and $\\tt{classify}$\\_$\\tt{videos}$ in the cell below. \n",
    "The method $\\tt{Classifier.fit}$ gets two dictionaries as input: train images and labels, and trains the classifier to predict the person shown on the image.\n",
    "$\\tt{Classifier.classify}$\\_$\\tt{images}$ gets the dictionary of test images (with filenames as keys) as input and should return the dictionary of the predicted labels.\n",
    "$\\tt{Classifier.classify}$\\_$\\tt{videos}$ is similar to the previous one, but gets the dictionary of test videos (with video as keys) as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4-aKpmg8cSt"
   },
   "source": [
    "To classify video you can combine the predictions for its frames any way you want (averaging, voting, etc.).\n",
    "If video classification takes too long you can use face detector not in all the frames but every few frames while preprocessing video frames. \n",
    "Besides, sometimes the face is hardly detected on the image and the frame in which the detector works wrong can add noise to the prediction. Hence, the result of the prediction without using such frames may be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "taBviW0o8cSx"
   },
   "source": [
    "Now we can build the classifier, fit it and use to predict the labels of testing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4U2NkS8cS0"
   },
   "source": [
    "### Image classification quality (2 points)\n",
    "\n",
    "Let us check the accuracy of your classification. To obtain 1 point for that rubric your implementation must have accuracy at least 0.90, to obtain 2 points — at least 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geFa3GNe8cS1"
   },
   "outputs": [],
   "source": [
    "def check_test(output, gt):\n",
    "    correct = 0.\n",
    "    total = len(gt)\n",
    "    for k, v in gt.items():\n",
    "        if output[k] == v:\n",
    "            correct += 1\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return 'Classification accuracy is %.4f' % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MY1WMDVP8cS6"
   },
   "source": [
    "### Video classification quality (2 points)\n",
    "\n",
    "Let us check the quality of video classification. To obtain 1 point for that rubric your implementation must have accuracy at least 0.80, to obtain 2 points — at least 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from os.path import join\n",
    "class ClassifierVideoCatboost():\n",
    "    def __init__(self, nn_model):\n",
    "        self.label_encoder = preprocessing.LabelEncoder()\n",
    "        self.catboost_model = CatBoostClassifier(verbose=True, iterations=750)\n",
    "        self.pca1 = decomposition.PCA(0.8)\n",
    "        self.pca2 = decomposition.PCA(0.8)\n",
    "        self.pca3 = decomposition.PCA(0.8)\n",
    "        \n",
    "        self.layer = 'fc6+fc7+fc8'\n",
    "        self.size_multiplier=2.15\n",
    "        self.video_step = 1\n",
    "\n",
    "    def fit(self, train_imgs, train_labels):\n",
    "        n_images=len(train_imgs)\n",
    "        image_counter=0\n",
    "        \n",
    "        labels_orig = []\n",
    "        for id in train_imgs:\n",
    "          labels_orig.append(train_labels[id])\n",
    "        \n",
    "        labels_orig.extend(labels_orig)\n",
    "\n",
    "        preprocessed_images = np.array(preprocess_imgs(train_imgs.values(), size_multiplier=self.size_multiplier))\n",
    "        flipped_images=np.flip(preprocessed_images, -2)\n",
    "        augmented_images = np.vstack((preprocessed_images, flipped_images))\n",
    "\n",
    "        # augment images with two different scaling bottlenecks\n",
    "\n",
    "#        bottleneck_70 = np.zeros_like(augmented_images)\n",
    "#        bottleneck_110 = np.zeros_like(augmented_images)\n",
    "##\n",
    "#        n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#        bottleneck_70[i,:,:] = transform.resize(transform.resize(augmented_images[i], (70, 70)), (224, 224))\n",
    "#        bottleneck_110[i,:,:] = transform.resize(transform.resize(augmented_images[i], (110, 110)), (224, 224))\n",
    "\n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, bottleneck_70, bottleneck_110))\n",
    "        \n",
    "#        blur1 = np.zeros_like(augmented_images)\n",
    "#        blur2 = np.zeros_like(augmented_images)\n",
    "\n",
    "#        n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#         blur1[i,:,:] = filters.gaussian(augmented_images[i])\n",
    "#         blur2[i,:,:] = filters.gaussian(blur1[i])\n",
    "         \n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, blur1, blur2))\n",
    "\n",
    "#        print('augmented image set shape {}'.format(augmented_images.shape))\n",
    "\n",
    "#        #flip the images of the second half horizontally\n",
    "\n",
    "        pca1 = self.pca1.fit_transform(get_layer_output(augmented_images, layer='fc6'))\n",
    "        pca2 = self.pca2.fit_transform(get_layer_output(augmented_images, layer='fc7'))\n",
    "        pca3 = self.pca3.fit_transform(get_layer_output(augmented_images, layer='fc8'))\n",
    "        # pca2 = self.pca2.fit_transform(get_layer_output(augmented_images,layer='fc7'))\n",
    "        \n",
    "        self.x_train_internal= np.hstack((pca1,pca2,pca3))\n",
    "        self.y_train_internal = self.label_encoder.fit_transform(labels_orig)\n",
    "        \n",
    "        self.catboost_model.fit(self.x_train_internal, self.y_train_internal)\n",
    "        self.fitted=True\n",
    "\n",
    "    def classify_images(self, test_imgs):\n",
    "      assert self.fitted\n",
    "\n",
    "      n_images=len(test_imgs)\n",
    "      image_counter=0\n",
    "              \n",
    "      # x_test= get_layer_output(np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier)), layer=self.layer)\n",
    "      preprocess_result = np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier))   \n",
    "      pca1 =  self.pca1.transform(get_layer_output(preprocess_result, layer='fc6'))\n",
    "      pca2 =  self.pca2.transform(get_layer_output(preprocess_result, layer='fc7'))\n",
    "      pca3 =  self.pca3.transform(get_layer_output(preprocess_result, layer='fc8'))\n",
    "      x_test = np.hstack((pca1, pca2, pca3))  \n",
    "      ids=[] \n",
    "      for id in test_imgs:\n",
    "        ids.append(id)\n",
    "        \n",
    "      y_test=self.label_encoder.inverse_transform(self.catboost_model.predict(x_test))\n",
    "      print('mapping predictions back')\n",
    "      print(y_test.shape)\n",
    "      for i in range(n_images):\n",
    "        predictions[ids[i]] = str(y_test[i])\n",
    "      return predictions\n",
    "        \n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "        \n",
    "    def classify_videos(self, test_video):\n",
    "        assert self.fitted\n",
    "        predictions={}\n",
    "\n",
    "        video_step = 6\n",
    "\n",
    "        preprocess_pool=[]\n",
    "        pool_start={}\n",
    "        pool_end={}\n",
    "\n",
    "        # populate pool and preprocess all images in one lump\n",
    "        for id in test_video:\n",
    "          pool_start[id] = len(preprocess_pool) \n",
    "          preprocess_pool.extend(test_video[id][::video_step])\n",
    "          pool_end[id] = len(preprocess_pool) \n",
    "\n",
    "        preprocess_result = np.array(preprocess_imgs(preprocess_pool, size_multiplier=self.size_multiplier))\n",
    "        \n",
    "         \n",
    "        for id in test_video:\n",
    "          print('classifying video id ',id )\n",
    "          pca1 = self.pca1.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc6'))\n",
    "          pca2 = self.pca2.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc7'))\n",
    "          pca3 = self.pca3.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc8'))\n",
    "                                    \n",
    "          x_pred= np.hstack((pca1, pca2, pca3))\n",
    "          probs = self.catboost_model.predict_proba(x_pred)\n",
    "          y_pred= self.label_encoder.inverse_transform(self.catboost_model.predict(x_pred))\n",
    "          for row in range(probs.shape[0]):\n",
    "         #   print('Frame ',row)\n",
    "         #   #best_indices = probs[row,:].argsort()[-5:][::-1]\n",
    "         #   #print(neigh_dist.shape, neigh_ind.shape)\n",
    "         #   #print('best indices:', best_indices)\n",
    "         #   #for i in range(5):\n",
    "         #   #  print('{} (p={})'.format(self.label_encoder.inverse_transform(best_indices)[i],\n",
    "         #   #                           probs[row,best_indices[i]]))\n",
    "\n",
    "#            # collect sliding window of past nearest neighbours\n",
    "#\n",
    "#            windowstart=max(0,row-10)\n",
    "#            ind_window=np.array(neigh_ind[windowstart:row+1]).flatten() \n",
    "#            dist_window=np.array(neigh_dist[windowstart:row+1]).flatten() \n",
    "#\n",
    "#            ind_window_sorted = ind_window[np.argsort(dist_window)]\n",
    "#            dist_window_sorted = np.sort(dist_window)\n",
    "#\n",
    "#            \n",
    "#            print(neigh_dist[row])\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[neigh_ind[row]]))\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[ind_window_sorted]))\n",
    "#            print(dist_window_sorted)\n",
    "\n",
    "            print('Frame prediction: ',y_pred[row])\n",
    "\n",
    "          lst=list(y_pred)\n",
    "          predictions[id]=max(set(lst), key=lst.count) # mode of y_pred\n",
    "          print('prediction for video {}: {}'.format(id,predictions[id]))\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSLiFmtWLgan"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from statistics import mode\n",
    "\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from os.path import join\n",
    "class ClassifierVideo():\n",
    "    def __init__(self, nn_model):\n",
    "        self.label_encoder = preprocessing.LabelEncoder()\n",
    "        self.standard_scaler = preprocessing.StandardScaler()\n",
    "        self.fitted = False\n",
    "        self.feature_dim = 4096\n",
    "        self.knn_model = kNN(n_neighbors=5)\n",
    "        self.pca = decomposition.PCA(0.9, whiten=True)\n",
    "        self.pca2 = decomposition.PCA(0.9, whiten=True)\n",
    "        self.layer = 'fc7'\n",
    "        self.size_multiplier=2.15\n",
    "        self.video_step = 1\n",
    "\n",
    "    def fit(self, train_imgs, train_labels):\n",
    "        n_images=len(train_imgs)\n",
    "        image_counter=0\n",
    "        \n",
    "        labels_orig = []\n",
    "        for id in train_imgs:\n",
    "          labels_orig.append(train_labels[id])\n",
    "        \n",
    "        labels_orig.extend(labels_orig)\n",
    "\n",
    "        preprocessed_images = np.array(preprocess_imgs(train_imgs.values(), size_multiplier=self.size_multiplier))\n",
    "        flipped_images=np.flip(preprocessed_images, -2)\n",
    "        augmented_images = np.vstack((preprocessed_images, flipped_images))\n",
    "\n",
    "        # augment images with two different scaling bottlenecks\n",
    "\n",
    "        #bottleneck_70 = np.zeros_like(augmented_images)\n",
    "        #bottleneck_110 = np.zeros_like(augmented_images)\n",
    "#\n",
    "#       n_augm = augmented_images.shape[0]\n",
    "#        for i in range(n_augm):\n",
    "#         bottleneck_70[i,:,:] = transform.resize(transform.resize(augmented_images[i], (70, 70)), (224, 224))\n",
    "#         bottleneck_110[i,:,:] = transform.resize(transform.resize(augmented_images[i], (110, 110)), (224, 224))\n",
    "#\n",
    "#        labels_orig = labels_orig * 3\n",
    "#        augmented_images = np.vstack((augmented_images, bottleneck_70, bottleneck_110))\n",
    "        \n",
    " #       blur1 = np.zeros_like(augmented_images)\n",
    " #       blur2 = np.zeros_like(augmented_images)\n",
    "\n",
    " #       n_augm = augmented_images.shape[0]\n",
    " #       for i in range(n_augm):\n",
    " #        blur1[i,:,:] = filters.gaussian(augmented_images[i])\n",
    " #        blur2[i,:,:] = filters.gaussian(blur1[i])\n",
    "         \n",
    " #       labels_orig = labels_orig * 3\n",
    " #       augmented_images = np.vstack((augmented_images, blur1, blur2))\n",
    "\n",
    "        print('augmented image set shape {}'.format(augmented_images.shape))\n",
    "\n",
    "        #flip the images of the second half horizontally\n",
    "\n",
    "        pca1 = self.pca.fit_transform(get_layer_output(augmented_images,layer=self.layer))\n",
    "        # pca2 = self.pca2.fit_transform(get_layer_output(augmented_images,layer='fc7'))\n",
    "        \n",
    "        self.x_train_internal= pca1\n",
    "        self.y_train_internal = self.label_encoder.fit_transform(labels_orig)\n",
    "        \n",
    "        self.knn_model.fit(self.x_train_internal, self.y_train_internal)\n",
    "        self.fitted=True\n",
    "\n",
    "    def classify_images(self, test_imgs):\n",
    "      assert self.fitted\n",
    "      predictions={}\n",
    "\n",
    "      n_images=len(test_imgs)\n",
    "      image_counter=0\n",
    "              \n",
    "      x_test= self.pca.transform(get_layer_output(np.array(preprocess_imgs(test_imgs.values(), size_multiplier=self.size_multiplier)), layer=self.layer))\n",
    "      ids=[] \n",
    "      for id in test_imgs:\n",
    "        ids.append(id)\n",
    "\n",
    "      y_test=self.label_encoder.inverse_transform(self.knn_model.predict(x_test))\n",
    "      print('mapping predictions back')\n",
    "      print(y_test.shape)\n",
    "      for i in range(n_images):\n",
    "        predictions[ids[i]] = str(y_test[i])\n",
    "      return predictions\n",
    "        \n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "        \n",
    "    def classify_videos(self, test_video):\n",
    "        assert self.fitted\n",
    "        predictions={}\n",
    "\n",
    "        video_step = 6\n",
    "\n",
    "        preprocess_pool=[]\n",
    "        pool_start={}\n",
    "        pool_end={}\n",
    "\n",
    "        # populate pool and preprocess all images in one lump\n",
    "        for id in test_video:\n",
    "          pool_start[id] = len(preprocess_pool) \n",
    "          preprocess_pool.extend(test_video[id][::video_step])\n",
    "          pool_end[id] = len(preprocess_pool) \n",
    "\n",
    "        preprocess_result = np.array(preprocess_imgs(preprocess_pool, size_multiplier=self.size_multiplier))\n",
    "        \n",
    "         \n",
    "        for id in test_video:\n",
    "          print('classifying video id ',id )\n",
    "          pca1 = self.pca.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer=self.layer))\n",
    "          # pca2 = self.pca2.transform(get_layer_output(preprocess_result[pool_start[id]:pool_end[id]], layer='fc7'))\n",
    "                                    \n",
    "          x_pred= pca1 # np.hstack((pca1, pca2))\n",
    "          probs = self.knn_model.predict_proba(x_pred)\n",
    "          y_pred= self.label_encoder.inverse_transform(self.knn_model.predict(x_pred))\n",
    " #         neigh_dist, neigh_ind = self.knn_model.kneighbors(x_pred, return_distance=True)\n",
    "          for row in range(probs.shape[0]):\n",
    "         #   print('Frame ',row)\n",
    "         #   #best_indices = probs[row,:].argsort()[-5:][::-1]\n",
    "         #   #print(neigh_dist.shape, neigh_ind.shape)\n",
    "         #   #print('best indices:', best_indices)\n",
    "         #   #for i in range(5):\n",
    "         #   #  print('{} (p={})'.format(self.label_encoder.inverse_transform(best_indices)[i],\n",
    "         #   #                           probs[row,best_indices[i]]))\n",
    "\n",
    "#            # collect sliding window of past nearest neighbours\n",
    "#\n",
    "#            windowstart=max(0,row-10)\n",
    "#            ind_window=np.array(neigh_ind[windowstart:row+1]).flatten() \n",
    "#            dist_window=np.array(neigh_dist[windowstart:row+1]).flatten() \n",
    "#\n",
    "#            ind_window_sorted = ind_window[np.argsort(dist_window)]\n",
    "#            dist_window_sorted = np.sort(dist_window)\n",
    "#\n",
    "#            \n",
    "#            print(neigh_dist[row])\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[neigh_ind[row]]))\n",
    "#            print(self.label_encoder.inverse_transform(self.y_train_internal[ind_window_sorted]))\n",
    "#            print(dist_window_sorted)\n",
    "\n",
    "            print('Frame prediction: ',y_pred[row])\n",
    "\n",
    "          lst=list(y_pred)\n",
    "          predictions[id]=max(set(lst), key=lst.count) # mode of y_pred\n",
    "          print('prediction for video {}: {}'.format(id,predictions[id]))\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdT5_xfVsqSu"
   },
   "outputs": [],
   "source": [
    "len(video_test['0'][::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAgG4UyJoL6Q"
   },
   "outputs": [],
   "source": [
    "# %%capture cap_out --no-stderr\n",
    "\n",
    "def extract_subdict(d, keys):\n",
    "    return dict((k, d[k]) for k in keys if k in d)\n",
    "\n",
    "difficult_labels=['10','14','16','29','35','40','43','49','5','50','53','54','57','59','63']\n",
    "testing_labels = ['0','1','11']+difficult_labels\n",
    "video_classifier = ClassifierVideo(model)\n",
    "video_classifier.fit(video_train, train_labels)\n",
    "y_video_difficult_out = video_classifier.classify_videos(extract_subdict(video_test, testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsTLjxSpthaS"
   },
   "outputs": [],
   "source": [
    "with open('fc7-heq-2.15.txt', 'w') as f:\n",
    "    f.write(cap_out.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing image 1/1390\n",
      "Preprocessing image 11/1390\n",
      "Preprocessing image 21/1390\n",
      "Preprocessing image 31/1390\n",
      "Preprocessing image 41/1390\n",
      "Preprocessing image 51/1390\n",
      "Preprocessing image 61/1390\n",
      "Preprocessing image 71/1390\n",
      "Preprocessing image 81/1390\n",
      "Preprocessing image 91/1390\n",
      "Preprocessing image 101/1390\n",
      "Preprocessing image 111/1390\n",
      "Preprocessing image 121/1390\n",
      "Preprocessing image 131/1390\n",
      "Preprocessing image 141/1390\n",
      "Preprocessing image 151/1390\n",
      "Preprocessing image 161/1390\n",
      "Preprocessing image 171/1390\n",
      "Preprocessing image 181/1390\n",
      "Preprocessing image 191/1390\n",
      "Preprocessing image 201/1390\n",
      "Preprocessing image 211/1390\n",
      "Preprocessing image 221/1390\n",
      "Preprocessing image 231/1390\n",
      "Preprocessing image 241/1390\n",
      "Preprocessing image 251/1390\n",
      "Preprocessing image 261/1390\n",
      "Preprocessing image 271/1390\n",
      "Preprocessing image 281/1390\n",
      "Preprocessing image 291/1390\n",
      "Preprocessing image 301/1390\n",
      "Preprocessing image 311/1390\n",
      "Preprocessing image 321/1390\n",
      "Preprocessing image 331/1390\n",
      "Preprocessing image 341/1390\n",
      "Preprocessing image 351/1390\n",
      "Preprocessing image 361/1390\n",
      "Preprocessing image 371/1390\n",
      "Preprocessing image 381/1390\n",
      "Preprocessing image 391/1390\n",
      "Preprocessing image 401/1390\n",
      "Preprocessing image 411/1390\n",
      "Preprocessing image 421/1390\n",
      "Preprocessing image 431/1390\n",
      "Preprocessing image 441/1390\n",
      "Preprocessing image 451/1390\n",
      "Preprocessing image 461/1390\n",
      "Preprocessing image 471/1390\n",
      "Preprocessing image 481/1390\n",
      "Preprocessing image 491/1390\n",
      "Preprocessing image 501/1390\n",
      "Preprocessing image 511/1390\n",
      "Preprocessing image 521/1390\n",
      "Preprocessing image 531/1390\n",
      "Preprocessing image 541/1390\n",
      "Preprocessing image 551/1390\n",
      "Preprocessing image 561/1390\n",
      "Preprocessing image 571/1390\n",
      "Preprocessing image 581/1390\n",
      "Preprocessing image 591/1390\n",
      "Preprocessing image 601/1390\n",
      "Preprocessing image 611/1390\n",
      "Preprocessing image 621/1390\n",
      "Preprocessing image 631/1390\n",
      "Preprocessing image 641/1390\n",
      "Preprocessing image 651/1390\n",
      "Preprocessing image 661/1390\n",
      "Preprocessing image 671/1390\n",
      "Preprocessing image 681/1390\n",
      "Preprocessing image 691/1390\n",
      "Preprocessing image 701/1390\n",
      "Preprocessing image 711/1390\n",
      "Preprocessing image 721/1390\n",
      "Preprocessing image 731/1390\n",
      "Preprocessing image 741/1390\n",
      "Preprocessing image 751/1390\n",
      "Preprocessing image 761/1390\n",
      "Preprocessing image 771/1390\n",
      "Preprocessing image 781/1390\n",
      "Preprocessing image 791/1390\n",
      "Preprocessing image 801/1390\n",
      "Preprocessing image 811/1390\n",
      "Preprocessing image 821/1390\n",
      "Preprocessing image 831/1390\n",
      "Preprocessing image 841/1390\n",
      "Preprocessing image 851/1390\n",
      "Preprocessing image 861/1390\n",
      "Preprocessing image 871/1390\n",
      "Preprocessing image 881/1390\n",
      "Preprocessing image 891/1390\n",
      "Preprocessing image 901/1390\n",
      "Preprocessing image 911/1390\n",
      "Preprocessing image 921/1390\n",
      "Preprocessing image 931/1390\n",
      "Preprocessing image 941/1390\n",
      "Preprocessing image 951/1390\n",
      "Preprocessing image 961/1390\n",
      "Preprocessing image 971/1390\n",
      "Preprocessing image 981/1390\n",
      "Preprocessing image 991/1390\n",
      "Preprocessing image 1001/1390\n",
      "Preprocessing image 1011/1390\n",
      "Preprocessing image 1021/1390\n",
      "Preprocessing image 1031/1390\n",
      "Preprocessing image 1041/1390\n",
      "Preprocessing image 1051/1390\n",
      "Preprocessing image 1061/1390\n",
      "Preprocessing image 1071/1390\n",
      "Preprocessing image 1081/1390\n",
      "Preprocessing image 1091/1390\n",
      "Preprocessing image 1101/1390\n",
      "Preprocessing image 1111/1390\n",
      "Preprocessing image 1121/1390\n",
      "Preprocessing image 1131/1390\n",
      "Preprocessing image 1141/1390\n",
      "Preprocessing image 1151/1390\n",
      "Preprocessing image 1161/1390\n",
      "Preprocessing image 1171/1390\n",
      "Preprocessing image 1181/1390\n",
      "Preprocessing image 1191/1390\n",
      "Preprocessing image 1201/1390\n",
      "Preprocessing image 1211/1390\n",
      "Preprocessing image 1221/1390\n",
      "Preprocessing image 1231/1390\n",
      "Preprocessing image 1241/1390\n",
      "Preprocessing image 1251/1390\n",
      "Preprocessing image 1261/1390\n",
      "Preprocessing image 1271/1390\n",
      "Preprocessing image 1281/1390\n",
      "Preprocessing image 1291/1390\n",
      "Preprocessing image 1301/1390\n",
      "Preprocessing image 1311/1390\n",
      "Preprocessing image 1321/1390\n",
      "Preprocessing image 1331/1390\n",
      "Preprocessing image 1341/1390\n",
      "Preprocessing image 1351/1390\n",
      "Preprocessing image 1361/1390\n",
      "Preprocessing image 1371/1390\n",
      "Preprocessing image 1381/1390\n",
      "0:\tlearn: 5.1498671\ttotal: 9.07s\tremaining: 1h 53m 16s\n",
      "1:\tlearn: 5.1216046\ttotal: 18.3s\tremaining: 1h 54m 7s\n",
      "2:\tlearn: 5.0941006\ttotal: 27.3s\tremaining: 1h 53m 20s\n",
      "3:\tlearn: 5.0567899\ttotal: 36.4s\tremaining: 1h 53m 7s\n",
      "4:\tlearn: 5.0164876\ttotal: 46s\tremaining: 1h 54m 15s\n",
      "5:\tlearn: 4.9826047\ttotal: 55s\tremaining: 1h 53m 41s\n",
      "6:\tlearn: 4.9447025\ttotal: 1m 4s\tremaining: 1h 53m 30s\n",
      "7:\tlearn: 4.9044594\ttotal: 1m 13s\tremaining: 1h 53m 8s\n",
      "8:\tlearn: 4.8717041\ttotal: 1m 22s\tremaining: 1h 52m 58s\n",
      "9:\tlearn: 4.8378583\ttotal: 1m 31s\tremaining: 1h 52m 36s\n",
      "10:\tlearn: 4.8017438\ttotal: 1m 40s\tremaining: 1h 52m 29s\n",
      "11:\tlearn: 4.7572343\ttotal: 1m 49s\tremaining: 1h 52m 20s\n",
      "12:\tlearn: 4.7306956\ttotal: 1m 58s\tremaining: 1h 52m 6s\n",
      "13:\tlearn: 4.7033427\ttotal: 2m 8s\tremaining: 1h 52m 13s\n",
      "14:\tlearn: 4.6663463\ttotal: 2m 17s\tremaining: 1h 51m 57s\n",
      "15:\tlearn: 4.6193104\ttotal: 2m 26s\tremaining: 1h 51m 51s\n",
      "16:\tlearn: 4.5837891\ttotal: 2m 35s\tremaining: 1h 51m 31s\n",
      "17:\tlearn: 4.5460958\ttotal: 2m 44s\tremaining: 1h 51m 23s\n",
      "18:\tlearn: 4.5147685\ttotal: 2m 53s\tremaining: 1h 51m 18s\n",
      "19:\tlearn: 4.4805425\ttotal: 3m 2s\tremaining: 1h 51m 3s\n",
      "20:\tlearn: 4.4419135\ttotal: 3m 11s\tremaining: 1h 50m 58s\n",
      "21:\tlearn: 4.4012451\ttotal: 3m 20s\tremaining: 1h 50m 45s\n",
      "22:\tlearn: 4.3729084\ttotal: 3m 30s\tremaining: 1h 50m 38s\n",
      "23:\tlearn: 4.3448629\ttotal: 3m 39s\tremaining: 1h 50m 26s\n",
      "24:\tlearn: 4.3069181\ttotal: 3m 48s\tremaining: 1h 50m 18s\n",
      "25:\tlearn: 4.2716605\ttotal: 3m 57s\tremaining: 1h 50m 10s\n",
      "26:\tlearn: 4.2365378\ttotal: 4m 6s\tremaining: 1h 49m 57s\n",
      "27:\tlearn: 4.2155574\ttotal: 4m 15s\tremaining: 1h 49m 52s\n",
      "28:\tlearn: 4.1903392\ttotal: 4m 24s\tremaining: 1h 49m 38s\n",
      "29:\tlearn: 4.1534230\ttotal: 4m 33s\tremaining: 1h 49m 30s\n",
      "30:\tlearn: 4.1235182\ttotal: 4m 42s\tremaining: 1h 49m 17s\n",
      "31:\tlearn: 4.0953999\ttotal: 4m 51s\tremaining: 1h 49m 7s\n",
      "32:\tlearn: 4.0655753\ttotal: 5m\tremaining: 1h 48m 57s\n",
      "33:\tlearn: 4.0274896\ttotal: 5m 9s\tremaining: 1h 48m 47s\n",
      "34:\tlearn: 3.9955709\ttotal: 5m 19s\tremaining: 1h 48m 41s\n",
      "35:\tlearn: 3.9684721\ttotal: 5m 28s\tremaining: 1h 48m 29s\n",
      "36:\tlearn: 3.9392637\ttotal: 5m 37s\tremaining: 1h 48m 22s\n",
      "37:\tlearn: 3.9031294\ttotal: 5m 46s\tremaining: 1h 48m 12s\n",
      "38:\tlearn: 3.8736230\ttotal: 5m 55s\tremaining: 1h 48m 3s\n",
      "39:\tlearn: 3.8357220\ttotal: 6m 4s\tremaining: 1h 47m 54s\n",
      "40:\tlearn: 3.8088459\ttotal: 6m 13s\tremaining: 1h 47m 45s\n",
      "41:\tlearn: 3.7822319\ttotal: 6m 23s\tremaining: 1h 47m 38s\n",
      "42:\tlearn: 3.7511769\ttotal: 6m 32s\tremaining: 1h 47m 31s\n",
      "43:\tlearn: 3.7165253\ttotal: 6m 41s\tremaining: 1h 47m 22s\n",
      "44:\tlearn: 3.6875821\ttotal: 6m 50s\tremaining: 1h 47m 10s\n",
      "45:\tlearn: 3.6569366\ttotal: 6m 59s\tremaining: 1h 47m 3s\n",
      "46:\tlearn: 3.6286773\ttotal: 7m 8s\tremaining: 1h 46m 53s\n",
      "47:\tlearn: 3.6038677\ttotal: 7m 17s\tremaining: 1h 46m 43s\n",
      "48:\tlearn: 3.5711853\ttotal: 7m 27s\tremaining: 1h 46m 36s\n",
      "49:\tlearn: 3.5472780\ttotal: 7m 36s\tremaining: 1h 46m 26s\n",
      "50:\tlearn: 3.5206763\ttotal: 7m 45s\tremaining: 1h 46m 18s\n",
      "51:\tlearn: 3.4919848\ttotal: 7m 54s\tremaining: 1h 46m 7s\n",
      "52:\tlearn: 3.4623043\ttotal: 8m 3s\tremaining: 1h 46m\n",
      "53:\tlearn: 3.4315005\ttotal: 8m 12s\tremaining: 1h 45m 49s\n",
      "54:\tlearn: 3.4001865\ttotal: 8m 21s\tremaining: 1h 45m 40s\n",
      "55:\tlearn: 3.3688348\ttotal: 8m 31s\tremaining: 1h 45m 33s\n",
      "56:\tlearn: 3.3399954\ttotal: 8m 40s\tremaining: 1h 45m 23s\n",
      "57:\tlearn: 3.3076635\ttotal: 8m 49s\tremaining: 1h 45m 15s\n",
      "58:\tlearn: 3.2755438\ttotal: 8m 58s\tremaining: 1h 45m 5s\n",
      "59:\tlearn: 3.2499083\ttotal: 9m 7s\tremaining: 1h 44m 56s\n",
      "60:\tlearn: 3.2214326\ttotal: 9m 16s\tremaining: 1h 44m 46s\n",
      "61:\tlearn: 3.1982841\ttotal: 9m 25s\tremaining: 1h 44m 37s\n",
      "62:\tlearn: 3.1771088\ttotal: 9m 34s\tremaining: 1h 44m 29s\n",
      "63:\tlearn: 3.1458613\ttotal: 9m 44s\tremaining: 1h 44m 20s\n",
      "64:\tlearn: 3.1250313\ttotal: 9m 53s\tremaining: 1h 44m 11s\n",
      "65:\tlearn: 3.0989036\ttotal: 10m 2s\tremaining: 1h 44m 1s\n",
      "66:\tlearn: 3.0811729\ttotal: 10m 11s\tremaining: 1h 43m 53s\n",
      "67:\tlearn: 3.0547505\ttotal: 10m 20s\tremaining: 1h 43m 42s\n",
      "68:\tlearn: 3.0304895\ttotal: 10m 29s\tremaining: 1h 43m 33s\n",
      "69:\tlearn: 3.0074632\ttotal: 10m 38s\tremaining: 1h 43m 25s\n",
      "70:\tlearn: 2.9873240\ttotal: 10m 47s\tremaining: 1h 43m 16s\n",
      "71:\tlearn: 2.9674124\ttotal: 10m 57s\tremaining: 1h 43m 8s\n",
      "72:\tlearn: 2.9385503\ttotal: 11m 6s\tremaining: 1h 42m 59s\n",
      "73:\tlearn: 2.9158754\ttotal: 11m 15s\tremaining: 1h 42m 50s\n",
      "74:\tlearn: 2.8926781\ttotal: 11m 24s\tremaining: 1h 42m 40s\n",
      "75:\tlearn: 2.8705090\ttotal: 11m 33s\tremaining: 1h 42m 32s\n",
      "76:\tlearn: 2.8480087\ttotal: 11m 43s\tremaining: 1h 42m 25s\n",
      "77:\tlearn: 2.8271883\ttotal: 11m 52s\tremaining: 1h 42m 15s\n",
      "78:\tlearn: 2.8054329\ttotal: 12m 1s\tremaining: 1h 42m 6s\n",
      "79:\tlearn: 2.7844529\ttotal: 12m 10s\tremaining: 1h 41m 56s\n",
      "80:\tlearn: 2.7662542\ttotal: 12m 19s\tremaining: 1h 41m 47s\n",
      "81:\tlearn: 2.7485951\ttotal: 12m 28s\tremaining: 1h 41m 38s\n",
      "82:\tlearn: 2.7319737\ttotal: 12m 37s\tremaining: 1h 41m 28s\n",
      "83:\tlearn: 2.7082628\ttotal: 12m 46s\tremaining: 1h 41m 20s\n",
      "84:\tlearn: 2.6894825\ttotal: 12m 55s\tremaining: 1h 41m 10s\n",
      "85:\tlearn: 2.6686056\ttotal: 13m 5s\tremaining: 1h 41m 2s\n",
      "86:\tlearn: 2.6488531\ttotal: 13m 14s\tremaining: 1h 40m 52s\n",
      "87:\tlearn: 2.6252864\ttotal: 13m 23s\tremaining: 1h 40m 43s\n",
      "88:\tlearn: 2.6028618\ttotal: 13m 32s\tremaining: 1h 40m 34s\n",
      "89:\tlearn: 2.5839284\ttotal: 13m 41s\tremaining: 1h 40m 25s\n",
      "90:\tlearn: 2.5640315\ttotal: 13m 50s\tremaining: 1h 40m 16s\n",
      "91:\tlearn: 2.5425878\ttotal: 13m 59s\tremaining: 1h 40m 7s\n",
      "92:\tlearn: 2.5226453\ttotal: 14m 9s\tremaining: 1h 39m 59s\n",
      "93:\tlearn: 2.5058909\ttotal: 14m 18s\tremaining: 1h 39m 49s\n",
      "94:\tlearn: 2.4850691\ttotal: 14m 27s\tremaining: 1h 39m 40s\n",
      "95:\tlearn: 2.4679531\ttotal: 14m 36s\tremaining: 1h 39m 31s\n",
      "96:\tlearn: 2.4507798\ttotal: 14m 45s\tremaining: 1h 39m 22s\n",
      "97:\tlearn: 2.4280350\ttotal: 14m 54s\tremaining: 1h 39m 13s\n",
      "98:\tlearn: 2.4090618\ttotal: 15m 3s\tremaining: 1h 39m 3s\n",
      "99:\tlearn: 2.3908089\ttotal: 15m 13s\tremaining: 1h 38m 54s\n",
      "100:\tlearn: 2.3690059\ttotal: 15m 22s\tremaining: 1h 38m 44s\n",
      "101:\tlearn: 2.3527110\ttotal: 15m 31s\tremaining: 1h 38m 36s\n",
      "102:\tlearn: 2.3317110\ttotal: 15m 40s\tremaining: 1h 38m 27s\n",
      "103:\tlearn: 2.3104638\ttotal: 15m 49s\tremaining: 1h 38m 18s\n",
      "104:\tlearn: 2.2905261\ttotal: 15m 58s\tremaining: 1h 38m 9s\n",
      "105:\tlearn: 2.2742403\ttotal: 16m 7s\tremaining: 1h 37m 59s\n",
      "106:\tlearn: 2.2566544\ttotal: 16m 17s\tremaining: 1h 37m 51s\n",
      "107:\tlearn: 2.2402252\ttotal: 16m 26s\tremaining: 1h 37m 41s\n",
      "108:\tlearn: 2.2255383\ttotal: 16m 35s\tremaining: 1h 37m 33s\n",
      "109:\tlearn: 2.2104176\ttotal: 16m 44s\tremaining: 1h 37m 23s\n",
      "110:\tlearn: 2.1901857\ttotal: 16m 53s\tremaining: 1h 37m 14s\n",
      "111:\tlearn: 2.1730807\ttotal: 17m 2s\tremaining: 1h 37m 5s\n",
      "112:\tlearn: 2.1576790\ttotal: 17m 11s\tremaining: 1h 36m 55s\n",
      "113:\tlearn: 2.1433589\ttotal: 17m 20s\tremaining: 1h 36m 47s\n",
      "114:\tlearn: 2.1261888\ttotal: 17m 30s\tremaining: 1h 36m 37s\n",
      "115:\tlearn: 2.1107459\ttotal: 17m 39s\tremaining: 1h 36m 29s\n",
      "116:\tlearn: 2.0944438\ttotal: 17m 48s\tremaining: 1h 36m 20s\n",
      "117:\tlearn: 2.0800834\ttotal: 17m 57s\tremaining: 1h 36m 11s\n",
      "118:\tlearn: 2.0685913\ttotal: 18m 6s\tremaining: 1h 36m 3s\n",
      "119:\tlearn: 2.0534405\ttotal: 18m 15s\tremaining: 1h 35m 53s\n",
      "120:\tlearn: 2.0355055\ttotal: 18m 25s\tremaining: 1h 35m 45s\n",
      "121:\tlearn: 2.0232914\ttotal: 18m 34s\tremaining: 1h 35m 35s\n",
      "122:\tlearn: 2.0091452\ttotal: 18m 43s\tremaining: 1h 35m 26s\n",
      "123:\tlearn: 1.9917605\ttotal: 18m 52s\tremaining: 1h 35m 17s\n",
      "124:\tlearn: 1.9760395\ttotal: 19m 1s\tremaining: 1h 35m 8s\n",
      "125:\tlearn: 1.9602213\ttotal: 19m 10s\tremaining: 1h 34m 59s\n",
      "126:\tlearn: 1.9434820\ttotal: 19m 19s\tremaining: 1h 34m 50s\n",
      "127:\tlearn: 1.9296879\ttotal: 19m 29s\tremaining: 1h 34m 41s\n",
      "128:\tlearn: 1.9154802\ttotal: 19m 38s\tremaining: 1h 34m 31s\n",
      "129:\tlearn: 1.8970157\ttotal: 19m 47s\tremaining: 1h 34m 23s\n",
      "130:\tlearn: 1.8827403\ttotal: 19m 56s\tremaining: 1h 34m 13s\n",
      "131:\tlearn: 1.8671263\ttotal: 20m 5s\tremaining: 1h 34m 4s\n",
      "132:\tlearn: 1.8542325\ttotal: 20m 14s\tremaining: 1h 33m 54s\n",
      "133:\tlearn: 1.8408636\ttotal: 20m 23s\tremaining: 1h 33m 45s\n",
      "134:\tlearn: 1.8257367\ttotal: 20m 32s\tremaining: 1h 33m 36s\n",
      "135:\tlearn: 1.8095391\ttotal: 20m 42s\tremaining: 1h 33m 27s\n",
      "136:\tlearn: 1.7955125\ttotal: 20m 51s\tremaining: 1h 33m 18s\n",
      "137:\tlearn: 1.7786895\ttotal: 21m\tremaining: 1h 33m 9s\n",
      "138:\tlearn: 1.7637045\ttotal: 21m 9s\tremaining: 1h 33m\n",
      "139:\tlearn: 1.7498505\ttotal: 21m 18s\tremaining: 1h 32m 51s\n",
      "140:\tlearn: 1.7369311\ttotal: 21m 27s\tremaining: 1h 32m 42s\n",
      "141:\tlearn: 1.7208708\ttotal: 21m 37s\tremaining: 1h 32m 33s\n",
      "142:\tlearn: 1.7069042\ttotal: 21m 46s\tremaining: 1h 32m 24s\n",
      "143:\tlearn: 1.6920623\ttotal: 21m 55s\tremaining: 1h 32m 15s\n",
      "144:\tlearn: 1.6796187\ttotal: 22m 4s\tremaining: 1h 32m 5s\n",
      "145:\tlearn: 1.6651101\ttotal: 22m 13s\tremaining: 1h 31m 57s\n",
      "146:\tlearn: 1.6514454\ttotal: 22m 22s\tremaining: 1h 31m 47s\n",
      "147:\tlearn: 1.6375030\ttotal: 22m 31s\tremaining: 1h 31m 38s\n",
      "148:\tlearn: 1.6223146\ttotal: 22m 41s\tremaining: 1h 31m 30s\n",
      "149:\tlearn: 1.6116701\ttotal: 22m 50s\tremaining: 1h 31m 20s\n",
      "150:\tlearn: 1.5985996\ttotal: 22m 59s\tremaining: 1h 31m 11s\n",
      "151:\tlearn: 1.5865936\ttotal: 23m 8s\tremaining: 1h 31m 1s\n",
      "152:\tlearn: 1.5732256\ttotal: 23m 17s\tremaining: 1h 30m 53s\n",
      "153:\tlearn: 1.5611862\ttotal: 23m 26s\tremaining: 1h 30m 43s\n",
      "154:\tlearn: 1.5477938\ttotal: 23m 35s\tremaining: 1h 30m 35s\n",
      "155:\tlearn: 1.5361701\ttotal: 23m 45s\tremaining: 1h 30m 25s\n",
      "156:\tlearn: 1.5238910\ttotal: 23m 54s\tremaining: 1h 30m 16s\n",
      "157:\tlearn: 1.5087566\ttotal: 24m 3s\tremaining: 1h 30m 7s\n",
      "158:\tlearn: 1.4991402\ttotal: 24m 12s\tremaining: 1h 29m 58s\n",
      "159:\tlearn: 1.4875382\ttotal: 24m 21s\tremaining: 1h 29m 49s\n",
      "160:\tlearn: 1.4767029\ttotal: 24m 30s\tremaining: 1h 29m 40s\n",
      "161:\tlearn: 1.4668119\ttotal: 24m 39s\tremaining: 1h 29m 31s\n",
      "162:\tlearn: 1.4572129\ttotal: 24m 48s\tremaining: 1h 29m 22s\n",
      "163:\tlearn: 1.4446763\ttotal: 24m 58s\tremaining: 1h 29m 12s\n",
      "164:\tlearn: 1.4322023\ttotal: 25m 7s\tremaining: 1h 29m 4s\n",
      "165:\tlearn: 1.4204806\ttotal: 25m 16s\tremaining: 1h 28m 54s\n",
      "166:\tlearn: 1.4088723\ttotal: 25m 25s\tremaining: 1h 28m 46s\n",
      "167:\tlearn: 1.3990578\ttotal: 25m 34s\tremaining: 1h 28m 36s\n",
      "168:\tlearn: 1.3883857\ttotal: 25m 43s\tremaining: 1h 28m 27s\n",
      "169:\tlearn: 1.3784893\ttotal: 25m 53s\tremaining: 1h 28m 19s\n",
      "170:\tlearn: 1.3703088\ttotal: 26m 2s\tremaining: 1h 28m 9s\n",
      "171:\tlearn: 1.3605630\ttotal: 26m 11s\tremaining: 1h 28m\n",
      "172:\tlearn: 1.3497881\ttotal: 26m 20s\tremaining: 1h 27m 51s\n",
      "173:\tlearn: 1.3390702\ttotal: 26m 29s\tremaining: 1h 27m 42s\n",
      "174:\tlearn: 1.3292848\ttotal: 26m 38s\tremaining: 1h 27m 32s\n",
      "175:\tlearn: 1.3194726\ttotal: 26m 47s\tremaining: 1h 27m 24s\n",
      "176:\tlearn: 1.3094407\ttotal: 26m 57s\tremaining: 1h 27m 15s\n",
      "177:\tlearn: 1.2995985\ttotal: 27m 6s\tremaining: 1h 27m 5s\n",
      "178:\tlearn: 1.2889501\ttotal: 27m 15s\tremaining: 1h 26m 57s\n",
      "179:\tlearn: 1.2786196\ttotal: 27m 24s\tremaining: 1h 26m 47s\n",
      "180:\tlearn: 1.2687723\ttotal: 27m 33s\tremaining: 1h 26m 38s\n",
      "181:\tlearn: 1.2591399\ttotal: 27m 42s\tremaining: 1h 26m 29s\n",
      "182:\tlearn: 1.2479118\ttotal: 27m 52s\tremaining: 1h 26m 20s\n",
      "183:\tlearn: 1.2357441\ttotal: 28m 1s\tremaining: 1h 26m 12s\n",
      "184:\tlearn: 1.2268871\ttotal: 28m 10s\tremaining: 1h 26m 2s\n",
      "185:\tlearn: 1.2195207\ttotal: 28m 19s\tremaining: 1h 25m 53s\n",
      "186:\tlearn: 1.2105135\ttotal: 28m 28s\tremaining: 1h 25m 44s\n",
      "187:\tlearn: 1.1996563\ttotal: 28m 37s\tremaining: 1h 25m 35s\n",
      "188:\tlearn: 1.1895065\ttotal: 28m 46s\tremaining: 1h 25m 26s\n",
      "189:\tlearn: 1.1811478\ttotal: 28m 56s\tremaining: 1h 25m 17s\n",
      "190:\tlearn: 1.1719924\ttotal: 29m 5s\tremaining: 1h 25m 8s\n",
      "191:\tlearn: 1.1636178\ttotal: 29m 14s\tremaining: 1h 24m 58s\n",
      "192:\tlearn: 1.1529711\ttotal: 29m 23s\tremaining: 1h 24m 49s\n",
      "193:\tlearn: 1.1444057\ttotal: 29m 32s\tremaining: 1h 24m 40s\n",
      "194:\tlearn: 1.1365553\ttotal: 29m 41s\tremaining: 1h 24m 31s\n",
      "195:\tlearn: 1.1281742\ttotal: 29m 51s\tremaining: 1h 24m 22s\n",
      "196:\tlearn: 1.1202299\ttotal: 30m\tremaining: 1h 24m 13s\n",
      "197:\tlearn: 1.1125620\ttotal: 30m 9s\tremaining: 1h 24m 4s\n",
      "198:\tlearn: 1.1046668\ttotal: 30m 18s\tremaining: 1h 23m 55s\n",
      "199:\tlearn: 1.0963393\ttotal: 30m 27s\tremaining: 1h 23m 46s\n",
      "200:\tlearn: 1.0870627\ttotal: 30m 36s\tremaining: 1h 23m 37s\n",
      "201:\tlearn: 1.0780366\ttotal: 30m 46s\tremaining: 1h 23m 28s\n",
      "202:\tlearn: 1.0699357\ttotal: 30m 55s\tremaining: 1h 23m 18s\n",
      "203:\tlearn: 1.0615391\ttotal: 31m 4s\tremaining: 1h 23m 10s\n",
      "204:\tlearn: 1.0549699\ttotal: 31m 13s\tremaining: 1h 23m\n",
      "205:\tlearn: 1.0471107\ttotal: 31m 22s\tremaining: 1h 22m 51s\n",
      "206:\tlearn: 1.0382044\ttotal: 31m 31s\tremaining: 1h 22m 42s\n",
      "207:\tlearn: 1.0295791\ttotal: 31m 40s\tremaining: 1h 22m 33s\n",
      "208:\tlearn: 1.0210497\ttotal: 31m 50s\tremaining: 1h 22m 24s\n",
      "209:\tlearn: 1.0138582\ttotal: 31m 59s\tremaining: 1h 22m 15s\n",
      "210:\tlearn: 1.0055138\ttotal: 32m 8s\tremaining: 1h 22m 6s\n",
      "211:\tlearn: 0.9981765\ttotal: 32m 17s\tremaining: 1h 21m 57s\n",
      "212:\tlearn: 0.9911144\ttotal: 32m 26s\tremaining: 1h 21m 47s\n",
      "213:\tlearn: 0.9832552\ttotal: 32m 35s\tremaining: 1h 21m 38s\n",
      "214:\tlearn: 0.9758735\ttotal: 32m 44s\tremaining: 1h 21m 29s\n",
      "215:\tlearn: 0.9674213\ttotal: 32m 54s\tremaining: 1h 21m 20s\n",
      "216:\tlearn: 0.9602103\ttotal: 33m 3s\tremaining: 1h 21m 11s\n",
      "217:\tlearn: 0.9536431\ttotal: 33m 12s\tremaining: 1h 21m 2s\n",
      "218:\tlearn: 0.9469815\ttotal: 33m 21s\tremaining: 1h 20m 53s\n",
      "219:\tlearn: 0.9401290\ttotal: 33m 30s\tremaining: 1h 20m 43s\n",
      "220:\tlearn: 0.9325794\ttotal: 33m 39s\tremaining: 1h 20m 34s\n",
      "221:\tlearn: 0.9267935\ttotal: 33m 48s\tremaining: 1h 20m 25s\n",
      "222:\tlearn: 0.9186567\ttotal: 33m 57s\tremaining: 1h 20m 16s\n",
      "223:\tlearn: 0.9120732\ttotal: 34m 6s\tremaining: 1h 20m 6s\n",
      "224:\tlearn: 0.9063069\ttotal: 34m 16s\tremaining: 1h 19m 57s\n",
      "225:\tlearn: 0.8980547\ttotal: 34m 25s\tremaining: 1h 19m 48s\n",
      "226:\tlearn: 0.8908666\ttotal: 34m 34s\tremaining: 1h 19m 39s\n",
      "227:\tlearn: 0.8846527\ttotal: 34m 43s\tremaining: 1h 19m 30s\n",
      "228:\tlearn: 0.8775704\ttotal: 34m 52s\tremaining: 1h 19m 20s\n",
      "229:\tlearn: 0.8713868\ttotal: 35m 1s\tremaining: 1h 19m 11s\n",
      "230:\tlearn: 0.8637324\ttotal: 35m 10s\tremaining: 1h 19m 2s\n",
      "231:\tlearn: 0.8560537\ttotal: 35m 20s\tremaining: 1h 18m 53s\n",
      "232:\tlearn: 0.8500275\ttotal: 35m 29s\tremaining: 1h 18m 44s\n",
      "233:\tlearn: 0.8435819\ttotal: 35m 38s\tremaining: 1h 18m 35s\n",
      "234:\tlearn: 0.8365071\ttotal: 35m 47s\tremaining: 1h 18m 26s\n",
      "235:\tlearn: 0.8310119\ttotal: 35m 56s\tremaining: 1h 18m 17s\n",
      "236:\tlearn: 0.8241110\ttotal: 36m 5s\tremaining: 1h 18m 8s\n",
      "237:\tlearn: 0.8181435\ttotal: 36m 14s\tremaining: 1h 17m 58s\n",
      "238:\tlearn: 0.8124823\ttotal: 36m 24s\tremaining: 1h 17m 49s\n",
      "239:\tlearn: 0.8071540\ttotal: 36m 33s\tremaining: 1h 17m 40s\n",
      "240:\tlearn: 0.8011811\ttotal: 36m 42s\tremaining: 1h 17m 31s\n",
      "241:\tlearn: 0.7950270\ttotal: 36m 51s\tremaining: 1h 17m 22s\n",
      "242:\tlearn: 0.7895883\ttotal: 37m\tremaining: 1h 17m 12s\n",
      "243:\tlearn: 0.7844229\ttotal: 37m 9s\tremaining: 1h 17m 4s\n",
      "244:\tlearn: 0.7773960\ttotal: 37m 18s\tremaining: 1h 16m 54s\n",
      "245:\tlearn: 0.7713221\ttotal: 37m 28s\tremaining: 1h 16m 45s\n",
      "246:\tlearn: 0.7660517\ttotal: 37m 37s\tremaining: 1h 16m 36s\n",
      "247:\tlearn: 0.7601783\ttotal: 37m 46s\tremaining: 1h 16m 27s\n",
      "248:\tlearn: 0.7542497\ttotal: 37m 55s\tremaining: 1h 16m 18s\n",
      "249:\tlearn: 0.7488459\ttotal: 38m 4s\tremaining: 1h 16m 9s\n",
      "250:\tlearn: 0.7436004\ttotal: 38m 13s\tremaining: 1h 16m\n",
      "251:\tlearn: 0.7385906\ttotal: 38m 22s\tremaining: 1h 15m 50s\n",
      "252:\tlearn: 0.7328662\ttotal: 38m 32s\tremaining: 1h 15m 41s\n",
      "253:\tlearn: 0.7279653\ttotal: 38m 41s\tremaining: 1h 15m 32s\n",
      "254:\tlearn: 0.7226356\ttotal: 38m 50s\tremaining: 1h 15m 23s\n",
      "255:\tlearn: 0.7163900\ttotal: 38m 59s\tremaining: 1h 15m 14s\n",
      "256:\tlearn: 0.7116065\ttotal: 39m 8s\tremaining: 1h 15m 4s\n",
      "257:\tlearn: 0.7056602\ttotal: 39m 17s\tremaining: 1h 14m 56s\n",
      "258:\tlearn: 0.7003870\ttotal: 39m 26s\tremaining: 1h 14m 46s\n",
      "259:\tlearn: 0.6946079\ttotal: 39m 35s\tremaining: 1h 14m 37s\n",
      "260:\tlearn: 0.6897106\ttotal: 39m 44s\tremaining: 1h 14m 28s\n",
      "261:\tlearn: 0.6851190\ttotal: 39m 54s\tremaining: 1h 14m 19s\n",
      "262:\tlearn: 0.6806080\ttotal: 40m 3s\tremaining: 1h 14m 10s\n",
      "263:\tlearn: 0.6763506\ttotal: 40m 12s\tremaining: 1h 14m\n",
      "264:\tlearn: 0.6722252\ttotal: 40m 21s\tremaining: 1h 13m 51s\n",
      "265:\tlearn: 0.6669788\ttotal: 40m 30s\tremaining: 1h 13m 42s\n",
      "266:\tlearn: 0.6616856\ttotal: 40m 39s\tremaining: 1h 13m 33s\n",
      "267:\tlearn: 0.6567126\ttotal: 40m 48s\tremaining: 1h 13m 23s\n",
      "268:\tlearn: 0.6523235\ttotal: 40m 57s\tremaining: 1h 13m 14s\n",
      "269:\tlearn: 0.6468853\ttotal: 41m 6s\tremaining: 1h 13m 5s\n",
      "270:\tlearn: 0.6430970\ttotal: 41m 15s\tremaining: 1h 12m 56s\n",
      "271:\tlearn: 0.6387223\ttotal: 41m 25s\tremaining: 1h 12m 47s\n",
      "272:\tlearn: 0.6342868\ttotal: 41m 34s\tremaining: 1h 12m 37s\n",
      "273:\tlearn: 0.6291273\ttotal: 41m 43s\tremaining: 1h 12m 28s\n",
      "274:\tlearn: 0.6254522\ttotal: 41m 52s\tremaining: 1h 12m 19s\n",
      "275:\tlearn: 0.6215198\ttotal: 42m 1s\tremaining: 1h 12m 10s\n",
      "276:\tlearn: 0.6173844\ttotal: 42m 10s\tremaining: 1h 12m 1s\n",
      "277:\tlearn: 0.6135529\ttotal: 42m 19s\tremaining: 1h 11m 52s\n",
      "278:\tlearn: 0.6092677\ttotal: 42m 29s\tremaining: 1h 11m 44s\n",
      "279:\tlearn: 0.6044883\ttotal: 42m 39s\tremaining: 1h 11m 35s\n",
      "280:\tlearn: 0.5999794\ttotal: 42m 48s\tremaining: 1h 11m 26s\n",
      "281:\tlearn: 0.5957658\ttotal: 42m 57s\tremaining: 1h 11m 18s\n",
      "282:\tlearn: 0.5920663\ttotal: 43m 7s\tremaining: 1h 11m 10s\n",
      "283:\tlearn: 0.5878710\ttotal: 43m 17s\tremaining: 1h 11m 1s\n",
      "284:\tlearn: 0.5837147\ttotal: 43m 26s\tremaining: 1h 10m 52s\n",
      "285:\tlearn: 0.5793030\ttotal: 43m 35s\tremaining: 1h 10m 43s\n",
      "286:\tlearn: 0.5743944\ttotal: 43m 45s\tremaining: 1h 10m 34s\n",
      "287:\tlearn: 0.5700363\ttotal: 43m 54s\tremaining: 1h 10m 26s\n",
      "288:\tlearn: 0.5664604\ttotal: 44m 4s\tremaining: 1h 10m 17s\n",
      "289:\tlearn: 0.5620336\ttotal: 44m 12s\tremaining: 1h 10m 8s\n",
      "290:\tlearn: 0.5583585\ttotal: 44m 22s\tremaining: 1h 9m 59s\n",
      "291:\tlearn: 0.5539216\ttotal: 44m 31s\tremaining: 1h 9m 49s\n",
      "292:\tlearn: 0.5499703\ttotal: 44m 40s\tremaining: 1h 9m 40s\n",
      "293:\tlearn: 0.5453178\ttotal: 44m 49s\tremaining: 1h 9m 31s\n",
      "294:\tlearn: 0.5414590\ttotal: 44m 58s\tremaining: 1h 9m 22s\n",
      "295:\tlearn: 0.5373827\ttotal: 45m 7s\tremaining: 1h 9m 13s\n",
      "296:\tlearn: 0.5334951\ttotal: 45m 16s\tremaining: 1h 9m 3s\n",
      "297:\tlearn: 0.5291705\ttotal: 45m 26s\tremaining: 1h 8m 54s\n",
      "298:\tlearn: 0.5253478\ttotal: 45m 35s\tremaining: 1h 8m 45s\n",
      "299:\tlearn: 0.5220227\ttotal: 45m 44s\tremaining: 1h 8m 36s\n",
      "300:\tlearn: 0.5184587\ttotal: 45m 53s\tremaining: 1h 8m 27s\n",
      "301:\tlearn: 0.5146732\ttotal: 46m 2s\tremaining: 1h 8m 17s\n",
      "302:\tlearn: 0.5107341\ttotal: 46m 11s\tremaining: 1h 8m 8s\n",
      "303:\tlearn: 0.5076312\ttotal: 46m 20s\tremaining: 1h 7m 59s\n",
      "304:\tlearn: 0.5042424\ttotal: 46m 29s\tremaining: 1h 7m 49s\n",
      "305:\tlearn: 0.5009048\ttotal: 46m 38s\tremaining: 1h 7m 41s\n",
      "306:\tlearn: 0.4970341\ttotal: 46m 48s\tremaining: 1h 7m 31s\n",
      "307:\tlearn: 0.4932346\ttotal: 46m 57s\tremaining: 1h 7m 22s\n",
      "308:\tlearn: 0.4904522\ttotal: 47m 6s\tremaining: 1h 7m 13s\n",
      "309:\tlearn: 0.4874531\ttotal: 47m 15s\tremaining: 1h 7m 4s\n",
      "310:\tlearn: 0.4840090\ttotal: 47m 24s\tremaining: 1h 6m 55s\n",
      "311:\tlearn: 0.4806134\ttotal: 47m 33s\tremaining: 1h 6m 46s\n",
      "312:\tlearn: 0.4769126\ttotal: 47m 42s\tremaining: 1h 6m 36s\n",
      "313:\tlearn: 0.4737228\ttotal: 47m 51s\tremaining: 1h 6m 27s\n",
      "314:\tlearn: 0.4705667\ttotal: 48m\tremaining: 1h 6m 18s\n",
      "315:\tlearn: 0.4678871\ttotal: 48m 9s\tremaining: 1h 6m 9s\n",
      "316:\tlearn: 0.4645058\ttotal: 48m 18s\tremaining: 1h 5m 59s\n",
      "317:\tlearn: 0.4613868\ttotal: 48m 28s\tremaining: 1h 5m 50s\n",
      "318:\tlearn: 0.4583066\ttotal: 48m 37s\tremaining: 1h 5m 41s\n",
      "319:\tlearn: 0.4561200\ttotal: 48m 46s\tremaining: 1h 5m 31s\n",
      "320:\tlearn: 0.4533460\ttotal: 48m 55s\tremaining: 1h 5m 22s\n",
      "321:\tlearn: 0.4497410\ttotal: 49m 4s\tremaining: 1h 5m 13s\n",
      "322:\tlearn: 0.4463159\ttotal: 49m 13s\tremaining: 1h 5m 4s\n",
      "323:\tlearn: 0.4435552\ttotal: 49m 22s\tremaining: 1h 4m 55s\n",
      "324:\tlearn: 0.4406458\ttotal: 49m 31s\tremaining: 1h 4m 45s\n",
      "325:\tlearn: 0.4376639\ttotal: 49m 40s\tremaining: 1h 4m 36s\n",
      "326:\tlearn: 0.4345734\ttotal: 49m 49s\tremaining: 1h 4m 27s\n",
      "327:\tlearn: 0.4312387\ttotal: 49m 58s\tremaining: 1h 4m 18s\n",
      "328:\tlearn: 0.4286295\ttotal: 50m 7s\tremaining: 1h 4m 8s\n",
      "329:\tlearn: 0.4258071\ttotal: 50m 16s\tremaining: 1h 3m 59s\n",
      "330:\tlearn: 0.4231749\ttotal: 50m 25s\tremaining: 1h 3m 50s\n",
      "331:\tlearn: 0.4209994\ttotal: 50m 34s\tremaining: 1h 3m 41s\n",
      "332:\tlearn: 0.4187323\ttotal: 50m 43s\tremaining: 1h 3m 31s\n",
      "333:\tlearn: 0.4158651\ttotal: 50m 53s\tremaining: 1h 3m 22s\n",
      "334:\tlearn: 0.4131078\ttotal: 51m 2s\tremaining: 1h 3m 13s\n",
      "335:\tlearn: 0.4107749\ttotal: 51m 11s\tremaining: 1h 3m 4s\n",
      "336:\tlearn: 0.4089818\ttotal: 51m 20s\tremaining: 1h 2m 54s\n",
      "337:\tlearn: 0.4074262\ttotal: 51m 29s\tremaining: 1h 2m 45s\n",
      "338:\tlearn: 0.4047669\ttotal: 51m 38s\tremaining: 1h 2m 36s\n",
      "339:\tlearn: 0.4024280\ttotal: 51m 47s\tremaining: 1h 2m 26s\n",
      "340:\tlearn: 0.4003661\ttotal: 51m 56s\tremaining: 1h 2m 17s\n",
      "341:\tlearn: 0.3984790\ttotal: 52m 5s\tremaining: 1h 2m 8s\n",
      "342:\tlearn: 0.3956932\ttotal: 52m 14s\tremaining: 1h 1m 59s\n",
      "343:\tlearn: 0.3929311\ttotal: 52m 23s\tremaining: 1h 1m 50s\n",
      "344:\tlearn: 0.3899890\ttotal: 52m 32s\tremaining: 1h 1m 40s\n",
      "345:\tlearn: 0.3884211\ttotal: 52m 41s\tremaining: 1h 1m 31s\n",
      "346:\tlearn: 0.3873979\ttotal: 52m 50s\tremaining: 1h 1m 22s\n",
      "347:\tlearn: 0.3858016\ttotal: 52m 59s\tremaining: 1h 1m 12s\n",
      "348:\tlearn: 0.3833388\ttotal: 53m 8s\tremaining: 1h 1m 3s\n",
      "349:\tlearn: 0.3809979\ttotal: 53m 17s\tremaining: 1h 54s\n",
      "350:\tlearn: 0.3785229\ttotal: 53m 26s\tremaining: 1h 45s\n",
      "351:\tlearn: 0.3760666\ttotal: 53m 35s\tremaining: 1h 35s\n",
      "352:\tlearn: 0.3741163\ttotal: 53m 44s\tremaining: 1h 26s\n",
      "353:\tlearn: 0.3718620\ttotal: 53m 53s\tremaining: 1h 17s\n",
      "354:\tlearn: 0.3699732\ttotal: 54m 2s\tremaining: 1h 8s\n",
      "355:\tlearn: 0.3680566\ttotal: 54m 11s\tremaining: 59m 58s\n",
      "356:\tlearn: 0.3657406\ttotal: 54m 20s\tremaining: 59m 49s\n",
      "357:\tlearn: 0.3638208\ttotal: 54m 30s\tremaining: 59m 40s\n",
      "358:\tlearn: 0.3623757\ttotal: 54m 38s\tremaining: 59m 31s\n",
      "359:\tlearn: 0.3604519\ttotal: 54m 47s\tremaining: 59m 21s\n",
      "360:\tlearn: 0.3584174\ttotal: 54m 56s\tremaining: 59m 12s\n",
      "361:\tlearn: 0.3567157\ttotal: 55m 5s\tremaining: 59m 3s\n",
      "362:\tlearn: 0.3550323\ttotal: 55m 14s\tremaining: 58m 54s\n",
      "363:\tlearn: 0.3527191\ttotal: 55m 24s\tremaining: 58m 44s\n",
      "364:\tlearn: 0.3507926\ttotal: 55m 33s\tremaining: 58m 35s\n",
      "365:\tlearn: 0.3495145\ttotal: 55m 42s\tremaining: 58m 26s\n",
      "366:\tlearn: 0.3474816\ttotal: 55m 51s\tremaining: 58m 17s\n",
      "367:\tlearn: 0.3457422\ttotal: 56m\tremaining: 58m 8s\n",
      "368:\tlearn: 0.3440456\ttotal: 56m 9s\tremaining: 57m 58s\n",
      "369:\tlearn: 0.3422840\ttotal: 56m 18s\tremaining: 57m 49s\n",
      "370:\tlearn: 0.3404348\ttotal: 56m 27s\tremaining: 57m 40s\n",
      "371:\tlearn: 0.3384087\ttotal: 56m 36s\tremaining: 57m 31s\n",
      "372:\tlearn: 0.3369354\ttotal: 56m 45s\tremaining: 57m 21s\n",
      "373:\tlearn: 0.3348647\ttotal: 56m 54s\tremaining: 57m 12s\n",
      "374:\tlearn: 0.3334936\ttotal: 57m 3s\tremaining: 57m 3s\n",
      "375:\tlearn: 0.3314353\ttotal: 57m 12s\tremaining: 56m 54s\n",
      "376:\tlearn: 0.3302325\ttotal: 57m 21s\tremaining: 56m 45s\n",
      "377:\tlearn: 0.3289741\ttotal: 57m 30s\tremaining: 56m 35s\n",
      "378:\tlearn: 0.3273458\ttotal: 57m 39s\tremaining: 56m 26s\n",
      "379:\tlearn: 0.3257024\ttotal: 57m 48s\tremaining: 56m 17s\n",
      "380:\tlearn: 0.3238381\ttotal: 57m 57s\tremaining: 56m 8s\n",
      "381:\tlearn: 0.3219933\ttotal: 58m 6s\tremaining: 55m 58s\n",
      "382:\tlearn: 0.3203518\ttotal: 58m 15s\tremaining: 55m 49s\n",
      "383:\tlearn: 0.3190249\ttotal: 58m 24s\tremaining: 55m 40s\n",
      "384:\tlearn: 0.3175896\ttotal: 58m 34s\tremaining: 55m 31s\n",
      "385:\tlearn: 0.3159999\ttotal: 58m 42s\tremaining: 55m 22s\n",
      "386:\tlearn: 0.3142614\ttotal: 58m 52s\tremaining: 55m 13s\n",
      "387:\tlearn: 0.3130541\ttotal: 59m 1s\tremaining: 55m 3s\n",
      "388:\tlearn: 0.3120610\ttotal: 59m 10s\tremaining: 54m 54s\n",
      "389:\tlearn: 0.3106480\ttotal: 59m 19s\tremaining: 54m 45s\n",
      "390:\tlearn: 0.3088657\ttotal: 59m 28s\tremaining: 54m 36s\n",
      "391:\tlearn: 0.3068894\ttotal: 59m 37s\tremaining: 54m 27s\n",
      "392:\tlearn: 0.3055434\ttotal: 59m 46s\tremaining: 54m 17s\n",
      "393:\tlearn: 0.3041650\ttotal: 59m 55s\tremaining: 54m 8s\n",
      "394:\tlearn: 0.3027314\ttotal: 1h 4s\tremaining: 53m 59s\n",
      "395:\tlearn: 0.3012758\ttotal: 1h 13s\tremaining: 53m 50s\n",
      "396:\tlearn: 0.2993729\ttotal: 1h 22s\tremaining: 53m 40s\n",
      "397:\tlearn: 0.2978505\ttotal: 1h 31s\tremaining: 53m 31s\n",
      "398:\tlearn: 0.2965628\ttotal: 1h 40s\tremaining: 53m 22s\n",
      "399:\tlearn: 0.2950710\ttotal: 1h 49s\tremaining: 53m 13s\n",
      "400:\tlearn: 0.2939649\ttotal: 1h 58s\tremaining: 53m 4s\n",
      "401:\tlearn: 0.2923627\ttotal: 1h 1m 7s\tremaining: 52m 54s\n",
      "402:\tlearn: 0.2908707\ttotal: 1h 1m 16s\tremaining: 52m 45s\n",
      "403:\tlearn: 0.2893581\ttotal: 1h 1m 25s\tremaining: 52m 36s\n",
      "404:\tlearn: 0.2881224\ttotal: 1h 1m 34s\tremaining: 52m 27s\n",
      "405:\tlearn: 0.2867255\ttotal: 1h 1m 43s\tremaining: 52m 18s\n",
      "406:\tlearn: 0.2856439\ttotal: 1h 1m 52s\tremaining: 52m 8s\n",
      "407:\tlearn: 0.2850668\ttotal: 1h 2m 1s\tremaining: 51m 59s\n",
      "408:\tlearn: 0.2837584\ttotal: 1h 2m 10s\tremaining: 51m 50s\n",
      "409:\tlearn: 0.2825976\ttotal: 1h 2m 19s\tremaining: 51m 41s\n",
      "410:\tlearn: 0.2814685\ttotal: 1h 2m 28s\tremaining: 51m 31s\n",
      "411:\tlearn: 0.2801324\ttotal: 1h 2m 37s\tremaining: 51m 22s\n",
      "412:\tlearn: 0.2787712\ttotal: 1h 2m 46s\tremaining: 51m 13s\n",
      "413:\tlearn: 0.2775389\ttotal: 1h 2m 55s\tremaining: 51m 4s\n",
      "414:\tlearn: 0.2768500\ttotal: 1h 3m 4s\tremaining: 50m 55s\n",
      "415:\tlearn: 0.2758668\ttotal: 1h 3m 13s\tremaining: 50m 45s\n",
      "416:\tlearn: 0.2743951\ttotal: 1h 3m 22s\tremaining: 50m 36s\n",
      "417:\tlearn: 0.2733528\ttotal: 1h 3m 31s\tremaining: 50m 27s\n",
      "418:\tlearn: 0.2719348\ttotal: 1h 3m 40s\tremaining: 50m 18s\n",
      "419:\tlearn: 0.2705029\ttotal: 1h 3m 49s\tremaining: 50m 9s\n",
      "420:\tlearn: 0.2697470\ttotal: 1h 3m 58s\tremaining: 49m 59s\n",
      "421:\tlearn: 0.2682956\ttotal: 1h 4m 8s\tremaining: 49m 50s\n",
      "422:\tlearn: 0.2670142\ttotal: 1h 4m 17s\tremaining: 49m 41s\n",
      "423:\tlearn: 0.2658544\ttotal: 1h 4m 26s\tremaining: 49m 32s\n",
      "424:\tlearn: 0.2644620\ttotal: 1h 4m 35s\tremaining: 49m 23s\n",
      "425:\tlearn: 0.2633421\ttotal: 1h 4m 44s\tremaining: 49m 14s\n",
      "426:\tlearn: 0.2625491\ttotal: 1h 4m 53s\tremaining: 49m 4s\n",
      "427:\tlearn: 0.2612098\ttotal: 1h 5m 2s\tremaining: 48m 55s\n",
      "428:\tlearn: 0.2600883\ttotal: 1h 5m 11s\tremaining: 48m 46s\n",
      "429:\tlearn: 0.2590786\ttotal: 1h 5m 20s\tremaining: 48m 37s\n",
      "430:\tlearn: 0.2577151\ttotal: 1h 5m 29s\tremaining: 48m 28s\n",
      "431:\tlearn: 0.2572390\ttotal: 1h 5m 38s\tremaining: 48m 18s\n",
      "432:\tlearn: 0.2561024\ttotal: 1h 5m 47s\tremaining: 48m 9s\n",
      "433:\tlearn: 0.2550403\ttotal: 1h 5m 56s\tremaining: 48m\n",
      "434:\tlearn: 0.2537618\ttotal: 1h 6m 5s\tremaining: 47m 51s\n",
      "435:\tlearn: 0.2525804\ttotal: 1h 6m 14s\tremaining: 47m 42s\n",
      "436:\tlearn: 0.2517588\ttotal: 1h 6m 23s\tremaining: 47m 32s\n",
      "437:\tlearn: 0.2507936\ttotal: 1h 6m 32s\tremaining: 47m 23s\n",
      "438:\tlearn: 0.2501193\ttotal: 1h 6m 41s\tremaining: 47m 14s\n",
      "439:\tlearn: 0.2491934\ttotal: 1h 6m 50s\tremaining: 47m 5s\n",
      "440:\tlearn: 0.2480768\ttotal: 1h 6m 59s\tremaining: 46m 56s\n",
      "441:\tlearn: 0.2469807\ttotal: 1h 7m 8s\tremaining: 46m 47s\n",
      "442:\tlearn: 0.2456649\ttotal: 1h 7m 17s\tremaining: 46m 37s\n",
      "443:\tlearn: 0.2447756\ttotal: 1h 7m 26s\tremaining: 46m 28s\n",
      "444:\tlearn: 0.2440070\ttotal: 1h 7m 35s\tremaining: 46m 19s\n",
      "445:\tlearn: 0.2428511\ttotal: 1h 7m 44s\tremaining: 46m 10s\n",
      "446:\tlearn: 0.2422060\ttotal: 1h 7m 53s\tremaining: 46m 1s\n",
      "447:\tlearn: 0.2410353\ttotal: 1h 8m 2s\tremaining: 45m 52s\n",
      "448:\tlearn: 0.2398212\ttotal: 1h 8m 11s\tremaining: 45m 42s\n",
      "449:\tlearn: 0.2391008\ttotal: 1h 8m 20s\tremaining: 45m 33s\n",
      "450:\tlearn: 0.2380255\ttotal: 1h 8m 29s\tremaining: 45m 24s\n",
      "451:\tlearn: 0.2374604\ttotal: 1h 8m 38s\tremaining: 45m 15s\n",
      "452:\tlearn: 0.2366313\ttotal: 1h 8m 47s\tremaining: 45m 6s\n",
      "453:\tlearn: 0.2356651\ttotal: 1h 8m 56s\tremaining: 44m 57s\n",
      "454:\tlearn: 0.2346407\ttotal: 1h 9m 5s\tremaining: 44m 47s\n",
      "455:\tlearn: 0.2338337\ttotal: 1h 9m 14s\tremaining: 44m 38s\n",
      "456:\tlearn: 0.2326424\ttotal: 1h 9m 23s\tremaining: 44m 29s\n",
      "457:\tlearn: 0.2314276\ttotal: 1h 9m 32s\tremaining: 44m 20s\n",
      "458:\tlearn: 0.2306161\ttotal: 1h 9m 41s\tremaining: 44m 11s\n",
      "459:\tlearn: 0.2296340\ttotal: 1h 9m 50s\tremaining: 44m 1s\n",
      "460:\tlearn: 0.2292179\ttotal: 1h 9m 59s\tremaining: 43m 52s\n",
      "461:\tlearn: 0.2283035\ttotal: 1h 10m 8s\tremaining: 43m 43s\n",
      "462:\tlearn: 0.2273669\ttotal: 1h 10m 17s\tremaining: 43m 34s\n",
      "463:\tlearn: 0.2263090\ttotal: 1h 10m 26s\tremaining: 43m 25s\n",
      "464:\tlearn: 0.2257329\ttotal: 1h 10m 35s\tremaining: 43m 16s\n",
      "465:\tlearn: 0.2246352\ttotal: 1h 10m 44s\tremaining: 43m 6s\n",
      "466:\tlearn: 0.2237798\ttotal: 1h 10m 54s\tremaining: 42m 57s\n",
      "467:\tlearn: 0.2227126\ttotal: 1h 11m 2s\tremaining: 42m 48s\n",
      "468:\tlearn: 0.2219888\ttotal: 1h 11m 11s\tremaining: 42m 39s\n",
      "469:\tlearn: 0.2210870\ttotal: 1h 11m 21s\tremaining: 42m 30s\n",
      "470:\tlearn: 0.2205221\ttotal: 1h 11m 30s\tremaining: 42m 21s\n",
      "471:\tlearn: 0.2197220\ttotal: 1h 11m 39s\tremaining: 42m 12s\n",
      "472:\tlearn: 0.2188125\ttotal: 1h 11m 47s\tremaining: 42m 2s\n",
      "473:\tlearn: 0.2178736\ttotal: 1h 11m 57s\tremaining: 41m 53s\n",
      "474:\tlearn: 0.2171222\ttotal: 1h 12m 5s\tremaining: 41m 44s\n",
      "475:\tlearn: 0.2162839\ttotal: 1h 12m 14s\tremaining: 41m 35s\n",
      "476:\tlearn: 0.2155052\ttotal: 1h 12m 24s\tremaining: 41m 26s\n",
      "477:\tlearn: 0.2148240\ttotal: 1h 12m 32s\tremaining: 41m 17s\n",
      "478:\tlearn: 0.2139404\ttotal: 1h 12m 42s\tremaining: 41m 7s\n",
      "479:\tlearn: 0.2132058\ttotal: 1h 12m 51s\tremaining: 40m 58s\n",
      "480:\tlearn: 0.2122340\ttotal: 1h 13m\tremaining: 40m 49s\n",
      "481:\tlearn: 0.2114070\ttotal: 1h 13m 9s\tremaining: 40m 40s\n",
      "482:\tlearn: 0.2106783\ttotal: 1h 13m 18s\tremaining: 40m 31s\n",
      "483:\tlearn: 0.2097706\ttotal: 1h 13m 27s\tremaining: 40m 22s\n",
      "484:\tlearn: 0.2091273\ttotal: 1h 13m 36s\tremaining: 40m 12s\n",
      "485:\tlearn: 0.2082557\ttotal: 1h 13m 45s\tremaining: 40m 3s\n",
      "486:\tlearn: 0.2074082\ttotal: 1h 13m 54s\tremaining: 39m 54s\n",
      "487:\tlearn: 0.2064187\ttotal: 1h 14m 3s\tremaining: 39m 45s\n",
      "488:\tlearn: 0.2059539\ttotal: 1h 14m 12s\tremaining: 39m 36s\n",
      "489:\tlearn: 0.2053485\ttotal: 1h 14m 21s\tremaining: 39m 27s\n",
      "490:\tlearn: 0.2045283\ttotal: 1h 14m 30s\tremaining: 39m 18s\n",
      "491:\tlearn: 0.2038468\ttotal: 1h 14m 39s\tremaining: 39m 8s\n",
      "492:\tlearn: 0.2028792\ttotal: 1h 14m 48s\tremaining: 38m 59s\n",
      "493:\tlearn: 0.2022568\ttotal: 1h 14m 57s\tremaining: 38m 50s\n",
      "494:\tlearn: 0.2020575\ttotal: 1h 15m 6s\tremaining: 38m 41s\n",
      "495:\tlearn: 0.2012287\ttotal: 1h 15m 15s\tremaining: 38m 32s\n",
      "496:\tlearn: 0.2004972\ttotal: 1h 15m 24s\tremaining: 38m 23s\n",
      "497:\tlearn: 0.2001035\ttotal: 1h 15m 33s\tremaining: 38m 13s\n",
      "498:\tlearn: 0.1993195\ttotal: 1h 15m 42s\tremaining: 38m 4s\n",
      "499:\tlearn: 0.1986047\ttotal: 1h 15m 51s\tremaining: 37m 55s\n",
      "500:\tlearn: 0.1978503\ttotal: 1h 16m\tremaining: 37m 46s\n",
      "501:\tlearn: 0.1970014\ttotal: 1h 16m 9s\tremaining: 37m 37s\n",
      "502:\tlearn: 0.1961915\ttotal: 1h 16m 18s\tremaining: 37m 28s\n",
      "503:\tlearn: 0.1953178\ttotal: 1h 16m 27s\tremaining: 37m 19s\n",
      "504:\tlearn: 0.1944952\ttotal: 1h 16m 36s\tremaining: 37m 10s\n",
      "505:\tlearn: 0.1937650\ttotal: 1h 16m 45s\tremaining: 37m\n",
      "506:\tlearn: 0.1932664\ttotal: 1h 16m 54s\tremaining: 36m 51s\n",
      "507:\tlearn: 0.1926947\ttotal: 1h 17m 3s\tremaining: 36m 42s\n",
      "508:\tlearn: 0.1921279\ttotal: 1h 17m 12s\tremaining: 36m 33s\n",
      "509:\tlearn: 0.1914898\ttotal: 1h 17m 21s\tremaining: 36m 24s\n",
      "510:\tlearn: 0.1909973\ttotal: 1h 17m 30s\tremaining: 36m 15s\n",
      "511:\tlearn: 0.1903934\ttotal: 1h 17m 39s\tremaining: 36m 6s\n",
      "512:\tlearn: 0.1897074\ttotal: 1h 17m 48s\tremaining: 35m 56s\n",
      "513:\tlearn: 0.1889045\ttotal: 1h 17m 57s\tremaining: 35m 47s\n",
      "514:\tlearn: 0.1882008\ttotal: 1h 18m 6s\tremaining: 35m 38s\n",
      "515:\tlearn: 0.1876490\ttotal: 1h 18m 15s\tremaining: 35m 29s\n",
      "516:\tlearn: 0.1870248\ttotal: 1h 18m 25s\tremaining: 35m 20s\n",
      "517:\tlearn: 0.1863516\ttotal: 1h 18m 34s\tremaining: 35m 11s\n",
      "518:\tlearn: 0.1858517\ttotal: 1h 18m 43s\tremaining: 35m 2s\n",
      "519:\tlearn: 0.1852314\ttotal: 1h 18m 52s\tremaining: 34m 53s\n",
      "520:\tlearn: 0.1847660\ttotal: 1h 19m 1s\tremaining: 34m 43s\n",
      "521:\tlearn: 0.1842013\ttotal: 1h 19m 10s\tremaining: 34m 34s\n",
      "522:\tlearn: 0.1835224\ttotal: 1h 19m 19s\tremaining: 34m 25s\n",
      "523:\tlearn: 0.1830162\ttotal: 1h 19m 28s\tremaining: 34m 16s\n",
      "524:\tlearn: 0.1822600\ttotal: 1h 19m 37s\tremaining: 34m 7s\n",
      "525:\tlearn: 0.1814859\ttotal: 1h 19m 46s\tremaining: 33m 58s\n",
      "526:\tlearn: 0.1809358\ttotal: 1h 19m 55s\tremaining: 33m 49s\n",
      "527:\tlearn: 0.1804396\ttotal: 1h 20m 4s\tremaining: 33m 40s\n",
      "528:\tlearn: 0.1797614\ttotal: 1h 20m 13s\tremaining: 33m 30s\n",
      "529:\tlearn: 0.1794116\ttotal: 1h 20m 22s\tremaining: 33m 21s\n",
      "530:\tlearn: 0.1791181\ttotal: 1h 20m 31s\tremaining: 33m 12s\n",
      "531:\tlearn: 0.1784541\ttotal: 1h 20m 40s\tremaining: 33m 3s\n",
      "532:\tlearn: 0.1777180\ttotal: 1h 20m 49s\tremaining: 32m 54s\n",
      "533:\tlearn: 0.1769788\ttotal: 1h 20m 58s\tremaining: 32m 45s\n",
      "534:\tlearn: 0.1764954\ttotal: 1h 21m 7s\tremaining: 32m 36s\n",
      "535:\tlearn: 0.1759495\ttotal: 1h 21m 16s\tremaining: 32m 27s\n",
      "536:\tlearn: 0.1753056\ttotal: 1h 21m 25s\tremaining: 32m 17s\n",
      "537:\tlearn: 0.1750503\ttotal: 1h 21m 34s\tremaining: 32m 8s\n",
      "538:\tlearn: 0.1744235\ttotal: 1h 21m 43s\tremaining: 31m 59s\n",
      "539:\tlearn: 0.1738201\ttotal: 1h 21m 52s\tremaining: 31m 50s\n",
      "540:\tlearn: 0.1733410\ttotal: 1h 22m 2s\tremaining: 31m 41s\n",
      "541:\tlearn: 0.1727328\ttotal: 1h 22m 11s\tremaining: 31m 32s\n",
      "542:\tlearn: 0.1722760\ttotal: 1h 22m 20s\tremaining: 31m 23s\n",
      "543:\tlearn: 0.1719362\ttotal: 1h 22m 29s\tremaining: 31m 14s\n",
      "544:\tlearn: 0.1713519\ttotal: 1h 22m 38s\tremaining: 31m 4s\n",
      "545:\tlearn: 0.1708258\ttotal: 1h 22m 47s\tremaining: 30m 55s\n",
      "546:\tlearn: 0.1701071\ttotal: 1h 22m 56s\tremaining: 30m 46s\n",
      "547:\tlearn: 0.1695256\ttotal: 1h 23m 5s\tremaining: 30m 37s\n",
      "548:\tlearn: 0.1691108\ttotal: 1h 23m 14s\tremaining: 30m 28s\n",
      "549:\tlearn: 0.1685085\ttotal: 1h 23m 23s\tremaining: 30m 19s\n",
      "550:\tlearn: 0.1679789\ttotal: 1h 23m 32s\tremaining: 30m 10s\n",
      "551:\tlearn: 0.1673644\ttotal: 1h 23m 41s\tremaining: 30m 1s\n",
      "552:\tlearn: 0.1668337\ttotal: 1h 23m 50s\tremaining: 29m 51s\n",
      "553:\tlearn: 0.1662591\ttotal: 1h 23m 59s\tremaining: 29m 42s\n",
      "554:\tlearn: 0.1657780\ttotal: 1h 24m 8s\tremaining: 29m 33s\n",
      "555:\tlearn: 0.1652685\ttotal: 1h 24m 17s\tremaining: 29m 24s\n",
      "556:\tlearn: 0.1647263\ttotal: 1h 24m 26s\tremaining: 29m 15s\n",
      "557:\tlearn: 0.1642858\ttotal: 1h 24m 35s\tremaining: 29m 6s\n",
      "558:\tlearn: 0.1638566\ttotal: 1h 24m 44s\tremaining: 28m 57s\n",
      "559:\tlearn: 0.1632184\ttotal: 1h 24m 53s\tremaining: 28m 48s\n",
      "560:\tlearn: 0.1628570\ttotal: 1h 25m 2s\tremaining: 28m 39s\n",
      "561:\tlearn: 0.1621953\ttotal: 1h 25m 11s\tremaining: 28m 30s\n",
      "562:\tlearn: 0.1619827\ttotal: 1h 25m 21s\tremaining: 28m 21s\n",
      "563:\tlearn: 0.1616164\ttotal: 1h 25m 30s\tremaining: 28m 11s\n",
      "564:\tlearn: 0.1613723\ttotal: 1h 25m 39s\tremaining: 28m 2s\n",
      "565:\tlearn: 0.1610805\ttotal: 1h 25m 48s\tremaining: 27m 53s\n",
      "566:\tlearn: 0.1608164\ttotal: 1h 25m 57s\tremaining: 27m 44s\n",
      "567:\tlearn: 0.1602798\ttotal: 1h 26m 6s\tremaining: 27m 35s\n",
      "568:\tlearn: 0.1597678\ttotal: 1h 26m 15s\tremaining: 27m 26s\n",
      "569:\tlearn: 0.1593951\ttotal: 1h 26m 24s\tremaining: 27m 17s\n",
      "570:\tlearn: 0.1587740\ttotal: 1h 26m 33s\tremaining: 27m 8s\n",
      "571:\tlearn: 0.1582772\ttotal: 1h 26m 42s\tremaining: 26m 59s\n",
      "572:\tlearn: 0.1578863\ttotal: 1h 26m 51s\tremaining: 26m 49s\n",
      "573:\tlearn: 0.1574669\ttotal: 1h 27m\tremaining: 26m 40s\n",
      "574:\tlearn: 0.1572320\ttotal: 1h 27m 9s\tremaining: 26m 31s\n",
      "575:\tlearn: 0.1566541\ttotal: 1h 27m 18s\tremaining: 26m 22s\n",
      "576:\tlearn: 0.1561203\ttotal: 1h 27m 28s\tremaining: 26m 13s\n",
      "577:\tlearn: 0.1555280\ttotal: 1h 27m 36s\tremaining: 26m 4s\n",
      "578:\tlearn: 0.1551069\ttotal: 1h 27m 46s\tremaining: 25m 55s\n",
      "579:\tlearn: 0.1547263\ttotal: 1h 27m 55s\tremaining: 25m 46s\n",
      "580:\tlearn: 0.1541482\ttotal: 1h 28m 4s\tremaining: 25m 37s\n",
      "581:\tlearn: 0.1536355\ttotal: 1h 28m 13s\tremaining: 25m 28s\n",
      "582:\tlearn: 0.1531695\ttotal: 1h 28m 22s\tremaining: 25m 18s\n",
      "583:\tlearn: 0.1526248\ttotal: 1h 28m 31s\tremaining: 25m 9s\n",
      "584:\tlearn: 0.1521856\ttotal: 1h 28m 40s\tremaining: 25m\n",
      "585:\tlearn: 0.1517611\ttotal: 1h 28m 49s\tremaining: 24m 51s\n",
      "586:\tlearn: 0.1512047\ttotal: 1h 28m 58s\tremaining: 24m 42s\n",
      "587:\tlearn: 0.1507551\ttotal: 1h 29m 7s\tremaining: 24m 33s\n",
      "588:\tlearn: 0.1503215\ttotal: 1h 29m 16s\tremaining: 24m 24s\n",
      "589:\tlearn: 0.1498601\ttotal: 1h 29m 25s\tremaining: 24m 15s\n",
      "590:\tlearn: 0.1493518\ttotal: 1h 29m 34s\tremaining: 24m 6s\n",
      "591:\tlearn: 0.1490465\ttotal: 1h 29m 43s\tremaining: 23m 56s\n",
      "592:\tlearn: 0.1485071\ttotal: 1h 29m 53s\tremaining: 23m 47s\n",
      "593:\tlearn: 0.1480145\ttotal: 1h 30m 1s\tremaining: 23m 38s\n",
      "594:\tlearn: 0.1476959\ttotal: 1h 30m 10s\tremaining: 23m 29s\n",
      "595:\tlearn: 0.1473689\ttotal: 1h 30m 20s\tremaining: 23m 20s\n",
      "596:\tlearn: 0.1470790\ttotal: 1h 30m 29s\tremaining: 23m 11s\n",
      "597:\tlearn: 0.1469099\ttotal: 1h 30m 38s\tremaining: 23m 2s\n",
      "598:\tlearn: 0.1467285\ttotal: 1h 30m 47s\tremaining: 22m 53s\n",
      "599:\tlearn: 0.1464452\ttotal: 1h 30m 56s\tremaining: 22m 44s\n",
      "600:\tlearn: 0.1459015\ttotal: 1h 31m 5s\tremaining: 22m 34s\n",
      "601:\tlearn: 0.1456032\ttotal: 1h 31m 14s\tremaining: 22m 25s\n",
      "602:\tlearn: 0.1451524\ttotal: 1h 31m 23s\tremaining: 22m 16s\n",
      "603:\tlearn: 0.1447190\ttotal: 1h 31m 32s\tremaining: 22m 7s\n",
      "604:\tlearn: 0.1445604\ttotal: 1h 31m 41s\tremaining: 21m 58s\n",
      "605:\tlearn: 0.1442048\ttotal: 1h 31m 50s\tremaining: 21m 49s\n",
      "606:\tlearn: 0.1438651\ttotal: 1h 31m 59s\tremaining: 21m 40s\n",
      "607:\tlearn: 0.1434967\ttotal: 1h 32m 8s\tremaining: 21m 31s\n",
      "608:\tlearn: 0.1430952\ttotal: 1h 32m 17s\tremaining: 21m 22s\n",
      "609:\tlearn: 0.1427288\ttotal: 1h 32m 26s\tremaining: 21m 12s\n",
      "610:\tlearn: 0.1421650\ttotal: 1h 32m 35s\tremaining: 21m 3s\n",
      "611:\tlearn: 0.1418026\ttotal: 1h 32m 44s\tremaining: 20m 54s\n",
      "612:\tlearn: 0.1413399\ttotal: 1h 32m 53s\tremaining: 20m 45s\n",
      "613:\tlearn: 0.1409198\ttotal: 1h 33m 2s\tremaining: 20m 36s\n",
      "614:\tlearn: 0.1404992\ttotal: 1h 33m 11s\tremaining: 20m 27s\n",
      "615:\tlearn: 0.1401476\ttotal: 1h 33m 20s\tremaining: 20m 18s\n",
      "616:\tlearn: 0.1397850\ttotal: 1h 33m 29s\tremaining: 20m 9s\n",
      "617:\tlearn: 0.1393822\ttotal: 1h 33m 38s\tremaining: 20m\n",
      "618:\tlearn: 0.1389182\ttotal: 1h 33m 48s\tremaining: 19m 51s\n",
      "619:\tlearn: 0.1386025\ttotal: 1h 33m 57s\tremaining: 19m 41s\n",
      "620:\tlearn: 0.1382181\ttotal: 1h 34m 6s\tremaining: 19m 32s\n",
      "621:\tlearn: 0.1377709\ttotal: 1h 34m 15s\tremaining: 19m 23s\n",
      "622:\tlearn: 0.1373513\ttotal: 1h 34m 24s\tremaining: 19m 14s\n",
      "623:\tlearn: 0.1370729\ttotal: 1h 34m 33s\tremaining: 19m 5s\n",
      "624:\tlearn: 0.1366564\ttotal: 1h 34m 42s\tremaining: 18m 56s\n",
      "625:\tlearn: 0.1364211\ttotal: 1h 34m 51s\tremaining: 18m 47s\n",
      "626:\tlearn: 0.1359600\ttotal: 1h 34m 59s\tremaining: 18m 38s\n",
      "627:\tlearn: 0.1354977\ttotal: 1h 35m 9s\tremaining: 18m 29s\n",
      "628:\tlearn: 0.1350719\ttotal: 1h 35m 18s\tremaining: 18m 19s\n",
      "629:\tlearn: 0.1347285\ttotal: 1h 35m 27s\tremaining: 18m 10s\n",
      "630:\tlearn: 0.1342679\ttotal: 1h 35m 35s\tremaining: 18m 1s\n",
      "631:\tlearn: 0.1338855\ttotal: 1h 35m 45s\tremaining: 17m 52s\n",
      "632:\tlearn: 0.1335038\ttotal: 1h 35m 54s\tremaining: 17m 43s\n",
      "633:\tlearn: 0.1330751\ttotal: 1h 36m 3s\tremaining: 17m 34s\n",
      "634:\tlearn: 0.1326591\ttotal: 1h 36m 12s\tremaining: 17m 25s\n",
      "635:\tlearn: 0.1322565\ttotal: 1h 36m 21s\tremaining: 17m 16s\n",
      "636:\tlearn: 0.1320301\ttotal: 1h 36m 30s\tremaining: 17m 7s\n",
      "637:\tlearn: 0.1317495\ttotal: 1h 36m 39s\tremaining: 16m 58s\n",
      "638:\tlearn: 0.1313321\ttotal: 1h 36m 48s\tremaining: 16m 48s\n",
      "639:\tlearn: 0.1310159\ttotal: 1h 36m 57s\tremaining: 16m 39s\n",
      "640:\tlearn: 0.1308075\ttotal: 1h 37m 6s\tremaining: 16m 30s\n",
      "641:\tlearn: 0.1304541\ttotal: 1h 37m 15s\tremaining: 16m 21s\n",
      "642:\tlearn: 0.1302969\ttotal: 1h 37m 24s\tremaining: 16m 12s\n",
      "643:\tlearn: 0.1298953\ttotal: 1h 37m 33s\tremaining: 16m 3s\n",
      "644:\tlearn: 0.1297930\ttotal: 1h 37m 42s\tremaining: 15m 54s\n",
      "645:\tlearn: 0.1293336\ttotal: 1h 37m 51s\tremaining: 15m 45s\n",
      "646:\tlearn: 0.1290097\ttotal: 1h 38m\tremaining: 15m 36s\n",
      "647:\tlearn: 0.1288128\ttotal: 1h 38m 9s\tremaining: 15m 27s\n",
      "648:\tlearn: 0.1285853\ttotal: 1h 38m 18s\tremaining: 15m 17s\n",
      "649:\tlearn: 0.1282431\ttotal: 1h 38m 27s\tremaining: 15m 8s\n",
      "650:\tlearn: 0.1280157\ttotal: 1h 38m 36s\tremaining: 14m 59s\n",
      "651:\tlearn: 0.1276159\ttotal: 1h 38m 45s\tremaining: 14m 50s\n",
      "652:\tlearn: 0.1272258\ttotal: 1h 38m 54s\tremaining: 14m 41s\n",
      "653:\tlearn: 0.1269983\ttotal: 1h 39m 3s\tremaining: 14m 32s\n",
      "654:\tlearn: 0.1266220\ttotal: 1h 39m 12s\tremaining: 14m 23s\n",
      "655:\tlearn: 0.1262989\ttotal: 1h 39m 21s\tremaining: 14m 14s\n",
      "656:\tlearn: 0.1258761\ttotal: 1h 39m 30s\tremaining: 14m 5s\n",
      "657:\tlearn: 0.1255067\ttotal: 1h 39m 39s\tremaining: 13m 56s\n",
      "658:\tlearn: 0.1251546\ttotal: 1h 39m 48s\tremaining: 13m 46s\n",
      "659:\tlearn: 0.1249030\ttotal: 1h 39m 57s\tremaining: 13m 37s\n",
      "660:\tlearn: 0.1247614\ttotal: 1h 40m 6s\tremaining: 13m 28s\n",
      "661:\tlearn: 0.1244151\ttotal: 1h 40m 15s\tremaining: 13m 19s\n",
      "662:\tlearn: 0.1241940\ttotal: 1h 40m 24s\tremaining: 13m 10s\n",
      "663:\tlearn: 0.1240408\ttotal: 1h 40m 33s\tremaining: 13m 1s\n",
      "664:\tlearn: 0.1237000\ttotal: 1h 40m 42s\tremaining: 12m 52s\n",
      "665:\tlearn: 0.1234227\ttotal: 1h 40m 51s\tremaining: 12m 43s\n",
      "666:\tlearn: 0.1230472\ttotal: 1h 41m\tremaining: 12m 34s\n",
      "667:\tlearn: 0.1227294\ttotal: 1h 41m 9s\tremaining: 12m 25s\n",
      "668:\tlearn: 0.1224092\ttotal: 1h 41m 18s\tremaining: 12m 16s\n",
      "669:\tlearn: 0.1220816\ttotal: 1h 41m 27s\tremaining: 12m 6s\n",
      "670:\tlearn: 0.1217469\ttotal: 1h 41m 37s\tremaining: 11m 57s\n",
      "671:\tlearn: 0.1213819\ttotal: 1h 41m 45s\tremaining: 11m 48s\n",
      "672:\tlearn: 0.1211194\ttotal: 1h 41m 55s\tremaining: 11m 39s\n",
      "673:\tlearn: 0.1207841\ttotal: 1h 42m 4s\tremaining: 11m 30s\n",
      "674:\tlearn: 0.1205665\ttotal: 1h 42m 13s\tremaining: 11m 21s\n",
      "675:\tlearn: 0.1201354\ttotal: 1h 42m 22s\tremaining: 11m 12s\n",
      "676:\tlearn: 0.1198265\ttotal: 1h 42m 31s\tremaining: 11m 3s\n",
      "677:\tlearn: 0.1195136\ttotal: 1h 42m 40s\tremaining: 10m 54s\n",
      "678:\tlearn: 0.1192172\ttotal: 1h 42m 49s\tremaining: 10m 45s\n",
      "679:\tlearn: 0.1189204\ttotal: 1h 42m 58s\tremaining: 10m 36s\n",
      "680:\tlearn: 0.1187079\ttotal: 1h 43m 7s\tremaining: 10m 26s\n",
      "681:\tlearn: 0.1184244\ttotal: 1h 43m 16s\tremaining: 10m 17s\n",
      "682:\tlearn: 0.1181462\ttotal: 1h 43m 25s\tremaining: 10m 8s\n",
      "683:\tlearn: 0.1178789\ttotal: 1h 43m 34s\tremaining: 9m 59s\n",
      "684:\tlearn: 0.1175390\ttotal: 1h 43m 43s\tremaining: 9m 50s\n",
      "685:\tlearn: 0.1173030\ttotal: 1h 43m 52s\tremaining: 9m 41s\n",
      "686:\tlearn: 0.1169817\ttotal: 1h 44m 1s\tremaining: 9m 32s\n",
      "687:\tlearn: 0.1167082\ttotal: 1h 44m 10s\tremaining: 9m 23s\n",
      "688:\tlearn: 0.1164022\ttotal: 1h 44m 20s\tremaining: 9m 14s\n",
      "689:\tlearn: 0.1161555\ttotal: 1h 44m 29s\tremaining: 9m 5s\n",
      "690:\tlearn: 0.1159365\ttotal: 1h 44m 38s\tremaining: 8m 56s\n",
      "691:\tlearn: 0.1156776\ttotal: 1h 44m 47s\tremaining: 8m 46s\n",
      "692:\tlearn: 0.1153778\ttotal: 1h 44m 56s\tremaining: 8m 37s\n",
      "693:\tlearn: 0.1152478\ttotal: 1h 45m 5s\tremaining: 8m 28s\n",
      "694:\tlearn: 0.1150015\ttotal: 1h 45m 14s\tremaining: 8m 19s\n",
      "695:\tlearn: 0.1147726\ttotal: 1h 45m 23s\tremaining: 8m 10s\n",
      "696:\tlearn: 0.1145320\ttotal: 1h 45m 32s\tremaining: 8m 1s\n",
      "697:\tlearn: 0.1143394\ttotal: 1h 45m 41s\tremaining: 7m 52s\n",
      "698:\tlearn: 0.1140493\ttotal: 1h 45m 50s\tremaining: 7m 43s\n",
      "699:\tlearn: 0.1137813\ttotal: 1h 45m 59s\tremaining: 7m 34s\n",
      "700:\tlearn: 0.1135919\ttotal: 1h 46m 8s\tremaining: 7m 25s\n",
      "701:\tlearn: 0.1134315\ttotal: 1h 46m 17s\tremaining: 7m 16s\n",
      "702:\tlearn: 0.1132324\ttotal: 1h 46m 26s\tremaining: 7m 6s\n",
      "703:\tlearn: 0.1128722\ttotal: 1h 46m 35s\tremaining: 6m 57s\n",
      "704:\tlearn: 0.1127131\ttotal: 1h 46m 44s\tremaining: 6m 48s\n",
      "705:\tlearn: 0.1124405\ttotal: 1h 46m 53s\tremaining: 6m 39s\n",
      "706:\tlearn: 0.1121244\ttotal: 1h 47m 2s\tremaining: 6m 30s\n",
      "707:\tlearn: 0.1118925\ttotal: 1h 47m 11s\tremaining: 6m 21s\n",
      "708:\tlearn: 0.1115921\ttotal: 1h 47m 20s\tremaining: 6m 12s\n",
      "709:\tlearn: 0.1113077\ttotal: 1h 47m 29s\tremaining: 6m 3s\n",
      "710:\tlearn: 0.1110157\ttotal: 1h 47m 38s\tremaining: 5m 54s\n",
      "711:\tlearn: 0.1108932\ttotal: 1h 47m 47s\tremaining: 5m 45s\n",
      "712:\tlearn: 0.1106315\ttotal: 1h 47m 56s\tremaining: 5m 36s\n",
      "713:\tlearn: 0.1103436\ttotal: 1h 48m 5s\tremaining: 5m 26s\n",
      "714:\tlearn: 0.1100773\ttotal: 1h 48m 14s\tremaining: 5m 17s\n",
      "715:\tlearn: 0.1097816\ttotal: 1h 48m 23s\tremaining: 5m 8s\n",
      "716:\tlearn: 0.1096248\ttotal: 1h 48m 32s\tremaining: 4m 59s\n",
      "717:\tlearn: 0.1095081\ttotal: 1h 48m 41s\tremaining: 4m 50s\n",
      "718:\tlearn: 0.1093315\ttotal: 1h 48m 50s\tremaining: 4m 41s\n",
      "719:\tlearn: 0.1090772\ttotal: 1h 48m 59s\tremaining: 4m 32s\n",
      "720:\tlearn: 0.1088326\ttotal: 1h 49m 8s\tremaining: 4m 23s\n",
      "721:\tlearn: 0.1086988\ttotal: 1h 49m 17s\tremaining: 4m 14s\n",
      "722:\tlearn: 0.1083954\ttotal: 1h 49m 26s\tremaining: 4m 5s\n",
      "723:\tlearn: 0.1081935\ttotal: 1h 49m 35s\tremaining: 3m 56s\n",
      "724:\tlearn: 0.1079634\ttotal: 1h 49m 44s\tremaining: 3m 47s\n",
      "725:\tlearn: 0.1076873\ttotal: 1h 49m 53s\tremaining: 3m 37s\n",
      "726:\tlearn: 0.1074311\ttotal: 1h 50m 2s\tremaining: 3m 28s\n",
      "727:\tlearn: 0.1071217\ttotal: 1h 50m 11s\tremaining: 3m 19s\n",
      "728:\tlearn: 0.1068329\ttotal: 1h 50m 20s\tremaining: 3m 10s\n",
      "729:\tlearn: 0.1065433\ttotal: 1h 50m 29s\tremaining: 3m 1s\n",
      "730:\tlearn: 0.1062617\ttotal: 1h 50m 38s\tremaining: 2m 52s\n",
      "731:\tlearn: 0.1060051\ttotal: 1h 50m 47s\tremaining: 2m 43s\n",
      "732:\tlearn: 0.1057062\ttotal: 1h 50m 57s\tremaining: 2m 34s\n",
      "733:\tlearn: 0.1054189\ttotal: 1h 51m 5s\tremaining: 2m 25s\n",
      "734:\tlearn: 0.1051903\ttotal: 1h 51m 15s\tremaining: 2m 16s\n",
      "735:\tlearn: 0.1049157\ttotal: 1h 51m 23s\tremaining: 2m 7s\n",
      "736:\tlearn: 0.1047019\ttotal: 1h 51m 33s\tremaining: 1m 58s\n",
      "737:\tlearn: 0.1044800\ttotal: 1h 51m 42s\tremaining: 1m 48s\n",
      "738:\tlearn: 0.1043178\ttotal: 1h 51m 51s\tremaining: 1m 39s\n",
      "739:\tlearn: 0.1040097\ttotal: 1h 52m\tremaining: 1m 30s\n",
      "740:\tlearn: 0.1037650\ttotal: 1h 52m 9s\tremaining: 1m 21s\n",
      "741:\tlearn: 0.1036251\ttotal: 1h 52m 18s\tremaining: 1m 12s\n",
      "742:\tlearn: 0.1033343\ttotal: 1h 52m 27s\tremaining: 1m 3s\n",
      "743:\tlearn: 0.1031393\ttotal: 1h 52m 36s\tremaining: 54.5s\n",
      "744:\tlearn: 0.1029337\ttotal: 1h 52m 45s\tremaining: 45.4s\n",
      "745:\tlearn: 0.1027070\ttotal: 1h 52m 54s\tremaining: 36.3s\n",
      "746:\tlearn: 0.1025743\ttotal: 1h 53m 3s\tremaining: 27.2s\n",
      "747:\tlearn: 0.1024428\ttotal: 1h 53m 12s\tremaining: 18.2s\n",
      "748:\tlearn: 0.1021589\ttotal: 1h 53m 21s\tremaining: 9.08s\n",
      "749:\tlearn: 0.1019155\ttotal: 1h 53m 30s\tremaining: 0us\n",
      "Preprocessing image 1/1466\n",
      "Preprocessing image 11/1466\n",
      "Preprocessing image 21/1466\n",
      "Preprocessing image 31/1466\n",
      "Preprocessing image 41/1466\n",
      "Preprocessing image 51/1466\n",
      "Preprocessing image 61/1466\n",
      "Preprocessing image 71/1466\n",
      "Preprocessing image 81/1466\n",
      "Preprocessing image 91/1466\n",
      "Preprocessing image 101/1466\n",
      "Preprocessing image 111/1466\n",
      "Preprocessing image 121/1466\n",
      "Preprocessing image 131/1466\n",
      "Preprocessing image 141/1466\n",
      "Preprocessing image 151/1466\n",
      "Preprocessing image 161/1466\n",
      "Preprocessing image 171/1466\n",
      "Preprocessing image 181/1466\n",
      "Preprocessing image 191/1466\n",
      "Preprocessing image 201/1466\n",
      "Preprocessing image 211/1466\n",
      "Preprocessing image 221/1466\n",
      "Preprocessing image 231/1466\n",
      "Preprocessing image 241/1466\n",
      "Preprocessing image 251/1466\n",
      "Preprocessing image 261/1466\n",
      "Preprocessing image 271/1466\n",
      "Preprocessing image 281/1466\n",
      "Preprocessing image 291/1466\n",
      "Preprocessing image 301/1466\n",
      "Preprocessing image 311/1466\n",
      "Preprocessing image 321/1466\n",
      "Preprocessing image 331/1466\n",
      "Preprocessing image 341/1466\n",
      "Preprocessing image 351/1466\n",
      "Preprocessing image 361/1466\n",
      "Preprocessing image 371/1466\n",
      "Preprocessing image 381/1466\n",
      "Preprocessing image 391/1466\n",
      "Preprocessing image 401/1466\n",
      "Preprocessing image 411/1466\n",
      "Preprocessing image 421/1466\n",
      "Preprocessing image 431/1466\n",
      "Preprocessing image 441/1466\n",
      "Preprocessing image 451/1466\n",
      "Preprocessing image 461/1466\n",
      "Preprocessing image 471/1466\n",
      "Preprocessing image 481/1466\n",
      "Preprocessing image 491/1466\n",
      "Preprocessing image 501/1466\n",
      "Preprocessing image 511/1466\n",
      "Preprocessing image 521/1466\n",
      "Preprocessing image 531/1466\n",
      "Preprocessing image 541/1466\n",
      "Preprocessing image 551/1466\n",
      "Preprocessing image 561/1466\n",
      "Preprocessing image 571/1466\n",
      "Preprocessing image 581/1466\n",
      "Preprocessing image 591/1466\n",
      "Preprocessing image 601/1466\n",
      "Preprocessing image 611/1466\n",
      "Preprocessing image 621/1466\n",
      "Preprocessing image 631/1466\n",
      "Preprocessing image 641/1466\n",
      "Preprocessing image 651/1466\n",
      "Preprocessing image 661/1466\n",
      "Preprocessing image 671/1466\n",
      "Preprocessing image 681/1466\n",
      "Preprocessing image 691/1466\n",
      "Preprocessing image 701/1466\n",
      "Preprocessing image 711/1466\n",
      "Preprocessing image 721/1466\n",
      "Preprocessing image 731/1466\n",
      "Preprocessing image 741/1466\n",
      "Preprocessing image 751/1466\n",
      "Preprocessing image 761/1466\n",
      "Preprocessing image 771/1466\n",
      "Preprocessing image 781/1466\n",
      "Preprocessing image 791/1466\n",
      "Preprocessing image 801/1466\n",
      "Preprocessing image 811/1466\n",
      "Preprocessing image 821/1466\n",
      "Preprocessing image 831/1466\n",
      "Preprocessing image 841/1466\n",
      "Preprocessing image 851/1466\n",
      "Preprocessing image 861/1466\n",
      "Preprocessing image 871/1466\n",
      "Preprocessing image 881/1466\n",
      "Preprocessing image 891/1466\n",
      "Preprocessing image 901/1466\n",
      "Preprocessing image 911/1466\n",
      "Preprocessing image 921/1466\n",
      "Preprocessing image 931/1466\n",
      "Preprocessing image 941/1466\n",
      "Preprocessing image 951/1466\n",
      "Preprocessing image 961/1466\n",
      "Preprocessing image 971/1466\n",
      "Preprocessing image 981/1466\n",
      "Preprocessing image 991/1466\n",
      "Preprocessing image 1001/1466\n",
      "Preprocessing image 1011/1466\n",
      "Preprocessing image 1021/1466\n",
      "Preprocessing image 1031/1466\n",
      "Preprocessing image 1041/1466\n",
      "Preprocessing image 1051/1466\n",
      "Preprocessing image 1061/1466\n",
      "Preprocessing image 1071/1466\n",
      "Preprocessing image 1081/1466\n",
      "Preprocessing image 1091/1466\n",
      "Preprocessing image 1101/1466\n",
      "Preprocessing image 1111/1466\n",
      "Preprocessing image 1121/1466\n",
      "Preprocessing image 1131/1466\n",
      "Preprocessing image 1141/1466\n",
      "Preprocessing image 1151/1466\n",
      "Preprocessing image 1161/1466\n",
      "Preprocessing image 1171/1466\n",
      "Preprocessing image 1181/1466\n",
      "Preprocessing image 1191/1466\n",
      "Preprocessing image 1201/1466\n",
      "Preprocessing image 1211/1466\n",
      "Preprocessing image 1221/1466\n",
      "Preprocessing image 1231/1466\n",
      "Preprocessing image 1241/1466\n",
      "Preprocessing image 1251/1466\n",
      "Preprocessing image 1261/1466\n",
      "Preprocessing image 1271/1466\n",
      "Preprocessing image 1281/1466\n",
      "Preprocessing image 1291/1466\n",
      "Preprocessing image 1301/1466\n",
      "Preprocessing image 1311/1466\n",
      "Preprocessing image 1321/1466\n",
      "Preprocessing image 1331/1466\n",
      "Preprocessing image 1341/1466\n",
      "Preprocessing image 1351/1466\n",
      "Preprocessing image 1361/1466\n",
      "Preprocessing image 1371/1466\n",
      "Preprocessing image 1381/1466\n",
      "Preprocessing image 1391/1466\n",
      "Preprocessing image 1401/1466\n",
      "Preprocessing image 1411/1466\n",
      "Preprocessing image 1421/1466\n",
      "Preprocessing image 1431/1466\n",
      "Preprocessing image 1441/1466\n",
      "Preprocessing image 1451/1466\n",
      "Preprocessing image 1461/1466\n",
      "classifying video id  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Nancy_Pelosi\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 0: Nancy_Pelosi\n",
      "classifying video id  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Paul_Wolfowitz\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 1: Paul_Wolfowitz\n",
      "classifying video id  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  David_Beckham\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  David_Beckham\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  Juan_Carlos_Ferrero\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  David_Beckham\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  Alvaro_Uribe\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  David_Beckham\n",
      "Frame prediction:  Juan_Carlos_Ferrero\n",
      "Frame prediction:  Alvaro_Uribe\n",
      "Frame prediction:  David_Beckham\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  Andy_Roddick\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 10: Andy_Roddick\n",
      "classifying video id  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 11: Benazir_Bhutto\n",
      "classifying video id  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 12: Eduardo_Duhalde\n",
      "classifying video id  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Leonid_Kuchma\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 13: Leonid_Kuchma\n",
      "classifying video id  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Habib_Rizieq\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Tiger_Woods\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Habib_Rizieq\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 14: Hu_Jintao\n",
      "classifying video id  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 15: Kofi_Annan\n",
      "classifying video id  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Bill_Gates\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Fernando_Henrique_Cardoso\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Colin_Montgomerie\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 16: Colin_Montgomerie\n",
      "classifying video id  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 17: Bill_Clinton\n",
      "classifying video id  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Vladimir_Putin\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 18: Vladimir_Putin\n",
      "classifying video id  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 19: Tom_Hanks\n",
      "classifying video id  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 2: Paul_ONeill\n",
      "classifying video id  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  William_Donaldson\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 20: William_Donaldson\n",
      "classifying video id  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  William_Ford_Jr\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 21: William_Ford_Jr\n",
      "classifying video id  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 22: Mahathir_Mohamad\n",
      "classifying video id  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Elsa_Zylberstein\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 23: Elsa_Zylberstein\n",
      "classifying video id  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 24: George_W_Bush\n",
      "classifying video id  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 25: Laura_Bush\n",
      "classifying video id  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Valery_Giscard_dEstaing\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 26: Valery_Giscard_dEstaing\n",
      "classifying video id  27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Benjamin_Netanyahu\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 27: Benjamin_Netanyahu\n",
      "classifying video id  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Abdullah_Gul\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 28: Abdullah_Gul\n",
      "classifying video id  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Harrison_Ford\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Bill_Frist\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 29: Tim_Robbins\n",
      "classifying video id  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  David_Nalbandian\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Hugh_Grant\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Hugh_Grant\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Hugh_Grant\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Hugh_Grant\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Hugh_Grant\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Hugh_Grant\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Ray_Romano\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 3: Ray_Romano\n",
      "classifying video id  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 30: Eduard_Shevardnadze\n",
      "classifying video id  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 31: Mahathir_Mohamad\n",
      "classifying video id  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  James_Wolfensohn\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 32: James_Wolfensohn\n",
      "classifying video id  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Pervez_Musharraf\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Pervez_Musharraf\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Pervez_Musharraf\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "Frame prediction:  Jake_Gyllenhaal\n",
      "prediction for video 33: Jake_Gyllenhaal\n",
      "classifying video id  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Catherine_Zeta-Jones\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Ludivine_Sagnier\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Cameron_Diaz\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 34: Cameron_Diaz\n",
      "classifying video id  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Catherine_Zeta-Jones\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Catherine_Zeta-Jones\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Catherine_Zeta-Jones\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Benazir_Bhutto\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 35: Benazir_Bhutto\n",
      "classifying video id  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 36: Tom_Hanks\n",
      "classifying video id  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 37: Pedro_Malan\n",
      "classifying video id  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 38: Allyson_Felix\n",
      "classifying video id  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 39: Angela_Bassett\n",
      "classifying video id  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 4: Angela_Bassett\n",
      "classifying video id  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 40: Al_Sharpton\n",
      "classifying video id  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Kevin_Spacey\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Igor_Ivanov\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 41: Igor_Ivanov\n",
      "classifying video id  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Liza_Minnelli\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 42: Salma_Hayek\n",
      "classifying video id  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Maria_Shriver\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 43: Laura_Bush\n",
      "classifying video id  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Eduardo_Duhalde\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "Frame prediction:  Alejandro_Toledo\n",
      "prediction for video 44: Alejandro_Toledo\n",
      "classifying video id  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Tim_Henman\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Tim_Henman\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Tim_Henman\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "prediction for video 45: Jan_Ullrich\n",
      "classifying video id  46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Colin_Powell\n",
      "Frame prediction:  Colin_Powell\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Colin_Powell\n",
      "Frame prediction:  Colin_Powell\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Carla_Del_Ponte\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Colin_Powell\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Carla_Del_Ponte\n",
      "Frame prediction:  Colin_Powell\n",
      "Frame prediction:  Colin_Powell\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 46: Paul_ONeill\n",
      "classifying video id  47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  John_Howard\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Angela_Bassett\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Clay_Aiken\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 47: Bill_Clinton\n",
      "classifying video id  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Zhu_Rongji\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 48: Zhu_Rongji\n",
      "classifying video id  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Liza_Minnelli\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Bill_Frist\n",
      "Frame prediction:  Liza_Minnelli\n",
      "Frame prediction:  Bill_Simon\n",
      "Frame prediction:  Liza_Minnelli\n",
      "Frame prediction:  Hugh_Grant\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 49: Bill_Simon\n",
      "classifying video id  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Pete_Sampras\n",
      "Frame prediction:  Tom_Cruise\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Amelie_Mauresmo\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Amelie_Mauresmo\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Pete_Sampras\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Amelie_Mauresmo\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Jan_Ullrich\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 5: Jan_Ullrich\n",
      "classifying video id  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Chanda_Rubin\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Pervez_Musharraf\n",
      "Frame prediction:  Al_Sharpton\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Allyson_Felix\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 50: Allyson_Felix\n",
      "classifying video id  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 51: Nicanor_Duarte_Frutos\n",
      "classifying video id  52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Kofi_Annan\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 52: Kofi_Annan\n",
      "classifying video id  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Jeremy_Greenstock\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 53: Jeremy_Greenstock\n",
      "classifying video id  54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Nicanor_Duarte_Frutos\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Maria_Soledad_Alvear_Valenzuela\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Liza_Minnelli\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 54: Salma_Hayek\n",
      "classifying video id  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Paul_Bremer\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 55: Paul_Bremer\n",
      "classifying video id  56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Tang_Jiaxuan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Tang_Jiaxuan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Tang_Jiaxuan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Pedro_Malan\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 56: Pedro_Malan\n",
      "classifying video id  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Bill_Clinton\n",
      "Frame prediction:  Harrison_Ford\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Harrison_Ford\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Harrison_Ford\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  Nick_Nolte\n",
      "Frame prediction:  George_W_Bush\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 57: Nick_Nolte\n",
      "classifying video id  58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Renee_Zellweger\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tom_Hanks\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Tim_Robbins\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 58: Tim_Robbins\n",
      "classifying video id  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Sarah_Hughes\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Emma_Watson\n",
      "Frame prediction:  Emma_Watson\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Emma_Watson\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Carrie-Anne_Moss\n",
      "Frame prediction:  Emma_Watson\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Emma_Watson\n",
      "Frame prediction:  Norah_Jones\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Salma_Hayek\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Winona_Ryder\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 59: Winona_Ryder\n",
      "classifying video id  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Gene_Robinson\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 6: Gene_Robinson\n",
      "classifying video id  60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Condoleezza_Rice\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 60: Condoleezza_Rice\n",
      "classifying video id  61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Gray_Davis\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Jacques_Rogge\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 61: Jacques_Rogge\n",
      "classifying video id  62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "Frame prediction:  Laura_Bush\n",
      "prediction for video 62: Laura_Bush\n",
      "classifying video id  63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Martin_McGuinness\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Martin_McGuinness\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Paul_ONeill\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Enrique_Bolanos\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 63: Enrique_Bolanos\n",
      "classifying video id  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 64: Mahathir_Mohamad\n",
      "classifying video id  65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Yoriko_Kawaguchi\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Mahathir_Mohamad\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Hu_Jintao\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Tang_Jiaxuan\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Thaksin_Shinawatra\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 65: Thaksin_Shinawatra\n",
      "classifying video id  66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Tom_Harkin\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 66: Tom_Harkin\n",
      "classifying video id  67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Paula_Radcliffe\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 67: Paula_Radcliffe\n",
      "classifying video id  68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Mohammed_Al-Douri\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Tom_Crean\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 68: Tom_Crean\n",
      "classifying video id  69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Nestor_Kirchner\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 69: Nestor_Kirchner\n",
      "classifying video id  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Eduard_Shevardnadze\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Mahmoud_Abbas\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 7: Mahmoud_Abbas\n",
      "classifying video id  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Tim_Henman\n",
      "Frame prediction:  Rick_Perry\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 8: Rick_Perry\n",
      "classifying video id  9\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Charlton_Heston\n",
      "Frame prediction:  Bill_Simon\n",
      "prediction for video 9: Charlton_Heston\n",
      "Classification accuracy is 0.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap_out --no-stderr\n",
    "\n",
    "video_train_aug=video_train\n",
    "train_labels_aug=train_labels\n",
    "\n",
    "for lbl in x_train:\n",
    "    video_train_aug['img:'+lbl] = x_train[lbl]\n",
    "    train_labels_aug['img:'+lbl] = y_train[lbl]\n",
    "\n",
    "video_classifier = ClassifierVideoCatboost(model)\n",
    "#video_classifier.fit(video_train, train_labels)\n",
    "video_classifier.fit(video_train_aug, train_labels_aug)\n",
    "y_video_out = video_classifier.classify_videos(video_test)\n",
    "\n",
    "print(check_test(y_video_out, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHRr5eHf8cS7"
   },
   "outputs": [],
   "source": [
    "# %%capture cap_out --no-stderr\n",
    "\n",
    "video_train_aug=video_train\n",
    "train_labels_aug=train_labels\n",
    "\n",
    "for lbl in x_train:\n",
    "    video_train_aug['img:'+lbl] = x_train[lbl]\n",
    "    train_labels_aug['img:'+lbl] = y_train[lbl]\n",
    "\n",
    "video_classifier = ClassifierVideo(model)\n",
    "#video_classifier.fit(video_train, train_labels)\n",
    "video_classifier.fit(video_train_aug, train_labels_aug)\n",
    "y_video_out = video_classifier.classify_videos(video_test)\n",
    "\n",
    "print(check_test(y_video_out, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khAmArs3p5Tt"
   },
   "outputs": [],
   "source": [
    "y_video_out = video_classifier.classify_videos(video_test)\n",
    "\n",
    "print(check_test(y_video_out, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAoP8fz0VNi-"
   },
   "outputs": [],
   "source": [
    "with open('fc7-heq-bottleneck-2.15-all.txt', 'w') as f:\n",
    "    f.write(cap_out.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wSLl0mpb8cS-",
    "outputId": "d1b4c514-124a-4aca-d7db-c897ab7b0ed5"
   },
   "outputs": [],
   "source": [
    "print(check_test(y_video_out, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGj2CiU78cTB"
   },
   "outputs": [],
   "source": [
    "video_classifier.pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g7qWFs1BgEwz",
    "outputId": "d2eec45c-2e40-4a7d-f352-b60113567bc0"
   },
   "outputs": [],
   "source": [
    "img_classifier = ClassifierVideo(model)\n",
    "img_classifier.fit(x_train, y_train)\n",
    "y_out = img_classifier.classify_images(x_test)\n",
    "print(check_test(y_out, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ace Recognition task - video tests.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
